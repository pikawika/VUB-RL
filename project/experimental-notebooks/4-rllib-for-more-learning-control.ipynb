{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Using RLlib for more multi-agent learning control\n",
    "\n",
    "As discussed in `5-improving-dqn-architecture.ipynb` we thought of three aspects that might be the root of the agent's not learning to play the game pleasingly:\n",
    "- Training two DQN agents simultaneously is known to be though, especially when starting from a random initialisation\n",
    "- The network used was a simple MLP\n",
    "- The training is not done over enough iterations\n",
    "\n",
    "In the notebooks `5-improving-dqn-architecture.ipynb` and `6-dqn-using-a-cnn.ipynb`, two alternative networks besides MLP were used.\n",
    "Whilst these give somewhat satisfactory results when trained for long enough and incentivising moves by giving a reward for making a move, it is still far from perfect.\n",
    "The iterations were also boosted to a couple of hours on a CUDA GPU, which didn't improve things all that much.\n",
    "\n",
    "Thus, what is most likely to be an issue is the fact that we are training two agents simultaneously.\n",
    "This makes it hard to get a good performing agent.\n",
    "An alternative to this is training an agent for a couple of epochs whilst freezing the other and alternating this between the agents.\n",
    "This makes the problem to learn \"stationary\" in a certain way and is known to make learning easier.\n",
    "What is also done, often in very complex games, is starting from a somewhat smart agent instead of a random one.\n",
    "\n",
    "This notebook will use [Ray RLlib](https://docs.ray.io/en/latest/rllib/index.html), which is better documented for use in multi-agent environments and PettingZoo like environments in particular.\n",
    "They also note that zero-sum environments are harder to learn in multi-agent settings.\n",
    "That is why we introduce a reward for making moves and a high reward for playing a tie game.\n",
    "We hope to create agents that are capable of reaching a tie board or extending losses maximally in this manner.\n",
    "\n",
    "We will use portions of the [Ray documentation and examples in this notebook](https://docs.ray.io/en/latest/rllib/rllib-examples.html).\n",
    "This includes following files on public GitHub repositories:\n",
    "- `multi_agent_independent_learning.py` from the [Ray GitHub repository](https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_independent_learning.py).\n",
    "- `multi_agent_parameter_sharing.py` from the [Ray GitHub repository](https://github.com/ray-project/ray/blob/master/rllib/examples/multi_agent_parameter_sharing.py).\n",
    "- `rllib_pistonball.py` from the [Petting Zoo GitHub repository](https://github.com/Farama-Foundation/PettingZoo/blob/master/tutorials/rllib_pistonball.py).\n",
    "\n",
    "Alongside these documents and files, a tutorial by[ J K Terry on using RLlib in Petting Zoo environments](https://towardsdatascience.com/using-pettingzoo-with-rllib-for-multi-agent-deep-reinforcement-learning-5ff47c677abd) was also used.\n",
    "\n",
    "# IMPORTANT: BUGGY NOTEBOOK\n",
    "This notebook doesn't work due to issues related to the one reported [here](https://github.com/ray-project/ray/issues/22976).\n",
    "This along with the fact that working with custom Petting Zoo like environment throws random errors, left us to beleive that the Ray RL Lib is sadly not the way to go.\n",
    "\n",
    "Indeed, our model has values that are `None` which throws the following error:\n",
    "\n",
    "> Can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
    "\n",
    "Since editing the source code of Ray RL lib is asking for troubles we leave our exploration of this library as is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Contact information\n",
    "- Checking requirements\n",
    "  - Correct Anaconda environment\n",
    "  - Correct module access\n",
    "  - Correct CUDA access\n",
    "- Training Connect Four agents with Ray RLlib\n",
    "  - Trying out Ray RL lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Contact information\n",
    "\n",
    "| Name             | Student ID | VUB mail                                                  | Personal mail                                               |\n",
    "| ---------------- | ---------- | --------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Lennert Bontinck | 0568702    | [lennert.bontinck@vub.be](mailto:lennert.bontinck@vub.be) | [info@lennertbontinck.com](mailto:info@lennertbontinck.com) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a405d24",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements\n",
    "\n",
    "### Correct Anaconda environment\n",
    "\n",
    "The `rl-project` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the RL course project and homeworks](https://github.com/pikawika/vub-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: rl-project\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'rl-project'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following code block will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version (1.12.1 recommended): 1.12.1\n",
      "Torch version (1.12.0 recommended): 1.12.0.dev20220520+cu116\n",
      "Gym version (0.21.0 recommended): 0.21.0\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Allow reloading of libraries\n",
    "import importlib\n",
    "# Ray RLlib for RL algorithms instead of Tianshou\n",
    "import ray; print(f\"Ray version (1.12.1 recommended): {ray.__version__}\")\n",
    "import ray.rllib\n",
    "\n",
    "# Torch is a popular DL framework\n",
    "import torch; print(f\"Torch version (1.12.0 recommended): {torch.__version__}\")\n",
    "\n",
    "# Gym environment\n",
    "import gym; print(f\"Gym version (0.21.0 recommended): {gym.__version__}\")\n",
    "\n",
    "# Our custom connect four gym environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import gym_connect4_pygame.envs.ConnectFourPygameEnvV2 as cfgym;\n",
    "importlib.invalidate_caches();\n",
    "importlib.reload(cfgym);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617a21",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct CUDA access\n",
    "\n",
    "The installation instructions specify how to install PyTorch with CUDA 11.6.\n",
    "The following code block tests if this was done successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac22356",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Training Connect Four agents with Ray RLlib\n",
    "\n",
    "As discussed, this notebook will use Ray RLlib to train two agents for Connect four.\n",
    "\n",
    "### Trying out Ray RL lib\n",
    "\n",
    "We try out the Ray RL lib and do this on the Petting Zoo provided Connect Four game.\n",
    "Whilst the training works, the saved files cause an issue for loading and thus for replaying.\n",
    "Becuase this is a straight copy from the documentation with only the environment changed, we see no reason why it should not work and discard further experiments with this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbc9156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import ray\n",
    "from gym.spaces import Box\n",
    "from ray import tune\n",
    "from ray.rllib.agents.dqn.dqn_torch_model import DQNTorchModel\n",
    "from ray.rllib.agents.registry import get_trainer_class\n",
    "from ray.rllib.env import PettingZooEnv\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.torch_utils import FLOAT_MAX\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "\n",
    "class TorchMaskedActions(DQNTorchModel):\n",
    "    \"\"\"PyTorch version of above ParametricActionsModel.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name, **kw):\n",
    "        DQNTorchModel.__init__(\n",
    "            self, obs_space, action_space, num_outputs, model_config, name, **kw\n",
    "        )\n",
    "\n",
    "        obs_len = obs_space.shape[0] - action_space.n\n",
    "\n",
    "        orig_obs_space = Box(\n",
    "            shape=(obs_len,), low=obs_space.low[:obs_len], high=obs_space.high[:obs_len]\n",
    "        )\n",
    "        self.action_embed_model = TorchFC(\n",
    "            orig_obs_space,\n",
    "            action_space,\n",
    "            action_space.n,\n",
    "            model_config,\n",
    "            name + \"_action_embed\",\n",
    "        )\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        # Extract the available actions tensor from the observation.\n",
    "        action_mask = input_dict[\"obs\"][\"action_mask\"]\n",
    "\n",
    "        # Compute the predicted action embedding\n",
    "        action_logits, _ = self.action_embed_model(\n",
    "            {\"obs\": input_dict[\"obs\"][\"observation\"]}\n",
    "        )\n",
    "        # turns probit action mask into logit action mask\n",
    "        inf_mask = torch.clamp(torch.log(action_mask), -1e10, FLOAT_MAX)\n",
    "\n",
    "        return action_logits + inf_mask, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self.action_embed_model.value_function()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e69fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 01:43:13,188\tINFO trial_runner.py:803 -- starting DQN_leduc_holdem_99c2b_00000\n",
      "2022-06-02 01:43:13,247\tERROR syncer.py:119 -- Log sync requires rsync to be installed.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:18,248\tINFO simple_q.py:161 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,683\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,683\tWARNING env.py:40 -- Skipping env checking for this experiment\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,709\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,714\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,718\tINFO torch_policy.py:183 -- TorchPolicy (worker=1) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,732\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,736\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:23 (running for 00:00:10.78)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,760\tINFO worker_set.py:154 -- Inferred observation/action spaces from remote worker (local worker has no env): {'player_0': (Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]], [[[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]], (6, 7, 2), int8)), Discrete(7)), 'player_1': (Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,743\tINFO torch_policy.py:183 -- TorchPolicy (worker=1) running on CPU.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,835\tINFO rollout_worker.py:809 -- Generating sample batch of size 30\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,836\tINFO sampler.py:672 -- Raw obs from env: { 0: { 'player_0': { 'action_mask': np.ndarray((7,), dtype=int8, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                      'observation': np.ndarray((6, 7, 2), dtype=int8, min=0.0, max=0.0, mean=0.0)}}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,836\tINFO sampler.py:673 -- Info return from env: {0: {}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,836\tWARNING deprecation.py:46 -- DeprecationWarning: `policy_mapping_fn(agent_id)` has been deprecated. Use `policy_mapping_fn(agent_id, episode, worker, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,836\tINFO sampler.py:908 -- Preprocessed obs: np.ndarray((91,), dtype=float32, min=0.0, max=1.0, mean=0.077)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,837\tINFO sampler.py:913 -- Filtered obs: np.ndarray((91,), dtype=float32, min=0.0, max=1.0, mean=0.077)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,839\tINFO sampler.py:1143 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m { 'player_0': [ { 'data': { 'agent_id': 'player_0',\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'env_id': 0,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'info': {},\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'obs': np.ndarray((91,), dtype=float32, min=0.0, max=1.0, mean=0.077),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'prev_action': None,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                             'rnn_state': None},\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                   'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,841\tINFO sampler.py:1169 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m { 'player_0': ( np.ndarray((1,), dtype=int64, min=3.0, max=3.0, mean=3.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 [],\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 { 'action_dist_inputs': np.ndarray((1, 7), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                   'action_logp': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                   'action_prob': np.ndarray((1,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                   'q_values': np.ndarray((1, 7), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]], [[[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]], (6, 7, 2), int8)), Discrete(7)), '__env__': (Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [0 0]]], [[[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m  [[1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m   [1 1]]], (6, 7, 2), int8)), Discrete(7))}\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,785\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,790\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,793\tINFO torch_policy.py:183 -- TorchPolicy (worker=local) running on CPU.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,806\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,810\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,815\tINFO torch_policy.py:183 -- TorchPolicy (worker=local) running on CPU.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,820\tINFO rollout_worker.py:1727 -- Built policy map: {}\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,820\tINFO rollout_worker.py:1728 -- Built preprocessor map: {'player_0': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000001B92BE16580>, 'player_1': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000001B92BAFAAC0>}\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,820\tINFO rollout_worker.py:666 -- Built filter map: {'player_0': <ray.rllib.utils.filter.NoFilter object at 0x000001B92BE16520>, 'player_1': <ray.rllib.utils.filter.NoFilter object at 0x000001B92BE16880>}\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,824\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=14440)\u001b[0m 2022-06-02 01:43:23,934\tINFO replay_buffer.py:47 -- Estimated max memory usage for replay buffer is 0.03825 GB (50000.0 batches of size 1, 765 bytes each), available system memory is 17.129304064 GB\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,870\tINFO simple_list_collector.py:904 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m { 'player_0': { 'actions': np.ndarray((7,), dtype=int64, min=0.0, max=6.0, mean=4.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'agent_index': np.ndarray((7,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'dones': np.ndarray((7,), dtype=bool, min=0.0, max=1.0, mean=0.143),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'eps_id': np.ndarray((7,), dtype=int32, min=1279442517.0, max=1279442517.0, mean=1279442517.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'infos': np.ndarray((7,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'new_obs': np.ndarray((7, 91), dtype=float32, min=0.0, max=1.0, mean=0.165),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'obs': np.ndarray((7, 91), dtype=float32, min=0.0, max=1.0, mean=0.143),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'rewards': np.ndarray((7,), dtype=int32, min=-1.0, max=0.0, mean=-0.143),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'unroll_id': np.ndarray((7,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'weights': np.ndarray((7,), dtype=int32, min=1.0, max=1.0, mean=1.0)},\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m   'player_1': { 'actions': np.ndarray((7,), dtype=int64, min=0.0, max=6.0, mean=1.286),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'agent_index': np.ndarray((7,), dtype=int32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'dones': np.ndarray((7,), dtype=bool, min=0.0, max=1.0, mean=0.143),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'eps_id': np.ndarray((7,), dtype=int32, min=1279442517.0, max=1279442517.0, mean=1279442517.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'infos': np.ndarray((7,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'new_obs': np.ndarray((7, 91), dtype=float32, min=0.0, max=1.0, mean=0.174),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'obs': np.ndarray((7, 91), dtype=float32, min=0.0, max=1.0, mean=0.154),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'rewards': np.ndarray((7,), dtype=int32, min=0.0, max=1.0, mean=0.143),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'unroll_id': np.ndarray((7,), dtype=int32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                 'weights': np.ndarray((7,), dtype=int32, min=1.0, max=1.0, mean=1.0)}}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m 2022-06-02 01:43:23,914\tINFO rollout_worker.py:854 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m { 'count': 30,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m   'policy_batches': { 'player_0': { 'actions': np.ndarray((15,), dtype=int64, min=0.0, max=6.0, mean=4.067),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'agent_index': np.ndarray((15,), dtype=int32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'dones': np.ndarray((15,), dtype=bool, min=0.0, max=1.0, mean=0.133),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'eps_id': np.ndarray((15,), dtype=int32, min=915525025.0, max=1279442517.0, mean=1085353187.933),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'infos': np.ndarray((15,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'new_obs': np.ndarray((15, 91), dtype=float32, min=0.0, max=1.0, mean=0.168),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'obs': np.ndarray((15, 91), dtype=float32, min=0.0, max=1.0, mean=0.147),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'rewards': np.ndarray((15,), dtype=int32, min=-1.0, max=0.0, mean=-0.133),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'unroll_id': np.ndarray((15,), dtype=int32, min=0.0, max=2.0, mean=1.067),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'weights': np.ndarray((15,), dtype=int32, min=1.0, max=1.0, mean=1.0)},\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                       'player_1': { 'actions': np.ndarray((15,), dtype=int64, min=0.0, max=6.0, mean=2.933),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'agent_index': np.ndarray((15,), dtype=int32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'dones': np.ndarray((15,), dtype=bool, min=0.0, max=1.0, mean=0.133),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'eps_id': np.ndarray((15,), dtype=int32, min=915525025.0, max=1279442517.0, mean=1085353187.933),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'infos': np.ndarray((15,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'new_obs': np.ndarray((15, 91), dtype=float32, min=0.0, max=1.0, mean=0.177),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'obs': np.ndarray((15, 91), dtype=float32, min=0.0, max=1.0, mean=0.158),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'rewards': np.ndarray((15,), dtype=int32, min=0.0, max=1.0, mean=0.133),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'unroll_id': np.ndarray((15,), dtype=int32, min=1.0, max=3.0, mean=2.067),\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m                                     'weights': np.ndarray((15,), dtype=int32, min=1.0, max=1.0, mean=1.0)}},\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m   'type': 'MultiAgentBatch'}\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 1019\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-25\n",
      "  done: false\n",
      "  episode_len_mean: 18.196428571428573\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.16071428571428573\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 56\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 1020\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.13445331156253815\n",
      "          max_q: 0.0067716725170612335\n",
      "          mean_q: -200000000.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -200000000.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - 0.0007208258612081409\n",
      "        - -0.0011981370626017451\n",
      "        - 9.534467244520783e-05\n",
      "        - 0.001677239779382944\n",
      "        - -0.0037090308032929897\n",
      "        - -0.9948515295982361\n",
      "        - -0.0012383128050714731\n",
      "        - 0.002088987734168768\n",
      "        - -0.0006379736587405205\n",
      "        - 0.0005851619062013924\n",
      "        - -0.0010748478816822171\n",
      "        - 0.0021195202134549618\n",
      "        - 0.002088987734168768\n",
      "        - 0.002088987734168768\n",
      "        - -0.0011981370626017451\n",
      "        - 0.002088987734168768\n",
      "        - 0.00046174752060323954\n",
      "        - -0.0030384575948119164\n",
      "        - 0.00046174752060323954\n",
      "        - -0.0007951213046908379\n",
      "        - 0.0007208258612081409\n",
      "        - -0.0011666824575513601\n",
      "        - 1.000830054283142\n",
      "        - -0.9976517558097839\n",
      "        - 0.0006634178571403027\n",
      "        - 9.534467244520783e-05\n",
      "        - -0.0011981370626017451\n",
      "        - 0.0018451017094776034\n",
      "        - 0.001677239779382944\n",
      "        - -0.0010029192781075835\n",
      "        - -0.001782053615897894\n",
      "        - -0.0011981370626017451\n",
      "        - -0.0030297781340777874\n",
      "        - -0.001782053615897894\n",
      "        - -0.0012270250590518117\n",
      "        - 0.006466466002166271\n",
      "        - -0.00045943562872707844\n",
      "        - -0.000979144824668765\n",
      "        - 0.00046174752060323954\n",
      "        - 0.002088987734168768\n",
      "        - 0.001677239779382944\n",
      "        - -0.0016805260675027966\n",
      "        - -0.0030872058123350143\n",
      "        - 0.0035121897235512733\n",
      "        - -0.0030872058123350143\n",
      "        - -0.0011981370626017451\n",
      "        - -0.00048773433081805706\n",
      "        - -0.001782053615897894\n",
      "        - 0.00046174752060323954\n",
      "        - -0.0007951213046908379\n",
      "        - -0.0012383128050714731\n",
      "        - -0.00026258674915879965\n",
      "        - -0.0007951213046908379\n",
      "        - 0.001677239779382944\n",
      "        - 0.0006634178571403027\n",
      "        - 0.00046174752060323954\n",
      "        - -0.001782053615897894\n",
      "        - -0.0012383128050714731\n",
      "        - 0.0006113662384450436\n",
      "        - 0.001677239779382944\n",
      "        - -0.0011981370626017451\n",
      "        - -0.001782053615897894\n",
      "        - -0.003351204562932253\n",
      "        - 0.002088987734168768\n",
      "        - -0.00045943562872707844\n",
      "        - -0.001818016404286027\n",
      "        - 0.002088987734168768\n",
      "        - -0.008780919946730137\n",
      "        - -0.004046866670250893\n",
      "        - 0.00035796454176306725\n",
      "        - 0.00046174752060323954\n",
      "        - -0.0011981370626017451\n",
      "        - -0.0007951213046908379\n",
      "        - 1.0029950141906738\n",
      "        - 0.002088987734168768\n",
      "        - -0.0012562491465359926\n",
      "        - -0.004797806032001972\n",
      "        - -0.0011981370626017451\n",
      "        - -0.0008419840596616268\n",
      "        - -0.0012383128050714731\n",
      "        - -0.0005052455817349255\n",
      "        - 1.000830054283142\n",
      "        - 0.00046174752060323954\n",
      "        - -0.0024560694582760334\n",
      "        - -0.0011981370626017451\n",
      "        - 0.0006634178571403027\n",
      "        - 0.0011882043909281492\n",
      "        - -0.0022236662916839123\n",
      "        - -0.0005485916044563055\n",
      "        - 0.0005202079191803932\n",
      "        - -0.00045943562872707844\n",
      "        - -0.0017094614449888468\n",
      "        - 0.001096075400710106\n",
      "        - -0.0007951213046908379\n",
      "        - -10000000000.0\n",
      "        - -0.001782053615897894\n",
      "        - 0.0006150866392999887\n",
      "        - 0.00021549314260482788\n",
      "        - -0.0009493089746683836\n",
      "        - -0.001782053615897894\n",
      "        - -0.001818016404286027\n",
      "        - 1.0044001340866089\n",
      "        - -0.00017553800716996193\n",
      "        - -0.0009585110237821937\n",
      "        - -0.0017094614449888468\n",
      "        - 0.0002503114810679108\n",
      "        - 0.000936310738325119\n",
      "        - -1.3037119060754776e-05\n",
      "        - 0.000772060826420784\n",
      "        - -0.0011981370626017451\n",
      "        - 0.0007208258612081409\n",
      "        - -0.0007885661907494068\n",
      "        - -0.0012383128050714731\n",
      "        - 0.0006485905032604933\n",
      "        - 0.0009806249290704727\n",
      "        - -0.0019054103177040815\n",
      "        - -0.0035856319591403008\n",
      "        - -0.001782053615897894\n",
      "        - -0.001782053615897894\n",
      "        - 0.002088987734168768\n",
      "        - -10000000000.0\n",
      "        - -0.001782053615897894\n",
      "        - -0.00045943562872707844\n",
      "        - -0.0012383128050714731\n",
      "        - -0.001818016404286027\n",
      "        - 0.002088987734168768\n",
      "        - 0.0006634178571403027\n",
      "        - -0.0006218748167157173\n",
      "        - -0.0012383128050714731\n",
      "        - -0.9948515295982361\n",
      "        - 0.0006485905032604933\n",
      "        - -0.0016805260675027966\n",
      "        - 0.002088987734168768\n",
      "        - 0.002088987734168768\n",
      "        - 0.0012017919216305017\n",
      "        - -0.9991430640220642\n",
      "        - 0.0011715890141204\n",
      "        - 0.0006485905032604933\n",
      "        - 0.0009192348225042224\n",
      "        - 0.0007200227119028568\n",
      "        - -0.0024560694582760334\n",
      "        - -0.0012383128050714731\n",
      "        - 0.000772060826420784\n",
      "        - 0.0006634178571403027\n",
      "        - -0.0006379736587405205\n",
      "        - -0.00016174843767657876\n",
      "        - 0.0009475282859057188\n",
      "        - -0.0032862434163689613\n",
      "        - -1.3037119060754776e-05\n",
      "        - 0.000936310738325119\n",
      "        - -0.0012383128050714731\n",
      "        - -0.0012562491465359926\n",
      "        - -10000000000.0\n",
      "        - 0.002088987734168768\n",
      "        - -0.002416594186797738\n",
      "        - 0.0009806249290704727\n",
      "        - -0.001782053615897894\n",
      "        - 0.00046174752060323954\n",
      "        - -0.001782053615897894\n",
      "        - -0.0008007879368960857\n",
      "        - 1.0019563436508179\n",
      "        - 0.0005813422612845898\n",
      "        - -8.035438077058643e-05\n",
      "        - -0.0009585110237821937\n",
      "        - 0.002088987734168768\n",
      "        - 0.001677239779382944\n",
      "        - -0.0011981370626017451\n",
      "        - 0.0006634178571403027\n",
      "        - 0.004488810896873474\n",
      "        - -0.0011981370626017451\n",
      "        - -0.0012383128050714731\n",
      "        - 0.0006634178571403027\n",
      "        - -0.0010029192781075835\n",
      "        - -0.001782053615897894\n",
      "        - -0.0011981370626017451\n",
      "        - -0.001782053615897894\n",
      "        - -0.0012383128050714731\n",
      "        - 0.0003487146459519863\n",
      "        - -0.001782053615897894\n",
      "        - -0.001818016404286027\n",
      "        - -0.0011981370626017451\n",
      "        - -0.0036141173914074898\n",
      "        - 0.002088987734168768\n",
      "        - -0.0012383128050714731\n",
      "        - 0.0005095500964671373\n",
      "        - -0.0011981370626017451\n",
      "        - 0.0012017919216305017\n",
      "        - 0.0006634178571403027\n",
      "        - -0.9950024485588074\n",
      "        - 0.001677239779382944\n",
      "        - -10000000000.0\n",
      "        - 0.0011882043909281492\n",
      "        - -0.001782053615897894\n",
      "        - -0.9982950091362\n",
      "        - 0.00018903892487287521\n",
      "        - -0.0011981370626017451\n",
      "        - -0.00124063971452415\n",
      "        - -8.035438077058643e-05\n",
      "        - -0.0011981368297711015\n",
      "        - 0.0007208262104541063\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.1657770574092865\n",
      "          max_q: 0.00699359318241477\n",
      "          mean_q: 0.0018885427853092551\n",
      "          min_q: -0.003949393052607775\n",
      "        mean_td_error: -0.01000459399074316\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -0.0005371373845264316\n",
      "        - 0.0015376495430245996\n",
      "        - -0.0010943756205961108\n",
      "        - 0.0005799990613013506\n",
      "        - -0.00149110471829772\n",
      "        - -0.0007641297415830195\n",
      "        - -0.0004565166309475899\n",
      "        - 0.0007371196988970041\n",
      "        - 1.0031956434249878\n",
      "        - 1.0038528442382812\n",
      "        - 0.0004217530367895961\n",
      "        - -0.0008474626811221242\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0007641297415830195\n",
      "        - 0.0006036300910636783\n",
      "        - 0.00032911321613937616\n",
      "        - -0.0008692150004208088\n",
      "        - -0.996389627456665\n",
      "        - 1.3719312846660614e-05\n",
      "        - 1.3719312846660614e-05\n",
      "        - 1.0035231113433838\n",
      "        - 0.001201182953082025\n",
      "        - -0.0002833541948348284\n",
      "        - 1.000586986541748\n",
      "        - -0.0008692150004208088\n",
      "        - -0.0010943756205961108\n",
      "        - -0.0005752516444772482\n",
      "        - -0.0010985024273395538\n",
      "        - 0.0004217530367895961\n",
      "        - -0.0010985024273395538\n",
      "        - 1.002057671546936\n",
      "        - 0.0013957696501165628\n",
      "        - -0.0008474626811221242\n",
      "        - 0.002685629529878497\n",
      "        - -0.0006190770654939115\n",
      "        - -0.003690452082082629\n",
      "        - -0.0026083500124514103\n",
      "        - 0.00029842997901141644\n",
      "        - -0.0010943756205961108\n",
      "        - -0.0010943756205961108\n",
      "        - -0.00047845556400716305\n",
      "        - 0.0004978710785508156\n",
      "        - -0.0003959129098802805\n",
      "        - -0.0015677069313824177\n",
      "        - 0.0013743606396019459\n",
      "        - -0.0005168905481696129\n",
      "        - -0.0006494536064565182\n",
      "        - 0.0013743606396019459\n",
      "        - -0.9974135756492615\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.0006565064541064203\n",
      "        - 0.0004217530367895961\n",
      "        - -0.00025243358686566353\n",
      "        - -0.996389627456665\n",
      "        - 0.0006684074178338051\n",
      "        - -0.00031743012368679047\n",
      "        - -0.00019037770107388496\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0011565638706088066\n",
      "        - 0.0013743606396019459\n",
      "        - -0.9967103600502014\n",
      "        - -0.0019369754008948803\n",
      "        - 0.0003715518396347761\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0010943756205961108\n",
      "        - -0.00047845556400716305\n",
      "        - -0.00018500408623367548\n",
      "        - -0.003713427111506462\n",
      "        - -0.001638754503801465\n",
      "        - 0.0010899013141170144\n",
      "        - -0.004659463185817003\n",
      "        - -0.000537222484126687\n",
      "        - 1.000586986541748\n",
      "        - -0.0003690938465297222\n",
      "        - -0.0009439014829695225\n",
      "        - -0.006234601140022278\n",
      "        - 0.0013482802314683795\n",
      "        - -0.00016990234144032001\n",
      "        - -0.00044694123789668083\n",
      "        - -0.003713427111506462\n",
      "        - -0.995802640914917\n",
      "        - -0.0010514520108699799\n",
      "        - 0.0005029907915741205\n",
      "        - 0.0003334998618811369\n",
      "        - -0.0022282670252025127\n",
      "        - -0.9953985810279846\n",
      "        - -0.0018355278298258781\n",
      "        - -0.0009745592251420021\n",
      "        - -0.00047845556400716305\n",
      "        - -0.0018971167737618089\n",
      "        - -0.0002833541948348284\n",
      "        - -0.0005168905481696129\n",
      "        - 1.0035231113433838\n",
      "        - -0.99553382396698\n",
      "        - 0.0013743606396019459\n",
      "        - -1.0004451274871826\n",
      "        - 0.0013743606396019459\n",
      "        - -0.00016990234144032001\n",
      "        - 0.0013743606396019459\n",
      "        - 0.00016100797802209854\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.0013957696501165628\n",
      "        - 0.0003669699653983116\n",
      "        - 0.0008173040114343166\n",
      "        - 0.0008173040114343166\n",
      "        - -0.0033628717064857483\n",
      "        - -0.0010985024273395538\n",
      "        - 0.0004217530367895961\n",
      "        - 1.0016616582870483\n",
      "        - 0.002685629529878497\n",
      "        - 0.0013743606396019459\n",
      "        - -0.001638754503801465\n",
      "        - -0.0019369754008948803\n",
      "        - 0.0013743606396019459\n",
      "        - 0.0004217530367895961\n",
      "        - 0.0013743606396019459\n",
      "        - -0.9982996582984924\n",
      "        - 0.0004056933685205877\n",
      "        - -0.0010943756205961108\n",
      "        - 1.0031309127807617\n",
      "        - -0.00013788673095405102\n",
      "        - 0.0013957696501165628\n",
      "        - 0.002668558619916439\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0006274529732763767\n",
      "        - 0.0010417962912470102\n",
      "        - -0.0008254599524661899\n",
      "        - -0.0016795250121504068\n",
      "        - -0.0064439778216183186\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.0004217530367895961\n",
      "        - -0.9930064082145691\n",
      "        - -0.00016990234144032001\n",
      "        - -0.0003345124423503876\n",
      "        - 1.3719312846660614e-05\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.00016990234144032001\n",
      "        - -9.86733939498663e-05\n",
      "        - 0.00032911321613937616\n",
      "        - -0.00012753007467836142\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.9982996582984924\n",
      "        - -0.0005620555020868778\n",
      "        - -0.005056664347648621\n",
      "        - -0.0015516270650550723\n",
      "        - -0.0011808860581368208\n",
      "        - 2.5995075702667236e-05\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.001124451868236065\n",
      "        - 0.001124451868236065\n",
      "        - 1.000586986541748\n",
      "        - -0.0007409385871142149\n",
      "        - 0.0013743606396019459\n",
      "        - -0.00016990234144032001\n",
      "        - 0.00032911321613937616\n",
      "        - -0.00013788673095405102\n",
      "        - -0.0008702351478859782\n",
      "        - 0.0009978348389267921\n",
      "        - -0.0018971167737618089\n",
      "        - -0.0005752516444772482\n",
      "        - -0.0010943756205961108\n",
      "        - -0.0010943756205961108\n",
      "        - -0.0010943756205961108\n",
      "        - 0.0013743606396019459\n",
      "        - 0.0013743606396019459\n",
      "        - -0.00028949626721441746\n",
      "        - -0.0008474626811221242\n",
      "        - -0.004684643819928169\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.0004217530367895961\n",
      "        - -0.0004958049394190311\n",
      "        - -0.0004029946867376566\n",
      "        - -0.0064439778216183186\n",
      "        - -0.0005752516444772482\n",
      "        - 0.0013743606396019459\n",
      "        - 3.455369733273983e-05\n",
      "        - 0.0004217530367895961\n",
      "        - -0.0003690938465297222\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0019369754008948803\n",
      "        - 0.0004217530367895961\n",
      "        - -0.0008702351478859782\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0022282670252025127\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0005752516444772482\n",
      "        - 0.0007371196988970041\n",
      "        - -0.001391178579069674\n",
      "        - -0.0002833541948348284\n",
      "        - -0.9972899556159973\n",
      "        - 0.0013743606396019459\n",
      "        - 0.003266722895205021\n",
      "        - 1.3719312846660614e-05\n",
      "        - 0.0013743606396019459\n",
      "        - 1.3719312846660614e-05\n",
      "        - -0.0005752516444772482\n",
      "        - -0.0006634911987930536\n",
      "        - 0.0004217530367895961\n",
      "        - -0.00016990245785564184\n",
      "        - -0.0008474630303680897\n",
      "    num_agent_steps_sampled: 1019\n",
      "    num_agent_steps_trained: 400\n",
      "    num_steps_sampled: 1020\n",
      "    num_steps_trained: 200\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.13333333333333\n",
      "    ram_util_percent: 63.73333333333333\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.17857142857142858\n",
      "    player_1: 0.017857142857142856\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06267092720651955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.18212120399886086\n",
      "    mean_inference_ms: 1.162703894261165\n",
      "    mean_raw_obs_processing_ms: 0.18210228930257563\n",
      "  time_since_restore: 1.940171241760254\n",
      "  time_this_iter_s: 1.940171241760254\n",
      "  time_total_s: 1.940171241760254\n",
      "  timers:\n",
      "    learn_throughput: 10002.633\n",
      "    learn_time_ms: 19.995\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    update_time_ms: 0.999\n",
      "  timestamp: 1654127005\n",
      "  timesteps_since_restore: 200\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 1020\n",
      "  training_iteration: 1\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:25 (running for 00:00:12.85)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.94017</td><td style=\"text-align: right;\">1020</td><td style=\"text-align: right;\">-0.160714</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">           18.1964</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 1889\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 11.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.03\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 143\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 1530\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0015086865751072764\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0012181898346170783\n",
      "          max_q: 0.006708851084113121\n",
      "          mean_q: -9949998080.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9949998080.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -0.010988345369696617\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "    num_agent_steps_sampled: 1889\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 1890\n",
      "    num_steps_trained: 6000\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 2\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf: {}\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.45\n",
      "    player_1: 0.42\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06262646668346614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.18089128121769277\n",
      "    mean_inference_ms: 1.1790726776994134\n",
      "    mean_raw_obs_processing_ms: 0.1977575296756545\n",
      "  time_since_restore: 5.507389307022095\n",
      "  time_this_iter_s: 0.12296032905578613\n",
      "  time_total_s: 5.507389307022095\n",
      "  timers:\n",
      "    learn_throughput: 10585.195\n",
      "    learn_time_ms: 18.894\n",
      "    load_throughput: 399971.773\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.799\n",
      "  timestamp: 1654127010\n",
      "  timesteps_since_restore: 6000\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 1890\n",
      "  training_iteration: 30\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:31 (running for 00:00:17.94)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         5.50739</td><td style=\"text-align: right;\">1890</td><td style=\"text-align: right;\">   -0.03</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">             11.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 2759\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 10.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.01\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 232\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 2550\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0017396074254065752\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.00136081431992352\n",
      "          max_q: 0.03263407573103905\n",
      "          mean_q: -9949998080.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9949998080.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -0.001248534768819809\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "    num_agent_steps_sampled: 2759\n",
      "    num_agent_steps_trained: 23600\n",
      "    num_steps_sampled: 2760\n",
      "    num_steps_trained: 11800\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.2\n",
      "    ram_util_percent: 63.8\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.5\n",
      "    player_1: 0.49\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06087746227681744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.17971631085711992\n",
      "    mean_inference_ms: 1.21435964529729\n",
      "    mean_raw_obs_processing_ms: 0.2046631743485157\n",
      "  time_since_restore: 9.031316041946411\n",
      "  time_this_iter_s: 0.12196087837219238\n",
      "  time_total_s: 9.031316041946411\n",
      "  timers:\n",
      "    learn_throughput: 10641.512\n",
      "    learn_time_ms: 18.794\n",
      "    load_throughput: 400009.918\n",
      "    load_time_ms: 0.5\n",
      "    update_time_ms: 1.799\n",
      "  timestamp: 1654127016\n",
      "  timesteps_since_restore: 11800\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 2760\n",
      "  training_iteration: 59\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:36 (running for 00:00:23.12)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         9.03132</td><td style=\"text-align: right;\">2760</td><td style=\"text-align: right;\">   -0.01</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">                10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 3659\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-41\n",
      "  done: false\n",
      "  episode_len_mean: 12.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.08\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 303\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 3570\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0021177916787564754\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0016700089909136295\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "    num_agent_steps_sampled: 3659\n",
      "    num_agent_steps_trained: 35600\n",
      "    num_steps_sampled: 3660\n",
      "    num_steps_trained: 17800\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 6\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf: {}\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.48\n",
      "    player_1: 0.4\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05949621490742521\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.18024667701736286\n",
      "    mean_inference_ms: 1.2138319845125534\n",
      "    mean_raw_obs_processing_ms: 0.20333932246292782\n",
      "  time_since_restore: 12.558895111083984\n",
      "  time_this_iter_s: 0.12396049499511719\n",
      "  time_total_s: 12.558895111083984\n",
      "  timers:\n",
      "    learn_throughput: 10585.275\n",
      "    learn_time_ms: 18.894\n",
      "    load_throughput: 666927.015\n",
      "    load_time_ms: 0.3\n",
      "    update_time_ms: 1.899\n",
      "  timestamp: 1654127021\n",
      "  timesteps_since_restore: 17800\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 3660\n",
      "  training_iteration: 89\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:41 (running for 00:00:28.20)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         12.5589</td><td style=\"text-align: right;\">3660</td><td style=\"text-align: right;\">   -0.08</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">             12.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:46 (running for 00:00:33.30)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>RUNNING </td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         15.9737</td><td style=\"text-align: right;\">4560</td><td style=\"text-align: right;\">   -0.09</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">             12.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 4589\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-46\n",
      "  done: false\n",
      "  episode_len_mean: 12.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.09\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 376\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 4590\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.002683277241885662\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.002124871825799346\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "    num_agent_steps_sampled: 4589\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_steps_sampled: 4590\n",
      "    num_steps_trained: 24000\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf: {}\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.59\n",
      "    player_1: 0.5\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.058508418044340066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.17847291980214808\n",
      "    mean_inference_ms: 1.1973196703482956\n",
      "    mean_raw_obs_processing_ms: 0.20188928675075998\n",
      "  time_since_restore: 16.090643167495728\n",
      "  time_this_iter_s: 0.11696124076843262\n",
      "  time_total_s: 16.090643167495728\n",
      "  timers:\n",
      "    learn_throughput: 11176.778\n",
      "    learn_time_ms: 17.894\n",
      "    load_throughput: 333357.495\n",
      "    load_time_ms: 0.6\n",
      "    update_time_ms: 1.9\n",
      "  timestamp: 1654127026\n",
      "  timesteps_since_restore: 24000\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 4590\n",
      "  training_iteration: 120\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m [WARNING]: Illegal move made, game terminating with current player losing. \n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=2128)\u001b[0m obs['action_mask'] contains a mask of all legal moves that can be chosen.\n",
      "Result for DQN_leduc_holdem_99c2b_00000:\n",
      "  agent_timesteps_total: 5009\n",
      "  custom_metrics: {}\n",
      "  date: 2022-06-02_01-43-48\n",
      "  done: true\n",
      "  episode_len_mean: 13.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: -0.07\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 407\n",
      "  experiment_id: 20d2d93e401548a1937e1ffd4fd1c320\n",
      "  hostname: GAMING-LENNERT\n",
      "  info:\n",
      "    last_target_update_ts: 4590\n",
      "    learner:\n",
      "      player_0:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0029454275500029325\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "      player_1:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          cur_lr: 0.0001\n",
      "          grad_gnorm: 0.0023539091926068068\n",
      "          max_q: -10000000000.0\n",
      "          mean_q: -9999997952.0\n",
      "          min_q: -10000000000.0\n",
      "        mean_td_error: -9999997952.0\n",
      "        model: {}\n",
      "        num_agent_steps_trained: 200.0\n",
      "        td_error:\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "        - -10000000000.0\n",
      "    num_agent_steps_sampled: 5009\n",
      "    num_agent_steps_trained: 53600\n",
      "    num_steps_sampled: 5010\n",
      "    num_steps_trained: 26800\n",
      "    num_steps_trained_this_iter: 200\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.5\n",
      "    ram_util_percent: 64.1\n",
      "  pid: 14440\n",
      "  policy_reward_max:\n",
      "    player_0: 1.0\n",
      "    player_1: 1.0\n",
      "  policy_reward_mean:\n",
      "    player_0: -0.52\n",
      "    player_1: 0.45\n",
      "  policy_reward_min:\n",
      "    player_0: -1.0\n",
      "    player_1: -1.0\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05768046438520657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.17820019097507234\n",
      "    mean_inference_ms: 1.1928081447523309\n",
      "    mean_raw_obs_processing_ms: 0.20013911322891292\n",
      "  time_since_restore: 17.788100957870483\n",
      "  time_this_iter_s: 0.11596250534057617\n",
      "  time_total_s: 17.788100957870483\n",
      "  timers:\n",
      "    learn_throughput: 10641.539\n",
      "    learn_time_ms: 18.794\n",
      "    load_throughput: 1000072.485\n",
      "    load_time_ms: 0.2\n",
      "    update_time_ms: 1.799\n",
      "  timestamp: 1654127028\n",
      "  timesteps_since_restore: 26800\n",
      "  timesteps_this_iter: 200\n",
      "  timesteps_total: 5010\n",
      "  training_iteration: 134\n",
      "  trial_id: 99c2b_00000\n",
      "  warmup_time: 5.621232032775879\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-06-02 01:43:49 (running for 00:00:35.97)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/3.89 GiB heap, 0.0/1.95 GiB objects<br>Result logdir: C:\\Users\\Lennert\\ray_results\\DQN<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_leduc_holdem_99c2b_00000</td><td>TERMINATED</td><td>127.0.0.1:14440</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         17.7881</td><td style=\"text-align: right;\">5010</td><td style=\"text-align: right;\">   -0.07</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">             13.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 01:43:49,565\tINFO tune.py:701 -- Total run time: 36.66 seconds (35.87 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-06-02 01:43:49,592\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\ProgramData\\Anaconda3\\envs\\rl-project\\python.exe\" C:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=62406 --object-store-name=tcp://127.0.0.1:63755 --raylet-name=tcp://127.0.0.1:63206 --redis-address=None --storage=None --temp-dir=C:\\Users\\Lennert\\AppData\\Local\\Temp\\ray --metrics-agent-port=63722 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:64969 --redis-password=5241590000000000 --startup-token=3 --runtime-env-hash=947844633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x2d68ef473a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg_name = \"DQN\"\n",
    "ModelCatalog.register_custom_model(\"pa_model\", TorchMaskedActions)\n",
    "# function that outputs the environment you wish to register.\n",
    "\n",
    "my_env = cfgym.env()\n",
    "\n",
    "def env_creator():\n",
    "    env = connect_four_v3.env()\n",
    "    return env\n",
    "\n",
    "num_cpus = 1\n",
    "\n",
    "config = deepcopy(get_trainer_class(alg_name)._default_config)\n",
    "\n",
    "register_env(\"leduc_holdem\", lambda config: PettingZooEnv(env_creator()))\n",
    "\n",
    "test_env = PettingZooEnv(env_creator())\n",
    "obs_space = test_env.observation_space\n",
    "print(obs_space)\n",
    "act_space = test_env.action_space\n",
    "\n",
    "config[\"multiagent\"] = {\n",
    "    \"policies\": {\n",
    "        \"player_0\": (None, obs_space, act_space, {}),\n",
    "        \"player_1\": (None, obs_space, act_space, {}),\n",
    "    },\n",
    "    \"policy_mapping_fn\": lambda agent_id: agent_id,\n",
    "}\n",
    "\n",
    "config[\"num_gpus\"] = int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\"))\n",
    "config[\"log_level\"] = \"INFO\"\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"rollout_fragment_length\"] = 30\n",
    "config[\"train_batch_size\"] = 200\n",
    "config[\"horizon\"] = 200\n",
    "config[\"no_done_at_end\"] = False\n",
    "config[\"framework\"] = \"torch\"\n",
    "config[\"model\"] = {\n",
    "    \"custom_model\": \"pa_model\",\n",
    "}\n",
    "config[\"n_step\"] = 1\n",
    "\n",
    "config[\"exploration_config\"] = {\n",
    "    # The Exploration class to use.\n",
    "    \"type\": \"EpsilonGreedy\",\n",
    "    # Config for the Exploration class' constructor:\n",
    "    \"initial_epsilon\": 0.1,\n",
    "    \"final_epsilon\": 0.0,\n",
    "    \"epsilon_timesteps\": 100000,  # Timesteps over which to anneal epsilon.\n",
    "}\n",
    "config[\"hiddens\"] = []\n",
    "config[\"dueling\"] = False\n",
    "config[\"env\"] = \"leduc_holdem\"\n",
    "\n",
    "ray.init(num_cpus=num_cpus + 1)\n",
    "\n",
    "tune.run(\n",
    "    alg_name,\n",
    "    name=\"DQN\",\n",
    "    stop={\"timesteps_total\": 5000},\n",
    "    checkpoint_freq=10,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62207afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 01:43:49,712\tINFO simple_q.py:161 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "2022-06-02 01:43:49,717\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "2022-06-02 01:43:49,718\tWARNING env.py:40 -- Skipping env checking for this experiment\n",
      "2022-06-02 01:43:49,750\tDEBUG rollout_worker.py:1704 -- Creating policy for player_0\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m 2022-06-02 01:43:49,624\tINFO context.py:67 -- Exec'ing worker with command: \"C:\\ProgramData\\Anaconda3\\envs\\rl-project\\python.exe\" C:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\workers/default_worker.py --node-ip-address=127.0.0.1 --node-manager-port=62406 --object-store-name=tcp://127.0.0.1:63755 --raylet-name=tcp://127.0.0.1:63206 --redis-address=None --storage=None --temp-dir=C:\\Users\\Lennert\\AppData\\Local\\Temp\\ray --metrics-agent-port=63722 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=127.0.0.1:64969 --redis-password=5241590000000000 --startup-token=2 --runtime-env-hash=947844633\n",
      "2022-06-02 01:43:49,751\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8)\n",
      "2022-06-02 01:43:49,753\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8)\n",
      "2022-06-02 01:43:49,756\tDEBUG catalog.py:805 -- Created preprocessor <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000002D68F01C1F0>: Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8)) -> (91,)\n",
      "2022-06-02 01:43:49,759\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "2022-06-02 01:43:49,766\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "2022-06-02 01:43:49,771\tINFO torch_policy.py:183 -- TorchPolicy (worker=local) running on CPU.\n",
      "2022-06-02 01:43:49,775\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8)\n",
      "2022-06-02 01:43:49,777\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8)\n",
      "2022-06-02 01:43:49,783\tDEBUG rollout_worker.py:1704 -- Creating policy for player_1\n",
      "2022-06-02 01:43:49,786\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8)\n",
      "2022-06-02 01:43:49,788\tDEBUG preprocessors.py:269 -- Creating sub-preprocessor for Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8)\n",
      "2022-06-02 01:43:49,791\tDEBUG catalog.py:805 -- Created preprocessor <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000002D68F011760>: Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]\n",
      "  [0 0]]], [[[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]\n",
      "  [1 1]]], (6, 7, 2), int8)) -> (91,)\n",
      "2022-06-02 01:43:49,793\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "2022-06-02 01:43:49,798\tINFO catalog.py:474 -- Wrapping <class '__main__.TorchMaskedActions'> as <class 'ray.rllib.agents.dqn.dqn_torch_model.DQNTorchModel'>\n",
      "2022-06-02 01:43:49,802\tINFO torch_policy.py:183 -- TorchPolicy (worker=local) running on CPU.\n",
      "2022-06-02 01:43:49,808\tINFO rollout_worker.py:1727 -- Built policy map: {}\n",
      "2022-06-02 01:43:49,808\tINFO rollout_worker.py:1728 -- Built preprocessor map: {'player_0': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000002D68F01C1F0>, 'player_1': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x000002D68F011760>}\n",
      "2022-06-02 01:43:49,809\tINFO rollout_worker.py:666 -- Built filter map: {'player_0': <ray.rllib.utils.filter.NoFilter object at 0x000002D68F05AEE0>, 'player_1': <ray.rllib.utils.filter.NoFilter object at 0x000002D68F125CD0>}\n",
      "2022-06-02 01:43:49,811\tDEBUG rollout_worker.py:779 -- Created rollout worker with env <ray.rllib.env.multi_agent_env.MultiAgentEnvWrapper object at 0x000002D68F05AEB0> (<PettingZooEnv instance>), policies {}\n",
      "2022-06-02 01:43:49,814\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#ray.init(num_cpus=8, num_gpus=0)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m DQNAgent \u001b[38;5;241m=\u001b[39m DQNTrainer(env\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleduc_holdem\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mDQNAgent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m reward_sums \u001b[38;5;241m=\u001b[39m {a: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39mpossible_agents}\n\u001b[0;32m     58\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\tune\\trainable.py:529\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_checkpoint(checkpoint_dict)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py:2033\u001b[0m, in \u001b[0;36mTrainer.load_checkpoint\u001b[1;34m(self, checkpoint_path)\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;129m@override\u001b[39m(Trainable)\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2032\u001b[0m     extra_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 2033\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py:2675\u001b[0m, in \u001b[0;36mTrainer.__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   2674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[1;32m-> 2675\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2676\u001b[0m         remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   2677\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\evaluation\\rollout_worker.py:1496\u001b[0m, in \u001b[0;36mRolloutWorker.restore\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m   1488\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[0;32m   1489\u001b[0m             policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[0;32m   1490\u001b[0m             policy_cls\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m             config\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[0;32m   1494\u001b[0m         )\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\policy\\torch_policy.py:759\u001b[0m, in \u001b[0;36mTorchPolicy.set_state\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[1;32m--> 759\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_torch_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m         o\u001b[38;5;241m.\u001b[39mload_state_dict(optim_state_dict)\n\u001b[0;32m    761\u001b[0m \u001b[38;5;66;03m# Set exploration's state.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\utils\\torch_utils.py:167\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor\u001b[1;34m(x, device)\u001b[0m\n\u001b[0;32m    164\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\tree\\__init__.py:430\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m--> 430\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\tree\\__init__.py:430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m--> 430\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\ray\\rllib\\utils\\torch_utils.py:161\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor.<locals>.mapping\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m    158\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Everything else: Convert to numpy, then wrap as torch tensor.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Floatify all float64 tensors.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdouble:\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import PIL\n",
    "import ray\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "from ray.rllib.agents.registry import get_trainer_class\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.expanduser(\"C:/Users/Lennert/ray_results/DQN/DQN_leduc_holdem_63720_00000_0_2022-05-26_15-04-34/checkpoint_000130/checkpoint-130\")\n",
    "params_path = Path(checkpoint_path).parent.parent / \"params.pkl\"\n",
    "\n",
    "\n",
    "alg_name = \"DQN\"\n",
    "ModelCatalog.register_custom_model(\"pa_model\", TorchMaskedActions)\n",
    "# function that outputs the environment you wish to register.\n",
    "\n",
    "\n",
    "def env_creator():\n",
    "    env = connect_four_v3.env()\n",
    "    return env\n",
    "\n",
    "\n",
    "num_cpus = 1\n",
    "\n",
    "config = deepcopy(get_trainer_class(alg_name)._default_config)\n",
    "\n",
    "register_env(\"leduc_holdem\", lambda config: PettingZooEnv(env_creator()))\n",
    "\n",
    "env = env_creator()\n",
    "# obs_space = env.observation_space\n",
    "# print(obs_space)\n",
    "# act_space = test_env.action_space\n",
    "\n",
    "with open(params_path, \"rb\") as f:\n",
    "    config = pickle.load(f)\n",
    "    # num_workers not needed since we are not training\n",
    "    del config[\"num_workers\"]\n",
    "    del config[\"num_gpus\"]\n",
    "\n",
    "#ray.init(num_cpus=8, num_gpus=0)\n",
    "DQNAgent = DQNTrainer(env=\"leduc_holdem\", config=config)\n",
    "DQNAgent.restore(checkpoint_path)\n",
    "\n",
    "reward_sums = {a: 0 for a in env.possible_agents}\n",
    "i = 0\n",
    "env.reset()\n",
    "\n",
    "for agent in env.agent_iter():\n",
    "    observation, reward, done, info = env.last()\n",
    "    obs = observation[\"observation\"]\n",
    "    reward_sums[agent] += reward\n",
    "    if done:\n",
    "        action = None\n",
    "    else:\n",
    "        print(DQNAgent.get_policy(agent))\n",
    "        policy = DQNAgent.get_policy(agent)\n",
    "        batch_obs = {\n",
    "            \"obs\": {\n",
    "                \"observation\": np.expand_dims(observation[\"observation\"], 0),\n",
    "                \"action_mask\": np.expand_dims(observation[\"action_mask\"], 0),\n",
    "            }\n",
    "        }\n",
    "        batched_action, state_out, info = policy.compute_actions_from_input_dict(\n",
    "            batch_obs\n",
    "        )\n",
    "        single_action = batched_action[0]\n",
    "        action = single_action\n",
    "\n",
    "    env.step(action)\n",
    "    i += 1\n",
    "    env.render()\n",
    "\n",
    "print(\"rewards:\")\n",
    "print(reward_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c15f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b88c88564fefe7444548986d165ad8d7f764d0079ffa923785a3f5a89d52c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
