{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Testing custom Gym environment\n",
    "\n",
    "This experimental notebook checks if the custom Gym environment is set up correctly by running some checks and some basic sample Gym code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- Contact information\n",
    "- Checking requirements\n",
    "  - Correct anaconda environment\n",
    "  - Correct module access\n",
    "- Testing connect four Gym setup\n",
    "  - Connect four with random agent\n",
    "    - Setting up the gym environment\n",
    "    - Interacting with the environment\n",
    "    - Visualising the environment in terminal\n",
    "    - Letting random agent play the game in terminal\n",
    "    - Visualising the environment in human mode\n",
    "    - Letting random agent play the game in human mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Contact information\n",
    "\n",
    "| Name             | Student ID | VUB mail                                                  | Personal mail                                               |\n",
    "| ---------------- | ---------- | --------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Lennert Bontinck | 0568702    | [lennert.bontinck@vub.be](mailto:lennert.bontinck@vub.be) | [info@lennertbontinck.com](mailto:info@lennertbontinck.com) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d16573",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements\n",
    "\n",
    "### Correct anaconda environment\n",
    "\n",
    "The `rl-project` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the RL course project and homeworks](https://github.com/pikawika/vub-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: rl-project\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'rl-project'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following codeblock will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version (3.5.1 recommended): 3.5.1\n",
      "Pygame version (2.1.2 recommended): 2.1.2\n",
      "Gym version (0.21.0 recommended): 0.21.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Allow reloading of libraries\n",
    "import importlib\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pygame\n",
    "import pygame; print(f\"Pygame version (2.1.2 recommended): {pygame.__version__}\")\n",
    "\n",
    "# Gym environment\n",
    "import gym; print(f\"Gym version (0.21.0 recommended): {gym.__version__}\")\n",
    "\n",
    "# Our custom connect four gym environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import gym_connect4_pygame\n",
    "importlib.invalidate_caches()\n",
    "importlib.reload(gym_connect4_pygame)\n",
    "\n",
    "# Time for allowing \"freezes\" in execution\n",
    "import time;\n",
    "\n",
    "# Used for updating notebook display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a5b20",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Testing connect four Gym setup\n",
    "\n",
    "### Connect four with random agent\n",
    "\n",
    "We start by creating an instance of the mountain car environment and analysing some of its properties.\n",
    "This is based on the documentation from the [Gym tutorials](https://www.gymlibrary.ml/content/tutorials/), [this one](https://blog.paperspace.com/getting-started-with-openai-gym/) in particular as well as the [mountain car documentation](https://www.gymlibrary.ml/environments/classic_control/mountain_car/).\n",
    "\n",
    "#### Setting up the gym environment\n",
    "\n",
    "The `observation_space` defines the structure as well as the legitimate values for the observation of the state of the environment.\n",
    "The observation can be different things for different environments.\n",
    "The most common form is a screenshot of the game.\n",
    "There can be other forms of observations as well, such as certain characteristics of the environment described in vector form.\n",
    "- The observation for the mountain car environment is a vector of two numbers:\n",
    "  - Position of the car along the x-axis\n",
    "  - Velocity of the car\n",
    "\n",
    "- The middle point between the two mountains is taken to be the origin, with right being the positive direction and left being the negative direction.\n",
    "\n",
    "Similarly, the `Env` class also defines an attribute called the `action_space`, which describes the numerical structure of the legitimate actions that can be applied to the environment.\n",
    "- We have three discrete actions:\n",
    "  - 0: Accelerate to the left\n",
    "  - 1: Don't accelerate\n",
    "  - 2: Accelerate to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb820ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Dict(board:Box([[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]], [[2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]], (6, 7), int32))\n",
      "\n",
      "Action space: Discrete(7)\n",
      "\n",
      " Initial observation:\n",
      "{'board': array([[0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# SETTING UP THE GYM ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Create an instance of the environment to be used\n",
    "env = gym.make('lennert_bontinck/ConnectFour-v1')\n",
    "\n",
    "# Get information about the environment\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"\\nAction space: {env.action_space}\")\n",
    "\n",
    "# Reset the environment to start from a clean state, returns the initial observation\n",
    "observation = env.reset()\n",
    "print(\"\\n Initial observation:\")\n",
    "print(observation)\n",
    "\n",
    "# Clean unused variables\n",
    "del observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39bebf",
   "metadata": {},
   "source": [
    "#### Interacting with the environment\n",
    "\n",
    "Next, let's interact with the created environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82416039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After taking action 0, the new observation of the board is: \n",
      " [[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "This resulted in a reward of 0 and a False done state\n",
      "\n",
      "Other information given is: {'current_player': 2}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# INTERACTING WITH THE ENNVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Place coin in the first column:\n",
    "action = 0\n",
    "\n",
    "# Take the action and get the new observation space\n",
    "new_observation, reward, done, info = env.step(action)\n",
    "print(f\"After taking action {action}, the new observation of the board is: \\n {new_observation['board']}\")\n",
    "print(f\"\\nThis resulted in a reward of {reward} and a {done} done state\")\n",
    "print(f\"\\nOther information given is: {info}\")\n",
    "\n",
    "# Clean unused variables\n",
    "del new_observation\n",
    "del reward\n",
    "del done\n",
    "del info\n",
    "del action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c823d0",
   "metadata": {},
   "source": [
    "#### Visualising the environment in terminal\n",
    "\n",
    "Let's now try to visualize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac78a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# VISUALISING THE ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Visualise the environment by printing to the terminal\n",
    "env.render(mode = 'terminal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b423e",
   "metadata": {},
   "source": [
    "#### Letting random agent play the game in terminal\n",
    "\n",
    "Let two agents play a combined total of 200 moves at random in the game and visualise it by updating the terminal continously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce3f07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed a move, new board: \n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# VISUALISING THE ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Reset environment\n",
    "obs = env.reset()\n",
    "\n",
    "# Show initial state of the environment\n",
    "env.render(mode= \"terminal\")\n",
    "\n",
    "for step in range(2):\n",
    "    # take random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # update environment in new window\n",
    "    clear_output()\n",
    "    print(\"Performed a move, new board: \")\n",
    "    env.render(mode= \"terminal\")\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        print(\"\\n\\n!!! Finished a game !!!\")\n",
    "        time.sleep(4)\n",
    "        env.reset()\n",
    "\n",
    "# Close the environment and thus the popup\n",
    "env.close()\n",
    "\n",
    "# Delete unused variables\n",
    "del action\n",
    "del done\n",
    "del info\n",
    "del obs\n",
    "del reward\n",
    "del step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321f057",
   "metadata": {},
   "source": [
    "#### Visualising the environment in human mode\n",
    "\n",
    "Let's now try to visualize the environment in the pygame window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5e1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# VISUALISING THE ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Reset the environment\n",
    "env.reset();\n",
    "\n",
    "# Visualise the environment by opening pygame window\n",
    "env.render(mode = 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9474dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CLOSE PYGAME WINDOW\n",
    "####################################################\n",
    "\n",
    "# Close and reset the environment\n",
    "env.close();\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745debb",
   "metadata": {},
   "source": [
    "#### Letting random agent play the game in human mode\n",
    "\n",
    "Let two agents play a combined total of 200 moves at random in the game and visualise it by updating the pygame continously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13f4c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed a move, board updated \n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# VISUALISING THE ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "# Reset environment\n",
    "obs = env.reset()\n",
    "\n",
    "# Show initial state of the environment\n",
    "env.render(mode= \"human\")\n",
    "\n",
    "# Wait for popup to open\n",
    "time.sleep(1.5)\n",
    "\n",
    "for step in range(100):\n",
    "    # take random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # update environment in new window\n",
    "    clear_output()\n",
    "    print(\"Performed a move, board updated \")\n",
    "    env.render(mode= \"human\")\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        print(\"\\n\\n!!! Finished a game !!!\")\n",
    "        time.sleep(2)\n",
    "        env.reset()\n",
    "\n",
    "# Close the environment and thus the popup\n",
    "env.close()\n",
    "\n",
    "# Delete unused variables\n",
    "del action\n",
    "del done\n",
    "del info\n",
    "del obs\n",
    "del reward\n",
    "del step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5be3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b88c88564fefe7444548986d165ad8d7f764d0079ffa923785a3f5a89d52c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
