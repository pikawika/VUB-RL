{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# CNN based DQN agent against fixed oponent\n",
    "\n",
    "As discussed in `5-improving-dqn-architecture.ipynb` we thought of three aspects that might be the root of the agent's not learning to play the game pleasingly:\n",
    "- Training two DQN agents simultaneously is known to be though, especially when starting from a random initialisation\n",
    "- The network used was a simple MLP\n",
    "- The training is not done over enough iterations\n",
    "\n",
    "In the notebooks `5-improving-dqn-architecture.ipynb` and `6-dqn-using-a-cnn.ipynb`, two alternative networks besides MLP were used.\n",
    "Whilst these give somewhat satisfactory results when trained for long enough and incentivising moves by giving a reward for making a move, it is still far from perfect.\n",
    "The iterations were also boosted to a couple of hours on a CUDA GPU, which didn't improve things all that much.\n",
    "\n",
    "Thus, what is most likely to be an issue is the fact that we are training two agents simultaneously.\n",
    "This makes it hard to get a good performing agent and makes the target non stationary as both agents evolve over time.\n",
    "An alternative to this is training an agent for a couple of epochs whilst freezing the other and alternating this between the agents.\n",
    "This makes the problem to learn more stationary and is known to make learning easier.\n",
    "What is also done, often in very complex games, is starting from a somewhat smart agent instead of a random one.\n",
    "\n",
    "Whilst some libraries such as Ray RL lib offer implementations of such a training strategy, the experimental notebook `4-rllib-for-more-learning-control.ipynb` found that even the Ray provided example results in error codes.\n",
    "Seeing their GitHub page has many open issues, the one we encountered being one of them, we refrain from using a different library considering Tianshou has many algorithms implemented and we have found a way to make things work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Contact information\n",
    "- Checking requirements\n",
    "  - Correct Anaconda environment\n",
    "  - Correct module access\n",
    "  - Correct CUDA access\n",
    "- Training two DQN agents on connect four Gym\n",
    "  - Building the environment\n",
    "  - Implementing the DQN policy\n",
    "  - Building agents\n",
    "  - Function for letting agents learn\n",
    "  - Function for watching learned agent\n",
    "  - Doing the experiment\n",
    "- Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Contact information\n",
    "\n",
    "| Name             | Student ID | VUB mail                                                  | Personal mail                                               |\n",
    "| ---------------- | ---------- | --------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Lennert Bontinck | 0568702    | [lennert.bontinck@vub.be](mailto:lennert.bontinck@vub.be) | [info@lennertbontinck.com](mailto:info@lennertbontinck.com) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a405d24",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements\n",
    "\n",
    "### Correct Anaconda environment\n",
    "\n",
    "The `rl-project` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the RL course project and homeworks](https://github.com/pikawika/vub-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: rl-project\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'rl-project'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following code block will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version (3.5.1 recommended): 3.5.1\n",
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Pygame version (2.1.2 recommended): 2.1.2\n",
      "Gym version (0.21.0 recommended): 0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\rl-project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tianshou version (0.4.8 recommended): 0.4.8\n",
      "Torch version (1.12.0 recommended): 1.12.0.dev20220520+cu116\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Allow reloading of libraries\n",
    "import importlib\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Argparser\n",
    "import argparse\n",
    "\n",
    "# More data types\n",
    "import typing\n",
    "import numpy as np\n",
    "\n",
    "# Pygame\n",
    "import pygame; print(f\"Pygame version (2.1.2 recommended): {pygame.__version__}\")\n",
    "\n",
    "# Gym environment\n",
    "import gym; print(f\"Gym version (0.21.0 recommended): {gym.__version__}\")\n",
    "\n",
    "# Tianshou for RL algorithms\n",
    "import tianshou as ts; print(f\"Tianshou version (0.4.8 recommended): {ts.__version__}\")\n",
    "\n",
    "# Torch is a popular DL framework\n",
    "import torch; print(f\"Torch version (1.12.0 recommended): {torch.__version__}\")\n",
    "\n",
    "# PPrint is a pretty print for variables\n",
    "from pprint import pprint\n",
    "\n",
    "# Our custom connect four gym environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import gym_connect4_pygame.envs.ConnectFourPygameEnvV2 as cfgym\n",
    "importlib.invalidate_caches()\n",
    "importlib.reload(cfgym)\n",
    "\n",
    "# Time for allowing \"freezes\" in execution\n",
    "import time;\n",
    "\n",
    "# Allow for copying objects in a non reference manner\n",
    "import copy\n",
    "\n",
    "# Used for updating notebook display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617a21",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct CUDA access\n",
    "\n",
    "The installation instructions specify how to install PyTorch with CUDA 11.6.\n",
    "The following code block tests if this was done successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9f5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "\n",
      "Amount of connected devices supporting CUDA: 1\n",
      "\n",
      "Current CUDA device: 0\n",
      "Cuda device 0 name: NVIDIA GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CUDA VALIDATION\n",
    "####################################################\n",
    "\n",
    "# Check cuda available\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Show cuda devices\n",
    "print(f\"\\nAmount of connected devices supporting CUDA: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Show current cuda device\n",
    "print(f\"\\nCurrent CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "# Show cuda device name\n",
    "print(f\"Cuda device 0 name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826657c4",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Training two DQN agents on connect four Gym\n",
    "\n",
    "Our connect four gym setup requires two agents, one for each player.\n",
    "To reduce complexity, agents will always play as the same player, e.g. always as player 1.\n",
    "It is important to note that connect four is a *solved game*.\n",
    "According to [The Washington Post](https://www.washingtonpost.com/news/wonk/wp/2015/05/08/how-to-win-any-popular-game-according-to-data-scientists/):\n",
    "\n",
    "> Connect Four is what mathematicians call a \"solved game,\" meaning you can play it perfectly every time, no matter what your opponent does. You will need to get the first move, but as long as you do so, you can always win within 41 moves.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Building the environment\n",
    "\n",
    "This code is taken from previous notebooks.\n",
    "We don't allow invalid moves to make the problem easier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b47a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]], [[2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]], (6, 7), int8))\n",
      "\n",
      "Action space: Discrete(7)\n",
      "\n",
      " Initial player id:\n",
      "player_1\n",
      "\n",
      " Initial observation:\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " Initial mask:\n",
      "[True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CONNECT FOUR V2 ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "def get_env():\n",
    "    \"\"\"\n",
    "    Returns the connect four gym environment V2 altered for Tianshou and Petting Zoo compatibility.\n",
    "    Already wrapped with a ts.env.PettingZooEnv wrapper.\n",
    "    \"\"\"\n",
    "    return ts.env.PettingZooEnv(cfgym.env(reward_move= 0, # Set to 1 for reward to make moves (incentivise longer games)\n",
    "                                          reward_invalid= -3,\n",
    "                                          reward_draw= 100,\n",
    "                                          reward_win= 25,\n",
    "                                          reward_loss= -25,\n",
    "                                          allow_invalid_move= False))\n",
    "    \n",
    "    \n",
    "# Test the environment\n",
    "env = get_env()\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"\\nAction space: {env.action_space}\")\n",
    "\n",
    "# Reset the environment to start from a clean state, returns the initial observation\n",
    "observation = env.reset()\n",
    "\n",
    "print(\"\\n Initial player id:\")\n",
    "print(observation[\"agent_id\"])\n",
    "\n",
    "print(\"\\n Initial observation:\")\n",
    "print(observation[\"obs\"])\n",
    "\n",
    "print(\"\\n Initial mask:\")\n",
    "print(observation[\"mask\"])\n",
    "\n",
    "# Clean unused variables\n",
    "del observation\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7e7da",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Implementing the DQN policy\n",
    "\n",
    "The DQN policy for the agent is configured and set up below.\n",
    "This is identical to the previous notebook with the added option of \"freezing\" an agent which corresponds to giving it an optimizer with learning rate 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2f43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# DQN ARCHITECTURE\n",
    "####################################################\n",
    "\n",
    "class CNNBasedDQN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom DQN using a model based on CNN\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_shape: typing.Sequence[int],\n",
    "                 action_shape: typing.Sequence[int],\n",
    "                 device: typing.Union[str, int, torch.device] = 'cuda' if torch.cuda.is_available() else 'cpu',):\n",
    "        # Parent call\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save device (e.g. cuda)\n",
    "        self.device = device\n",
    "        \n",
    "        # Number of input channels\n",
    "        input_channels_cnn = 1\n",
    "        output_channels_cnn = 32\n",
    "        flatten_size = (state_shape[0] - 3) * (state_shape[1] - 3) * output_channels_cnn\n",
    "        output_size= np.prod(action_shape)\n",
    "        \n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels= input_channels_cnn, out_channels= output_channels_cnn, kernel_size= 4, stride= 1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Flatten(0,-1),\n",
    "            torch.nn.Unflatten(0, (1, flatten_size)),\n",
    "            torch.nn.Linear(flatten_size, 128), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, 128), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float, device=self.device)\n",
    "        \n",
    "        logits = self.model(obs)\n",
    "        return logits, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# DQN POLICY\n",
    "####################################################\n",
    "\n",
    "def cf_cnn_dqn_policy(state_shape: tuple,\n",
    "                      action_shape: tuple,\n",
    "                      optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                      learning_rate: float =  0.0001,\n",
    "                      gamma: float = 0.9, # Smaller gamma favours \"faster\" win\n",
    "                      n_step: int = 4, # Number of steps to look ahead\n",
    "                      frozen: bool = False,\n",
    "                      target_update_freq: int = 320):\n",
    "    # Use cuda device if possible\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Network to be used for DQN\n",
    "    net = CNNBasedDQN(state_shape, action_shape, device= device).to(device)\n",
    "    \n",
    "    # Default optimizer is an adam optimizer with the argparser learning rate\n",
    "    if optim is None:\n",
    "        optim = torch.optim.Adam(net.parameters(), lr= learning_rate)\n",
    "        \n",
    "    # If we are frozen, we use an optimizer that has learning rate 0\n",
    "    if frozen:\n",
    "        optim = torch.optim.SGD(net.parameters(), lr= 0)\n",
    "        \n",
    "        \n",
    "    # Our agent DQN policy\n",
    "    return ts.policy.DQNPolicy(model= net,\n",
    "                               optim= optim,\n",
    "                               discount_factor= gamma,\n",
    "                               estimation_step= n_step,\n",
    "                               target_update_freq= target_update_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd411318",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Building agents\n",
    "\n",
    "This is identical to the previous notebook with the added option of \"freezing\" an agent which corresponds to giving it an optimizer with learning rate 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ae27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT CREATION\n",
    "####################################################\n",
    "\n",
    "def get_agents(agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "               agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "               optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "               resume_path_player_1: str = '', # Path to file to resume agent training from\n",
    "               resume_path_player_2: str = '', \n",
    "               agent_player1_frozen: bool = False, # Freeze a player -> don't let it learn further\n",
    "               agent_player2_frozen: bool = False,\n",
    "               ) -> typing.Tuple[ts.policy.BasePolicy, torch.optim.Optimizer, list]:\n",
    "    \"\"\"\n",
    "    Gets a multi agent policy manager, optimizer and player ids for the connect four V2 gym environment.\n",
    "    Per default this returns \n",
    "        - Multi agent manager for 2 agents using DQN\n",
    "        - Adam optimizer\n",
    "        - ['player_1', 'player_2'] from the connect four environment\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the environment to play in (Connect four gym V2)\n",
    "    env = get_env()\n",
    "    \n",
    "    # Get the observation space from the environment, depending on typo of space (ternary operator)\n",
    "    observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "    \n",
    "    # Set the arguments\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    \n",
    "    # Configure agent player 1 to be a DQN if no policy is passed.\n",
    "    if agent_player1 is None:\n",
    "        # Our agent1 uses a DQN policy\n",
    "        agent_player1 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                          action_shape= action_shape,\n",
    "                                          optim= optim,\n",
    "                                          frozen= agent_player1_frozen)\n",
    "        \n",
    "        # If we resume our agent we need to load the previous config\n",
    "        if resume_path_player_1:\n",
    "            agent_player1.load_state_dict(torch.load(resume_path_player_1))\n",
    "            \n",
    "    \n",
    "    # Configure agent player 2 to be a DQN if no policy is passed.\n",
    "    if agent_player2 is None:\n",
    "        # Our agent1 uses a DQN policy\n",
    "        agent_player2 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                          action_shape= action_shape,\n",
    "                                          optim= optim,\n",
    "                                          frozen= agent_player2_frozen)\n",
    "        \n",
    "        # If we resume our agent we need to load the previous config\n",
    "        if resume_path_player_2:\n",
    "            agent_player2.load_state_dict(torch.load(resume_path_player_2))\n",
    "\n",
    "    # Both our agents are DQN agents by default\n",
    "    agents = [agent_player1, agent_player2]\n",
    "        \n",
    "    # Our policy depends on the order of the agents\n",
    "    policy = ts.policy.MultiAgentPolicyManager(agents, env)\n",
    "    \n",
    "    # Return our policy, optimizer and the available agents in the environment\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using DQN\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    \n",
    "    return policy, optim, env.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8f3a6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for letting agents learn\n",
    "\n",
    "This is identical to the previous notebook with the added option of \"freezing\" an agent which corresponds to giving it an optimizer with learning rate 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a32c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT TRAINING\n",
    "####################################################\n",
    "\n",
    "def train_agent(filename: str = \"dqn_vs_dqn_cnn_based\",\n",
    "                agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                agent_player1_frozen: bool = False, # Freeze a player -> don't let it learn further\n",
    "                agent_player2_frozen: bool = False,\n",
    "                single_agent_score_as_reward: bool= False, # Uses non frozen agent's score as reward\n",
    "                optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                training_env_num: int = 1,\n",
    "                testing_env_num: int = 1,\n",
    "                buffer_size: int = 2^14,\n",
    "                batch_size: int = 1, \n",
    "                epochs: int = 50, #50\n",
    "                step_per_epoch: int = 1024, #1024\n",
    "                step_per_collect: int = 64, # transition before update\n",
    "                update_per_step: float = 0.1,\n",
    "                testing_eps: float = 0.05,\n",
    "                training_eps: float = 0.1,\n",
    "                ) -> typing.Tuple[dict, ts.policy.BasePolicy]:\n",
    "    \"\"\"\n",
    "    Trains two agents in the connect four V2 environment and saves their best model and logs.\n",
    "    Returns:\n",
    "        - result from offpolicy_trainer\n",
    "        - final version of agent 1\n",
    "        - final version of agent 2\n",
    "    \"\"\"\n",
    "\n",
    "    # ======== notebook specific =========\n",
    "    notebook_version = '7' # Used for foldering logs and models\n",
    "\n",
    "    # ======== environment setup =========\n",
    "    train_envs = ts.env.DummyVectorEnv([get_env for _ in range(training_env_num)])\n",
    "    test_envs = ts.env.DummyVectorEnv([get_env for _ in range(testing_env_num)])\n",
    "    \n",
    "    # set the seed for reproducibility\n",
    "    np.random.seed(1998)\n",
    "    torch.manual_seed(1998)\n",
    "    train_envs.seed(1998)\n",
    "    test_envs.seed(1998)\n",
    "\n",
    "    # ======== agent setup =========\n",
    "    # Gets our agents from the previously made function\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using DQN\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    policy, optim, agents = get_agents(agent_player1=agent_player1,\n",
    "                                       agent_player2=agent_player2,\n",
    "                                       agent_player1_frozen= agent_player1_frozen,\n",
    "                                       agent_player2_frozen= agent_player2_frozen,\n",
    "                                       optim=optim)\n",
    "\n",
    "    # ======== collector setup =========\n",
    "    # Make a collector for the training environments\n",
    "    train_collector = ts.data.Collector(policy= policy,\n",
    "                                        env= train_envs,\n",
    "                                        buffer= ts.data.VectorReplayBuffer(buffer_size, len(train_envs)),\n",
    "                                        exploration_noise= True)\n",
    "    \n",
    "    # Make a collector for the testing environments\n",
    "    test_collector = ts.data.Collector(policy= policy,\n",
    "                                       env= test_envs,\n",
    "                                       buffer= ts.data.VectorReplayBuffer(buffer_size, len(test_envs)),\n",
    "                                       exploration_noise= True)\n",
    "    \n",
    "    # Uncomment below if you want to set epsilon in epsilon policy\n",
    "    # policy.set_eps(1)\n",
    "    \n",
    "    # Collect data fot the training evnironments\n",
    "    train_collector.collect(n_step= batch_size * training_env_num)\n",
    "    \n",
    "    # ======== ensure folders exist =========\n",
    "    if not os.path.exists(os.path.join('./logs', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./logs', 'paper_notebooks', notebook_version, filename))\n",
    "    if not os.path.exists(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename))\n",
    "\n",
    "    # ======== tensorboard logging setup =========\n",
    "    # Allows to save the training progress to tensorboard compatable logs\n",
    "    log_path = os.path.join('./logs', 'paper_notebooks', notebook_version, filename)\n",
    "    writer = torch.utils.tensorboard.SummaryWriter(log_path)\n",
    "    logger = ts.utils.TensorboardLogger(writer)\n",
    "\n",
    "    # ======== callback functions used during training =========\n",
    "    # We want to save our best policy\n",
    "    def save_best_fn(policy):\n",
    "        \"\"\"\n",
    "        Callback to save the best model\n",
    "        \"\"\"\n",
    "        # Save best agent 1\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent1.pth')\n",
    "        torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save best agent 2\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent2.pth')\n",
    "        torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save agent2\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        \"\"\"\n",
    "        Callback to stop training when we've reached the win rate\n",
    "        \"\"\"\n",
    "        return mean_rewards >= 7 # (win = 10, 70% win without invalid moves = mean of 7)\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback before training\n",
    "        \"\"\"        \n",
    "        # Before training we want to configure the epsilon for the agents\n",
    "        # In general more exploratory than the test case\n",
    "        policy.policies[agents[0]].set_eps(training_eps)\n",
    "        policy.policies[agents[1]].set_eps(training_eps)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback beore testing\n",
    "        \"\"\"        \n",
    "        # Before testing we want to configure the epsilon for the agents\n",
    "        # In general more greedy than the train case but not\n",
    "        #   to avoid getting stuck on invalid moves\n",
    "        policy.policies[agents[0]].set_eps(testing_eps)\n",
    "        policy.policies[agents[1]].set_eps(testing_eps)\n",
    "\n",
    "    def reward_metric(rews):\n",
    "        \"\"\"\n",
    "        Callback for reward collection\n",
    "        \"\"\"        \n",
    "        if agent_player2_frozen and single_agent_score_as_reward:\n",
    "            # agent 2 frozen, optimizing for agent 1\n",
    "            return rews[:, 0]\n",
    "        \n",
    "        if agent_player1_frozen and single_agent_score_as_reward:\n",
    "            # agent 1 frozen, optimizing for agent 2\n",
    "            return rews[:, 1]\n",
    "        \n",
    "        # Per default we are interested in optimizing both agents\n",
    "        return rews[:, 0] + rews[:, 1]\n",
    "    \n",
    "            \n",
    "\n",
    "    # trainer\n",
    "    result = ts.trainer.offpolicy_trainer(policy= policy,\n",
    "                                          train_collector= train_collector,\n",
    "                                          test_collector= test_collector,\n",
    "                                          max_epoch= epochs,\n",
    "                                          step_per_epoch= step_per_epoch,\n",
    "                                          step_per_collect= step_per_collect,\n",
    "                                          episode_per_test= testing_env_num,\n",
    "                                          batch_size= batch_size,\n",
    "                                          train_fn= train_fn,\n",
    "                                          test_fn= test_fn,\n",
    "                                          # Stop function to stop before specified amount of epochs\n",
    "                                          #stop_fn= stop_fn\n",
    "                                          save_best_fn= save_best_fn,\n",
    "                                          update_per_step= update_per_step,\n",
    "                                          logger= logger,\n",
    "                                          test_in_train= False,\n",
    "                                          reward_metric= reward_metric)\n",
    "    \n",
    "    # Save final agent 1\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent1.pth')\n",
    "    torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "\n",
    "    # Save final agent 2\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent2.pth')\n",
    "    torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "\n",
    "    return result, policy.policies[agents[0]], policy.policies[agents[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161cc0f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for watching learned agent\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459114bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# WATCHING THE LEARNED POLICY IN ACTION\n",
    "####################################################\n",
    "\n",
    "def watch(numer_of_games: int = 3,\n",
    "          agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          test_epsilon: float = 0.05, # For the watching we act completely greedy but low random for not getting stuck on invalid move\n",
    "          render_speed: float = 0.15, # Amount of seconds to update frame/ do a step\n",
    "          ) -> None:\n",
    "    \n",
    "    # Get the connect four V2 environment (must be a list)\n",
    "    env= ts.env.DummyVectorEnv([get_env])\n",
    "    \n",
    "    # Get the agents from the trained agents\n",
    "    policy, optim, agents = get_agents(agent_player1= agent_player1,\n",
    "                                       agent_player2= agent_player2)\n",
    "    \n",
    "    # Evaluate the policy\n",
    "    policy.eval()\n",
    "    \n",
    "    # Set the testing policy epsilon for our agents\n",
    "    policy.policies[agents[0]].set_eps(test_epsilon)\n",
    "    policy.policies[agents[1]].set_eps(test_epsilon)\n",
    "    \n",
    "    # Collect the test data\n",
    "    collector = ts.data.Collector(policy= policy,\n",
    "                                  env= env,\n",
    "                                  exploration_noise= True)\n",
    "    \n",
    "    # Render games in human mode to see how it plays\n",
    "    result = collector.collect(n_episode= numer_of_games, render= render_speed)\n",
    "    \n",
    "    # Close the environment aftering collecting the results\n",
    "    # This closes the pygame window after completion\n",
    "    env.close()\n",
    "    \n",
    "    # Get the rewards and length from the test trials\n",
    "    rewards, length = result[\"rews\"], result[\"lens\"]\n",
    "    \n",
    "    # Print the final reward for the first agent\n",
    "    print(f\"Average steps of game:  {length.mean()}\")\n",
    "    print(f\"Final mean reward agent 1: {rewards[:, 0].mean()}, std: {rewards[:, 0].std()}\")\n",
    "    print(f\"Final mean reward agent 2: {rewards[:, 1].mean()}, std: {rewards[:, 1].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31784e9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Doing the experiment\n",
    "\n",
    "We now do the experiment with using our previously created functions.\n",
    "We freeze one agent and initialize both agents from previous versions.\n",
    "\n",
    "The following iterations were made:\n",
    "\n",
    "1. Freeze agent 1, train agent 2:\n",
    "    - Model save name: `1-cnn_dqn_frozen_agent1` \n",
    "    - Agent 1 start: `./saved_variables/paper_notebooks/6/dqn_vs_dqn_cnn_based/best_policy_agent1.pth`\n",
    "    - Agent 2 start: `./saved_variables/paper_notebooks/6/dqn_vs_dqn_cnn_based/best_policy_agent2.pth`\n",
    "    - Learning rate: `0.0001`\n",
    "    - Training epsilon: `0.2`\n",
    "    - Look ahead steps: `4`\n",
    "    - Reward for move/invalid: `+1` / `-3`\n",
    "    - Allow invalid move: `False`\n",
    "    - Epochs: `1000`\n",
    "    - Gamma: `0.9`\n",
    "    - Best epoch: `51` with test reward `1102`\n",
    "    - Scoring: sum of `both` agent's score\n",
    "2. Freeze agent 2, train agent 1:\n",
    "    - Model save name: `2-cnn_dqn_frozen_agent2` \n",
    "    - Agent 1 start: `./saved_variables/paper_notebooks/6/dqn_vs_dqn_cnn_based/best_policy_agent1.pth`\n",
    "    - Agent 2 start: `./saved_variables/paper_notebooks/7/1-cnn_dqn_frozen_agent1/final_policy_agent2.pth`\n",
    "    - Learning rate: `0.0001`\n",
    "    - Training epsilon: `0.2`\n",
    "    - Look ahead steps: `4`\n",
    "    - Reward for move/invalid: `+1` / `-3`\n",
    "    - Allow invalid move: `False`\n",
    "    - Epochs: `1000`\n",
    "    - Gamma: `0.9`\n",
    "    - Best epoch: `360` with test reward `1102`\n",
    "    - Scoring: sum of `both` agent's score\n",
    "\n",
    "After which the agent was so focused on prolonging the game, we decided to lower the learning rate and start optimizing for winning again. We also lowered the amount of epochs in each iterations of swapping the frozen agent.\n",
    "\n",
    "3. Freeze agent 1, train agent 2:\n",
    "    - Model save name: `3-cnn_dqn_frozen_agent1` \n",
    "    - Agent 1 start: `./saved_variables/paper_notebooks/7/2-cnn_dqn_frozen_agent2/best_policy_agent1.pth`\n",
    "    - Agent 2 start: `./saved_variables/paper_notebooks/7/1-cnn_dqn_frozen_agent1/final_policy_agent2.pth`\n",
    "    - Learning rate: `0.00005` # halfed learning rate\n",
    "    - Training epsilon: `0.1` # halfed training epsilon\n",
    "    - Look ahead steps: `4`\n",
    "    - Reward for move/invalid: `0` / `-3`\n",
    "    - Allow invalid move: `False`\n",
    "    - Epochs: `500`\n",
    "    - Gamma: `0.8` # Lowered to not make agent want to play too fast again\n",
    "    - Best epoch: `1` with test reward `100` - tie game\n",
    "    - Scoring: reward of `agent 2`\n",
    "4. Freeze agent 2, train agent 1:\n",
    "    - Model save name: `4-cnn_dqn_frozen_agent2` \n",
    "    - Agent 1 start: `./saved_variables/paper_notebooks/7/2-cnn_dqn_frozen_agent2/best_policy_agent1.pth`\n",
    "    - Agent 2 start: `./saved_variables/paper_notebooks/7/3-cnn_dqn_frozen_agent1/best_policy_agent2.pth`\n",
    "    - Learning rate: `0.00005`\n",
    "    - Training epsilon: `0.1`\n",
    "    - Look ahead steps: `4`\n",
    "    - Reward for move/invalid: `0` / `-3`\n",
    "    - Allow invalid move: `False`\n",
    "    - Epochs: `500`\n",
    "    - Gamma: `0.8` # Lowered to not make agent want to play too fast again\n",
    "    - Best epoch: `1` with test reward `100` - tie game\n",
    "    - Scoring: reward of `agent 1`\n",
    "    \n",
    "To do further training, a loop was created which alternated between freezing agens every 50 epochs. This loop was executed 20 times. The learning rate was also lowered once again.\n",
    "\n",
    "4. Loop frozen agents:\n",
    "    - Model save name: `i-looping` \n",
    "    - Agent 1 start: `./saved_variables/paper_notebooks/7/4-cnn_dqn_frozen_agent2/best_policy_agent1.pth`\n",
    "    - Agent 2 start: `./saved_variables/paper_notebooks/7/3-cnn_dqn_frozen_agent1/best_policy_agent2.pth`\n",
    "    - Learning rate: `0.000001`\n",
    "    - Training epsilon: `0.1`\n",
    "    - Look ahead steps: `4`\n",
    "    - Reward for move/invalid: `0` / `-3`\n",
    "    - Allow invalid move: `False`\n",
    "    - Epochs: `50` x `i` \n",
    "    - Gamma: `0.8` # Lowered to not make agent want to play too fast again\n",
    "    - Best epoch: final epoch always taken to next round\n",
    "    - Scoring: reward of `non frozen agent`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93fe8961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1025it [00:02, 372.71it/s, env_step=1024, len=32, n/ep=2, n/st=64, player_1/loss=1464.507, player_2/loss=1739.194, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 100.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1025it [00:02, 430.04it/s, env_step=2048, len=31, n/ep=2, n/st=64, player_1/loss=1330.691, player_2/loss=1639.518, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 100.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1025it [00:02, 439.04it/s, env_step=3072, len=35, n/ep=2, n/st=64, player_1/loss=719.483, player_2/loss=1558.502, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1025it [00:02, 429.80it/s, env_step=4096, len=17, n/ep=3, n/st=64, player_1/loss=606.336, player_2/loss=1410.289, rew=-8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1025it [00:02, 409.94it/s, env_step=5120, len=26, n/ep=3, n/st=64, player_1/loss=512.857, player_2/loss=1504.404, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1025it [00:02, 383.67it/s, env_step=6144, len=32, n/ep=2, n/st=64, player_1/loss=433.962, player_2/loss=1399.332, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 100.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1025it [00:02, 442.55it/s, env_step=7168, len=38, n/ep=2, n/st=64, player_1/loss=515.364, player_2/loss=1290.387, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1025it [00:02, 457.80it/s, env_step=8192, len=16, n/ep=4, n/st=64, player_1/loss=525.078, player_2/loss=1281.859, rew=-12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1025it [00:02, 444.67it/s, env_step=9216, len=34, n/ep=2, n/st=64, player_1/loss=365.542, player_2/loss=1453.316, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1025it [00:02, 451.44it/s, env_step=10240, len=31, n/ep=2, n/st=64, player_1/loss=344.236, player_2/loss=1485.317, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1025it [00:02, 456.85it/s, env_step=11264, len=38, n/ep=2, n/st=64, player_1/loss=366.543, player_2/loss=1775.453, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1025it [00:02, 461.26it/s, env_step=12288, len=37, n/ep=2, n/st=64, player_1/loss=239.896, player_2/loss=1707.175, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1025it [00:02, 463.48it/s, env_step=13312, len=36, n/ep=2, n/st=64, player_1/loss=200.287, player_2/loss=1548.158, rew=62.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1025it [00:02, 468.73it/s, env_step=14336, len=24, n/ep=2, n/st=64, player_1/loss=232.620, player_2/loss=1411.014, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1025it [00:02, 471.23it/s, env_step=15360, len=29, n/ep=2, n/st=64, player_1/loss=175.931, player_2/loss=1342.156, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1025it [00:02, 468.03it/s, env_step=16384, len=40, n/ep=2, n/st=64, player_1/loss=205.413, player_2/loss=1505.115, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1025it [00:02, 464.18it/s, env_step=17408, len=28, n/ep=2, n/st=64, player_1/loss=202.502, player_2/loss=1629.197, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1025it [00:02, 466.68it/s, env_step=18432, len=27, n/ep=3, n/st=64, player_1/loss=200.576, player_2/loss=1750.501, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1025it [00:02, 470.90it/s, env_step=19456, len=28, n/ep=3, n/st=64, player_1/loss=127.080, player_2/loss=1909.646, rew=50.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1025it [00:02, 469.70it/s, env_step=20480, len=33, n/ep=2, n/st=64, player_1/loss=65.595, player_2/loss=1772.863, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #21: 1025it [00:02, 466.01it/s, env_step=21504, len=37, n/ep=2, n/st=64, player_1/loss=88.179, player_2/loss=1615.382, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #21: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #22: 1025it [00:02, 463.90it/s, env_step=22528, len=35, n/ep=2, n/st=64, player_1/loss=134.703, player_2/loss=1904.048, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #22: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #23: 1025it [00:02, 462.15it/s, env_step=23552, len=35, n/ep=2, n/st=64, player_1/loss=110.208, player_2/loss=1933.115, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #23: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #24: 1025it [00:02, 469.30it/s, env_step=24576, len=30, n/ep=2, n/st=64, player_1/loss=76.685, player_2/loss=1458.436, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #24: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #25: 1025it [00:02, 468.88it/s, env_step=25600, len=32, n/ep=2, n/st=64, player_1/loss=103.844, player_2/loss=1627.797, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #25: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #26: 1025it [00:02, 463.27it/s, env_step=26624, len=31, n/ep=2, n/st=64, player_1/loss=86.945, player_2/loss=1747.441, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #26: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #27: 1025it [00:02, 406.36it/s, env_step=27648, len=30, n/ep=2, n/st=64, player_1/loss=43.392, player_2/loss=1554.377, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #27: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #28: 1025it [00:02, 446.03it/s, env_step=28672, len=31, n/ep=2, n/st=64, player_2/loss=1358.476, rew=25.00]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #28: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #29: 1025it [00:02, 396.07it/s, env_step=29696, len=23, n/ep=2, n/st=64, player_1/loss=43.583, player_2/loss=1356.998, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #29: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #30: 1025it [00:02, 409.85it/s, env_step=30720, len=30, n/ep=2, n/st=64, player_1/loss=40.773, player_2/loss=1886.282, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #30: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #31: 1025it [00:02, 451.67it/s, env_step=31744, len=16, n/ep=3, n/st=64, player_1/loss=83.308, player_2/loss=2374.965, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #31: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #32: 1025it [00:02, 455.06it/s, env_step=32768, len=29, n/ep=2, n/st=64, player_1/loss=92.907, player_2/loss=1849.157, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #32: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #33: 1025it [00:02, 458.97it/s, env_step=33792, len=22, n/ep=3, n/st=64, player_1/loss=75.033, player_2/loss=1604.062, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #33: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #34: 1025it [00:02, 456.97it/s, env_step=34816, len=15, n/ep=5, n/st=64, player_1/loss=68.043, player_2/loss=1846.008, rew=-5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #34: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #35: 1025it [00:02, 456.08it/s, env_step=35840, len=22, n/ep=3, n/st=64, player_1/loss=63.818, player_2/loss=1807.289, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #36: 1025it [00:02, 456.37it/s, env_step=36864, len=23, n/ep=4, n/st=64, player_1/loss=39.694, player_2/loss=1512.780, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #36: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #37: 1025it [00:02, 461.05it/s, env_step=37888, len=16, n/ep=4, n/st=64, player_1/loss=57.815, player_2/loss=1430.658, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #37: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #38: 1025it [00:02, 461.05it/s, env_step=38912, len=16, n/ep=5, n/st=64, player_1/loss=86.173, player_2/loss=1399.847, rew=-25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #38: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #39: 1025it [00:02, 461.58it/s, env_step=39936, len=17, n/ep=4, n/st=64, player_1/loss=77.857, player_2/loss=2268.032, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #39: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #40: 1025it [00:02, 448.97it/s, env_step=40960, len=15, n/ep=3, n/st=64, player_1/loss=69.708, player_2/loss=2146.106, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #41: 1025it [00:02, 450.61it/s, env_step=41984, len=14, n/ep=4, n/st=64, player_1/loss=63.950, player_2/loss=2111.056, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #41: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #42: 1025it [00:02, 459.29it/s, env_step=43008, len=16, n/ep=4, n/st=64, player_1/loss=93.223, player_2/loss=2150.795, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #42: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #43: 1025it [00:02, 463.71it/s, env_step=44032, len=15, n/ep=4, n/st=64, player_1/loss=98.386, player_2/loss=1912.712, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #43: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #44: 1025it [00:02, 461.20it/s, env_step=45056, len=18, n/ep=4, n/st=64, player_1/loss=74.311, player_2/loss=2280.268, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #44: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #45: 1025it [00:02, 457.90it/s, env_step=46080, len=11, n/ep=6, n/st=64, player_1/loss=61.329, player_2/loss=2277.006, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #45: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #46: 1025it [00:02, 461.19it/s, env_step=47104, len=9, n/ep=7, n/st=64, player_1/loss=93.956, player_2/loss=1737.028, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #46: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #47: 1025it [00:02, 461.77it/s, env_step=48128, len=9, n/ep=6, n/st=64, player_1/loss=123.978, player_2/loss=1822.908, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #47: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #48: 1025it [00:02, 451.33it/s, env_step=49152, len=7, n/ep=8, n/st=64, player_1/loss=112.679, player_2/loss=1780.515, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #48: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #49: 1025it [00:02, 435.97it/s, env_step=50176, len=8, n/ep=8, n/st=64, player_1/loss=92.966, player_2/loss=1805.887, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #49: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #50: 1025it [00:02, 419.00it/s, env_step=51200, len=7, n/ep=9, n/st=64, player_1/loss=106.709, player_2/loss=1875.023, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #51: 1025it [00:02, 405.01it/s, env_step=52224, len=8, n/ep=7, n/st=64, player_1/loss=126.132, player_2/loss=2331.765, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #51: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #52: 1025it [00:02, 390.79it/s, env_step=53248, len=8, n/ep=8, n/st=64, player_1/loss=132.783, player_2/loss=2400.407, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #52: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #53: 1025it [00:02, 378.38it/s, env_step=54272, len=7, n/ep=9, n/st=64, player_1/loss=124.672, player_2/loss=2538.509, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #53: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #54: 1025it [00:02, 365.10it/s, env_step=55296, len=7, n/ep=8, n/st=64, player_1/loss=97.353, player_2/loss=2570.836, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #54: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #55: 1025it [00:02, 367.59it/s, env_step=56320, len=7, n/ep=8, n/st=64, player_1/loss=86.649, player_2/loss=2732.758, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #55: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #56: 1025it [00:02, 369.43it/s, env_step=57344, len=7, n/ep=8, n/st=64, player_1/loss=78.564, player_2/loss=2226.943, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #56: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #57: 1025it [00:02, 365.80it/s, env_step=58368, len=7, n/ep=9, n/st=64, player_1/loss=76.437, player_2/loss=1757.258, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #57: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #58: 1025it [00:02, 369.01it/s, env_step=59392, len=7, n/ep=10, n/st=64, player_1/loss=86.810, player_2/loss=2091.305, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #58: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #59: 1025it [00:02, 367.11it/s, env_step=60416, len=8, n/ep=8, n/st=64, player_1/loss=84.721, player_2/loss=2148.834, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #59: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #60: 1025it [00:02, 366.45it/s, env_step=61440, len=8, n/ep=8, n/st=64, player_1/loss=76.267, player_2/loss=2508.954, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #60: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #61: 1025it [00:02, 365.62it/s, env_step=62464, len=8, n/ep=8, n/st=64, player_1/loss=69.756, player_2/loss=2021.153, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #61: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #62: 1025it [00:02, 365.85it/s, env_step=63488, len=7, n/ep=8, n/st=64, player_1/loss=63.752, player_2/loss=1849.537, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #62: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #63: 1025it [00:02, 366.32it/s, env_step=64512, len=7, n/ep=7, n/st=64, player_1/loss=76.377, player_2/loss=1856.703, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #63: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #64: 1025it [00:02, 365.32it/s, env_step=65536, len=7, n/ep=9, n/st=64, player_1/loss=61.959, player_2/loss=1817.514, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #64: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #65: 1025it [00:02, 367.07it/s, env_step=66560, len=7, n/ep=8, n/st=64, player_1/loss=60.875, player_2/loss=1950.516, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #65: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #66: 1025it [00:02, 365.68it/s, env_step=67584, len=9, n/ep=7, n/st=64, player_1/loss=54.507, player_2/loss=2135.883, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #66: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #67: 1025it [00:02, 366.27it/s, env_step=68608, len=8, n/ep=8, n/st=64, player_1/loss=64.820, player_2/loss=2294.599, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #67: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #68: 1025it [00:02, 365.57it/s, env_step=69632, len=8, n/ep=7, n/st=64, player_1/loss=94.054, player_2/loss=1903.578, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #68: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #69: 1025it [00:02, 365.98it/s, env_step=70656, len=8, n/ep=8, n/st=64, player_1/loss=76.485, player_2/loss=2087.956, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #69: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #70: 1025it [00:02, 364.75it/s, env_step=71680, len=8, n/ep=7, n/st=64, player_1/loss=44.681, player_2/loss=2141.685, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #70: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #71: 1025it [00:02, 365.53it/s, env_step=72704, len=7, n/ep=9, n/st=64, player_1/loss=42.771, player_2/loss=2306.869, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #71: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #72: 1025it [00:02, 366.68it/s, env_step=73728, len=8, n/ep=9, n/st=64, player_1/loss=36.897, player_2/loss=2326.929, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #72: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #73: 1025it [00:02, 364.06it/s, env_step=74752, len=7, n/ep=8, n/st=64, player_1/loss=45.056, player_2/loss=2146.802, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #73: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #74: 1025it [00:02, 367.84it/s, env_step=75776, len=7, n/ep=9, n/st=64, player_1/loss=50.809, player_2/loss=2200.666, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #74: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #75: 1025it [00:02, 369.41it/s, env_step=76800, len=7, n/ep=8, n/st=64, player_1/loss=49.483, player_2/loss=2354.992, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #75: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #76: 1025it [00:02, 362.19it/s, env_step=77824, len=8, n/ep=8, n/st=64, player_1/loss=49.030, player_2/loss=2257.669, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #76: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #77: 1025it [00:02, 376.30it/s, env_step=78848, len=7, n/ep=8, n/st=64, player_1/loss=36.187, player_2/loss=2420.120, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #77: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #78: 1025it [00:02, 379.09it/s, env_step=79872, len=7, n/ep=8, n/st=64, player_1/loss=26.260, player_2/loss=2379.257, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #78: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #79: 1025it [00:02, 368.32it/s, env_step=80896, len=8, n/ep=7, n/st=64, player_1/loss=27.245, player_2/loss=2360.920, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #79: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #80: 1025it [00:02, 364.94it/s, env_step=81920, len=8, n/ep=8, n/st=64, player_1/loss=22.301, player_2/loss=2200.797, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #80: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #81: 1025it [00:02, 366.77it/s, env_step=82944, len=7, n/ep=9, n/st=64, player_1/loss=42.765, player_2/loss=2181.416, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #81: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #82: 1025it [00:02, 367.95it/s, env_step=83968, len=7, n/ep=8, n/st=64, player_1/loss=54.133, player_2/loss=2111.475, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #82: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #83: 1025it [00:02, 366.03it/s, env_step=84992, len=7, n/ep=9, n/st=64, player_1/loss=39.901, player_2/loss=2204.048, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #83: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #84: 1025it [00:02, 366.96it/s, env_step=86016, len=7, n/ep=9, n/st=64, player_1/loss=29.974, player_2/loss=2135.839, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #84: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #85: 1025it [00:02, 366.39it/s, env_step=87040, len=8, n/ep=8, n/st=64, player_1/loss=15.663, player_2/loss=2113.943, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #85: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #86: 1025it [00:02, 367.09it/s, env_step=88064, len=7, n/ep=8, n/st=64, player_1/loss=18.090, player_2/loss=2384.569, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #86: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #87: 1025it [00:02, 364.90it/s, env_step=89088, len=8, n/ep=8, n/st=64, player_1/loss=27.483, player_2/loss=2405.385, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #87: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #88: 1025it [00:02, 367.12it/s, env_step=90112, len=7, n/ep=9, n/st=64, player_1/loss=30.449, player_2/loss=2107.574, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #88: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #89: 1025it [00:02, 366.79it/s, env_step=91136, len=7, n/ep=8, n/st=64, player_1/loss=28.543, player_2/loss=1972.913, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #89: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #90: 1025it [00:02, 366.83it/s, env_step=92160, len=8, n/ep=7, n/st=64, player_1/loss=29.139, player_2/loss=2204.015, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #90: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #91: 1025it [00:02, 366.17it/s, env_step=93184, len=8, n/ep=6, n/st=64, player_1/loss=35.226, player_2/loss=2230.000, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #91: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #92: 1025it [00:02, 363.99it/s, env_step=94208, len=7, n/ep=9, n/st=64, player_1/loss=40.571, player_2/loss=2402.958, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #92: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #93: 1025it [00:02, 364.14it/s, env_step=95232, len=7, n/ep=8, n/st=64, player_1/loss=28.590, player_2/loss=2006.964, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #93: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #94: 1025it [00:02, 367.20it/s, env_step=96256, len=7, n/ep=8, n/st=64, player_1/loss=19.022, player_2/loss=2187.023, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #94: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #95: 1025it [00:02, 368.31it/s, env_step=97280, len=8, n/ep=7, n/st=64, player_1/loss=33.317, player_2/loss=2070.468, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #95: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #96: 1025it [00:02, 369.93it/s, env_step=98304, len=12, n/ep=5, n/st=64, player_1/loss=38.180, player_2/loss=1917.325, rew=5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #96: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #97: 1025it [00:02, 363.71it/s, env_step=99328, len=8, n/ep=8, n/st=64, player_1/loss=20.201, player_2/loss=2040.430, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #97: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #98: 1025it [00:02, 368.72it/s, env_step=100352, len=7, n/ep=8, n/st=64, player_1/loss=16.387, player_2/loss=2185.045, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #98: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #99: 1025it [00:02, 364.82it/s, env_step=101376, len=7, n/ep=8, n/st=64, player_1/loss=12.890, player_2/loss=2317.487, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #99: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #100: 1025it [00:02, 365.87it/s, env_step=102400, len=7, n/ep=9, n/st=64, player_1/loss=10.240, player_2/loss=2024.937, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #100: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #101: 1025it [00:02, 363.36it/s, env_step=103424, len=11, n/ep=6, n/st=64, player_1/loss=30.745, player_2/loss=2099.489, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #101: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #102: 1025it [00:02, 366.60it/s, env_step=104448, len=9, n/ep=8, n/st=64, player_1/loss=26.245, player_2/loss=2181.793, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #102: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #103: 1025it [00:02, 366.48it/s, env_step=105472, len=9, n/ep=7, n/st=64, player_1/loss=31.083, player_2/loss=2153.546, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #103: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #104: 1025it [00:02, 368.88it/s, env_step=106496, len=7, n/ep=9, n/st=64, player_1/loss=34.987, player_2/loss=2108.232, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #104: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #105: 1025it [00:02, 366.86it/s, env_step=107520, len=8, n/ep=8, n/st=64, player_1/loss=29.453, player_2/loss=1839.523, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #105: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #106: 1025it [00:02, 364.79it/s, env_step=108544, len=7, n/ep=8, n/st=64, player_1/loss=14.913, player_2/loss=2003.522, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #106: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #107: 1025it [00:02, 366.95it/s, env_step=109568, len=7, n/ep=9, n/st=64, player_1/loss=12.661, player_2/loss=2211.871, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #107: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #108: 1025it [00:02, 366.68it/s, env_step=110592, len=8, n/ep=8, n/st=64, player_1/loss=17.192, player_2/loss=2100.213, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #108: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #109: 1025it [00:02, 366.23it/s, env_step=111616, len=9, n/ep=7, n/st=64, player_1/loss=21.536, player_2/loss=2114.161, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #109: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #110: 1025it [00:02, 368.28it/s, env_step=112640, len=8, n/ep=7, n/st=64, player_1/loss=17.167, player_2/loss=2378.516, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #110: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #111: 1025it [00:02, 366.13it/s, env_step=113664, len=7, n/ep=9, n/st=64, player_1/loss=8.242, player_2/loss=2545.366, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #111: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #112: 1025it [00:02, 366.64it/s, env_step=114688, len=9, n/ep=7, n/st=64, player_1/loss=9.345, player_2/loss=2350.620, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #112: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #113: 1025it [00:02, 364.40it/s, env_step=115712, len=8, n/ep=8, n/st=64, player_1/loss=10.268, player_2/loss=2279.333, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #113: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #114: 1025it [00:02, 367.40it/s, env_step=116736, len=8, n/ep=8, n/st=64, player_1/loss=11.470, player_2/loss=2286.102, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #114: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #115: 1025it [00:02, 366.94it/s, env_step=117760, len=7, n/ep=9, n/st=64, player_1/loss=17.294, player_2/loss=2105.456, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #115: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #116: 1025it [00:02, 366.14it/s, env_step=118784, len=8, n/ep=7, n/st=64, player_1/loss=20.537, player_2/loss=2144.024, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #116: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #117: 1025it [00:02, 364.88it/s, env_step=119808, len=9, n/ep=7, n/st=64, player_1/loss=17.856, player_2/loss=2089.494, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #117: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #118: 1025it [00:02, 366.39it/s, env_step=120832, len=7, n/ep=8, n/st=64, player_1/loss=18.052, player_2/loss=1927.694, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #118: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #119: 1025it [00:02, 365.84it/s, env_step=121856, len=7, n/ep=8, n/st=64, player_1/loss=51.045, player_2/loss=1985.042, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #119: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #120: 1025it [00:02, 381.85it/s, env_step=122880, len=8, n/ep=8, n/st=64, player_1/loss=44.999, player_2/loss=2366.135, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #120: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #121: 1025it [00:02, 382.06it/s, env_step=123904, len=8, n/ep=8, n/st=64, player_1/loss=26.654, player_2/loss=2021.439, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #121: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #122: 1025it [00:02, 368.37it/s, env_step=124928, len=7, n/ep=8, n/st=64, player_1/loss=43.907, player_2/loss=1919.184, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #122: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #123: 1025it [00:02, 364.05it/s, env_step=125952, len=8, n/ep=8, n/st=64, player_1/loss=28.565, player_2/loss=1874.597, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #123: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #124: 1025it [00:02, 364.54it/s, env_step=126976, len=8, n/ep=7, n/st=64, player_1/loss=12.696, player_2/loss=2163.994, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #124: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #125: 1025it [00:02, 361.37it/s, env_step=128000, len=8, n/ep=8, n/st=64, player_1/loss=19.600, player_2/loss=2427.850, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #125: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #126: 1025it [00:02, 365.97it/s, env_step=129024, len=7, n/ep=9, n/st=64, player_1/loss=33.456, player_2/loss=2421.598, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #126: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #127: 1025it [00:02, 367.28it/s, env_step=130048, len=7, n/ep=8, n/st=64, player_1/loss=26.607, player_2/loss=2037.361, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #127: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #128: 1025it [00:02, 363.94it/s, env_step=131072, len=8, n/ep=8, n/st=64, player_1/loss=12.285, player_2/loss=1833.765, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #128: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #129: 1025it [00:02, 365.09it/s, env_step=132096, len=8, n/ep=8, n/st=64, player_1/loss=12.454, player_2/loss=1591.437, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #129: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #130: 1025it [00:02, 354.88it/s, env_step=133120, len=8, n/ep=8, n/st=64, player_1/loss=7.671, player_2/loss=2195.419, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #130: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #131: 1025it [00:02, 365.63it/s, env_step=134144, len=8, n/ep=8, n/st=64, player_1/loss=22.461, player_2/loss=2512.442, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #131: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #132: 1025it [00:02, 362.99it/s, env_step=135168, len=8, n/ep=8, n/st=64, player_1/loss=43.833, player_2/loss=2399.798, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #132: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #133: 1025it [00:02, 367.04it/s, env_step=136192, len=7, n/ep=9, n/st=64, player_1/loss=40.827, player_2/loss=2070.096, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #133: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #134: 1025it [00:02, 367.37it/s, env_step=137216, len=7, n/ep=8, n/st=64, player_1/loss=34.604, player_2/loss=2059.939, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #134: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #135: 1025it [00:02, 366.52it/s, env_step=138240, len=7, n/ep=8, n/st=64, player_1/loss=20.469, player_2/loss=2103.961, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #135: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #136: 1025it [00:02, 364.72it/s, env_step=139264, len=7, n/ep=9, n/st=64, player_1/loss=19.986, player_2/loss=1948.609, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #136: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #137: 1025it [00:02, 366.31it/s, env_step=140288, len=8, n/ep=7, n/st=64, player_1/loss=22.998, player_2/loss=2099.572, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #137: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #138: 1025it [00:02, 365.85it/s, env_step=141312, len=7, n/ep=8, n/st=64, player_1/loss=8.439, player_2/loss=2144.550, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #138: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #139: 1025it [00:02, 364.41it/s, env_step=142336, len=8, n/ep=8, n/st=64, player_1/loss=6.626, player_2/loss=2066.436, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #139: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #140: 1025it [00:02, 365.73it/s, env_step=143360, len=7, n/ep=8, n/st=64, player_1/loss=21.410, player_2/loss=1991.438, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #140: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #141: 1025it [00:02, 367.11it/s, env_step=144384, len=8, n/ep=8, n/st=64, player_1/loss=33.801, player_2/loss=1968.258, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #141: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #142: 1025it [00:02, 364.35it/s, env_step=145408, len=7, n/ep=9, n/st=64, player_1/loss=22.911, player_2/loss=2259.774, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #142: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #143: 1025it [00:02, 367.38it/s, env_step=146432, len=7, n/ep=9, n/st=64, player_1/loss=25.280, player_2/loss=2111.351, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #143: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #144: 1025it [00:02, 366.33it/s, env_step=147456, len=7, n/ep=9, n/st=64, player_1/loss=20.193, player_2/loss=1804.744, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #144: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #145: 1025it [00:02, 366.42it/s, env_step=148480, len=8, n/ep=7, n/st=64, player_1/loss=8.298, player_2/loss=1912.693, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #145: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #146: 1025it [00:02, 364.98it/s, env_step=149504, len=8, n/ep=7, n/st=64, player_1/loss=10.270, player_2/loss=2189.729, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #146: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #147: 1025it [00:02, 366.75it/s, env_step=150528, len=9, n/ep=6, n/st=64, player_1/loss=20.827, player_2/loss=2118.745, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #147: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #148: 1025it [00:02, 368.22it/s, env_step=151552, len=7, n/ep=8, n/st=64, player_1/loss=28.942, player_2/loss=1915.955, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #148: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #149: 1025it [00:02, 361.48it/s, env_step=152576, len=8, n/ep=8, n/st=64, player_1/loss=25.851, player_2/loss=2033.371, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #149: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #150: 1025it [00:02, 365.94it/s, env_step=153600, len=8, n/ep=7, n/st=64, player_1/loss=28.810, player_2/loss=1860.969, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #150: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #151: 1025it [00:02, 362.84it/s, env_step=154624, len=8, n/ep=7, n/st=64, player_1/loss=34.005, player_2/loss=2057.613, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #151: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #152: 1025it [00:02, 367.07it/s, env_step=155648, len=9, n/ep=7, n/st=64, player_1/loss=37.631, player_2/loss=2184.238, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #152: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #153: 1025it [00:02, 365.79it/s, env_step=156672, len=11, n/ep=6, n/st=64, player_1/loss=22.252, player_2/loss=2393.376, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #153: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #154: 1025it [00:02, 364.30it/s, env_step=157696, len=7, n/ep=8, n/st=64, player_1/loss=23.730, player_2/loss=2260.534, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #154: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #155: 1025it [00:02, 365.08it/s, env_step=158720, len=7, n/ep=9, n/st=64, player_1/loss=13.435, player_2/loss=2402.090, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #155: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #156: 1025it [00:02, 366.15it/s, env_step=159744, len=7, n/ep=8, n/st=64, player_1/loss=7.224, player_2/loss=2403.897, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #156: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #157: 1025it [00:02, 368.15it/s, env_step=160768, len=8, n/ep=8, n/st=64, player_1/loss=7.665, player_2/loss=2283.080, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #157: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #158: 1025it [00:02, 366.86it/s, env_step=161792, len=8, n/ep=8, n/st=64, player_2/loss=2434.773, rew=25.00]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #158: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #159: 1025it [00:02, 368.11it/s, env_step=162816, len=8, n/ep=8, n/st=64, player_1/loss=33.736, rew=18.75]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #159: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #160: 1025it [00:02, 363.90it/s, env_step=163840, len=9, n/ep=8, n/st=64, player_1/loss=27.339, player_2/loss=1765.938, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #160: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #161: 1025it [00:02, 360.82it/s, env_step=164864, len=8, n/ep=8, n/st=64, player_1/loss=24.008, player_2/loss=1749.773, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #161: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #162: 1025it [00:02, 373.12it/s, env_step=165888, len=9, n/ep=7, n/st=64, player_1/loss=28.918, player_2/loss=2119.197, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #162: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #163: 1025it [00:02, 378.03it/s, env_step=166912, len=8, n/ep=8, n/st=64, player_1/loss=18.479, player_2/loss=2348.857, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #163: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #164: 1025it [00:02, 367.16it/s, env_step=167936, len=8, n/ep=8, n/st=64, player_1/loss=8.572, player_2/loss=2280.234, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #164: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #165: 1025it [00:02, 364.02it/s, env_step=168960, len=7, n/ep=8, n/st=64, player_1/loss=33.438, player_2/loss=2273.959, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #165: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #166: 1025it [00:02, 366.52it/s, env_step=169984, len=8, n/ep=8, n/st=64, player_1/loss=12.793, player_2/loss=2118.660, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #166: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #167: 1025it [00:02, 365.73it/s, env_step=171008, len=8, n/ep=8, n/st=64, player_1/loss=7.058, player_2/loss=2112.861, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #167: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #168: 1025it [00:02, 364.53it/s, env_step=172032, len=9, n/ep=8, n/st=64, player_1/loss=15.117, player_2/loss=2037.433, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #168: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #169: 1025it [00:02, 363.93it/s, env_step=173056, len=7, n/ep=8, n/st=64, player_1/loss=24.700, player_2/loss=2168.837, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #169: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #170: 1025it [00:02, 364.57it/s, env_step=174080, len=8, n/ep=8, n/st=64, player_1/loss=17.668, player_2/loss=1853.506, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #170: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #171: 1025it [00:02, 365.87it/s, env_step=175104, len=9, n/ep=7, n/st=64, player_1/loss=14.503, player_2/loss=1610.035, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #171: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #172: 1025it [00:02, 364.71it/s, env_step=176128, len=7, n/ep=8, n/st=64, player_1/loss=24.578, player_2/loss=1743.678, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #172: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #173: 1025it [00:02, 368.90it/s, env_step=177152, len=8, n/ep=7, n/st=64, player_1/loss=16.893, player_2/loss=2045.419, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #173: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #174: 1025it [00:02, 365.69it/s, env_step=178176, len=7, n/ep=9, n/st=64, player_1/loss=20.632, player_2/loss=2109.750, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #174: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #175: 1025it [00:02, 367.27it/s, env_step=179200, len=7, n/ep=9, n/st=64, player_1/loss=22.204, player_2/loss=2101.720, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #175: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #176: 1025it [00:02, 365.42it/s, env_step=180224, len=8, n/ep=7, n/st=64, player_1/loss=19.293, player_2/loss=2211.319, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #176: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #177: 1025it [00:02, 366.78it/s, env_step=181248, len=7, n/ep=9, n/st=64, player_1/loss=23.636, player_2/loss=1947.041, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #177: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #178: 1025it [00:02, 366.08it/s, env_step=182272, len=10, n/ep=6, n/st=64, player_1/loss=45.365, player_2/loss=1787.204, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #178: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #179: 1025it [00:02, 364.80it/s, env_step=183296, len=8, n/ep=7, n/st=64, player_1/loss=51.571, player_2/loss=1811.477, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #179: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #180: 1025it [00:02, 365.60it/s, env_step=184320, len=8, n/ep=8, n/st=64, player_1/loss=28.389, player_2/loss=1966.145, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #180: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #181: 1025it [00:02, 365.73it/s, env_step=185344, len=8, n/ep=8, n/st=64, player_1/loss=18.906, player_2/loss=2113.293, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #181: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #182: 1025it [00:02, 366.29it/s, env_step=186368, len=7, n/ep=8, n/st=64, player_1/loss=8.228, player_2/loss=2092.432, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #182: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #183: 1025it [00:02, 366.13it/s, env_step=187392, len=9, n/ep=7, n/st=64, player_1/loss=11.119, player_2/loss=2010.311, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #183: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #184: 1025it [00:02, 366.61it/s, env_step=188416, len=8, n/ep=8, n/st=64, player_1/loss=11.005, player_2/loss=1825.016, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #184: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #185: 1025it [00:02, 365.88it/s, env_step=189440, len=7, n/ep=8, n/st=64, player_1/loss=11.081, player_2/loss=1957.921, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #185: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #186: 1025it [00:02, 365.22it/s, env_step=190464, len=9, n/ep=7, n/st=64, player_1/loss=6.055, player_2/loss=2081.165, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #186: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #187: 1025it [00:02, 365.22it/s, env_step=191488, len=8, n/ep=8, n/st=64, player_1/loss=7.903, player_2/loss=1842.249, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #187: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #188: 1025it [00:02, 364.91it/s, env_step=192512, len=8, n/ep=7, n/st=64, player_1/loss=5.943, player_2/loss=1964.809, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #188: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #189: 1025it [00:02, 366.70it/s, env_step=193536, len=7, n/ep=9, n/st=64, player_1/loss=7.273, rew=25.00]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #189: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #190: 1025it [00:02, 365.47it/s, env_step=194560, len=7, n/ep=8, n/st=64, player_1/loss=6.840, player_2/loss=2113.140, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #190: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #191: 1025it [00:02, 368.66it/s, env_step=195584, len=8, n/ep=8, n/st=64, player_1/loss=20.240, player_2/loss=2165.696, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #191: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #192: 1025it [00:02, 367.05it/s, env_step=196608, len=7, n/ep=8, n/st=64, player_1/loss=23.848, player_2/loss=2233.728, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #192: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #193: 1025it [00:02, 365.39it/s, env_step=197632, len=7, n/ep=9, n/st=64, player_1/loss=13.724, player_2/loss=2385.674, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #193: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #194: 1025it [00:02, 364.65it/s, env_step=198656, len=8, n/ep=8, n/st=64, player_1/loss=5.685, player_2/loss=2283.082, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #194: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #195: 1025it [00:02, 365.76it/s, env_step=199680, len=8, n/ep=7, n/st=64, player_1/loss=8.774, player_2/loss=2347.534, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #195: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #196: 1025it [00:02, 366.01it/s, env_step=200704, len=8, n/ep=8, n/st=64, player_1/loss=8.550, player_2/loss=2501.485, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #196: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #197: 1025it [00:02, 367.02it/s, env_step=201728, len=8, n/ep=8, n/st=64, player_1/loss=21.578, player_2/loss=2200.659, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #197: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #198: 1025it [00:02, 365.49it/s, env_step=202752, len=7, n/ep=9, n/st=64, player_1/loss=34.494, player_2/loss=2069.802, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #198: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #199: 1025it [00:02, 364.95it/s, env_step=203776, len=8, n/ep=8, n/st=64, player_1/loss=7.570, player_2/loss=1968.027, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #199: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #200: 1025it [00:02, 365.45it/s, env_step=204800, len=8, n/ep=7, n/st=64, player_1/loss=9.549, player_2/loss=2333.183, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #200: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #201: 1025it [00:02, 367.35it/s, env_step=205824, len=7, n/ep=9, n/st=64, player_1/loss=9.246, player_2/loss=2487.140, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #201: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #202: 1025it [00:02, 365.07it/s, env_step=206848, len=8, n/ep=8, n/st=64, player_1/loss=13.130, player_2/loss=2486.217, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #202: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #203: 1025it [00:02, 365.27it/s, env_step=207872, len=8, n/ep=7, n/st=64, player_1/loss=21.047, player_2/loss=2278.954, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #203: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #204: 1025it [00:02, 397.77it/s, env_step=208896, len=8, n/ep=7, n/st=64, player_1/loss=15.546, player_2/loss=2295.061, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #204: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #205: 1025it [00:02, 432.65it/s, env_step=209920, len=7, n/ep=9, n/st=64, player_1/loss=5.727, player_2/loss=1970.299, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #205: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #206: 1025it [00:02, 413.84it/s, env_step=210944, len=7, n/ep=8, n/st=64, player_1/loss=47.051, player_2/loss=2121.473, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #206: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #207: 1025it [00:02, 401.40it/s, env_step=211968, len=9, n/ep=7, n/st=64, player_1/loss=77.780, player_2/loss=2241.581, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #207: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #208: 1025it [00:02, 389.99it/s, env_step=212992, len=7, n/ep=9, n/st=64, player_1/loss=34.953, player_2/loss=2243.054, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #208: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #209: 1025it [00:02, 375.06it/s, env_step=214016, len=8, n/ep=8, n/st=64, player_1/loss=20.223, player_2/loss=2202.286, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #209: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #210: 1025it [00:02, 363.72it/s, env_step=215040, len=7, n/ep=6, n/st=64, player_1/loss=16.200, player_2/loss=2071.201, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #210: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #211: 1025it [00:02, 365.46it/s, env_step=216064, len=8, n/ep=8, n/st=64, player_1/loss=11.931, player_2/loss=2145.700, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #211: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #212: 1025it [00:02, 365.39it/s, env_step=217088, len=8, n/ep=8, n/st=64, player_1/loss=15.512, player_2/loss=2098.602, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #212: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #213: 1025it [00:02, 366.73it/s, env_step=218112, len=7, n/ep=8, n/st=64, player_1/loss=15.691, player_2/loss=2280.000, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #213: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #214: 1025it [00:02, 364.63it/s, env_step=219136, len=7, n/ep=9, n/st=64, player_1/loss=12.208, player_2/loss=2011.762, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #214: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #215: 1025it [00:02, 364.49it/s, env_step=220160, len=8, n/ep=8, n/st=64, player_1/loss=26.899, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #215: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #216: 1025it [00:02, 366.86it/s, env_step=221184, len=8, n/ep=8, n/st=64, player_1/loss=22.027, player_2/loss=2203.824, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #216: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #217: 1025it [00:02, 368.12it/s, env_step=222208, len=8, n/ep=7, n/st=64, player_1/loss=7.840, player_2/loss=2244.631, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #217: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #218: 1025it [00:02, 365.12it/s, env_step=223232, len=7, n/ep=10, n/st=64, player_1/loss=11.678, player_2/loss=2033.310, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #218: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #219: 1025it [00:02, 369.38it/s, env_step=224256, len=8, n/ep=8, n/st=64, player_1/loss=10.475, player_2/loss=2161.348, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #219: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #220: 1025it [00:02, 363.78it/s, env_step=225280, len=7, n/ep=9, n/st=64, player_1/loss=10.135, player_2/loss=2319.161, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #220: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #221: 1025it [00:02, 367.99it/s, env_step=226304, len=9, n/ep=7, n/st=64, player_1/loss=16.597, player_2/loss=1895.268, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #221: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #222: 1025it [00:02, 366.60it/s, env_step=227328, len=7, n/ep=6, n/st=64, player_1/loss=15.810, player_2/loss=1575.557, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #222: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #223: 1025it [00:02, 366.56it/s, env_step=228352, len=9, n/ep=7, n/st=64, player_1/loss=16.316, player_2/loss=1647.034, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #223: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #224: 1025it [00:02, 364.45it/s, env_step=229376, len=8, n/ep=7, n/st=64, player_1/loss=14.221, player_2/loss=2070.762, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #224: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #225: 1025it [00:02, 367.99it/s, env_step=230400, len=7, n/ep=9, n/st=64, player_1/loss=11.827, player_2/loss=2467.135, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #225: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #226: 1025it [00:02, 366.79it/s, env_step=231424, len=7, n/ep=8, n/st=64, player_1/loss=19.749, player_2/loss=2211.761, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #226: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #227: 1025it [00:02, 365.71it/s, env_step=232448, len=7, n/ep=7, n/st=64, player_1/loss=16.807, player_2/loss=1655.593, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #227: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #228: 1025it [00:02, 364.66it/s, env_step=233472, len=8, n/ep=8, n/st=64, player_1/loss=14.375, player_2/loss=1795.219, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #228: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #229: 1025it [00:02, 366.37it/s, env_step=234496, len=9, n/ep=7, n/st=64, player_1/loss=10.551, player_2/loss=2056.559, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #229: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #230: 1025it [00:02, 366.82it/s, env_step=235520, len=7, n/ep=8, n/st=64, player_1/loss=9.252, player_2/loss=2072.864, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #230: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #231: 1025it [00:02, 367.79it/s, env_step=236544, len=9, n/ep=6, n/st=64, player_1/loss=6.969, player_2/loss=2027.743, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #231: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #232: 1025it [00:02, 365.54it/s, env_step=237568, len=7, n/ep=9, n/st=64, player_1/loss=25.617, player_2/loss=2366.406, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #232: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #233: 1025it [00:02, 366.39it/s, env_step=238592, len=7, n/ep=8, n/st=64, player_1/loss=30.820, player_2/loss=2522.358, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #233: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #234: 1025it [00:02, 365.27it/s, env_step=239616, len=8, n/ep=7, n/st=64, player_1/loss=7.953, player_2/loss=2261.649, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #234: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #235: 1025it [00:02, 369.24it/s, env_step=240640, len=7, n/ep=9, n/st=64, player_1/loss=4.979, player_2/loss=2169.792, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #235: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #236: 1025it [00:02, 364.36it/s, env_step=241664, len=8, n/ep=8, n/st=64, player_1/loss=31.977, player_2/loss=2222.824, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #236: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #237: 1025it [00:02, 366.21it/s, env_step=242688, len=7, n/ep=8, n/st=64, player_1/loss=10.220, player_2/loss=2169.265, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #237: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #238: 1025it [00:02, 363.89it/s, env_step=243712, len=7, n/ep=8, n/st=64, player_1/loss=4.665, player_2/loss=2296.976, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #238: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #239: 1025it [00:02, 365.38it/s, env_step=244736, len=7, n/ep=10, n/st=64, player_1/loss=16.787, player_2/loss=2150.826, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #239: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #240: 1025it [00:02, 367.31it/s, env_step=245760, len=8, n/ep=8, n/st=64, player_1/loss=33.153, player_2/loss=1898.003, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #240: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #241: 1025it [00:02, 366.06it/s, env_step=246784, len=8, n/ep=6, n/st=64, player_1/loss=30.650, player_2/loss=1783.254, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #241: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #242: 1025it [00:02, 366.00it/s, env_step=247808, len=8, n/ep=8, n/st=64, player_1/loss=20.603, player_2/loss=1999.294, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #242: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #243: 1025it [00:02, 367.57it/s, env_step=248832, len=8, n/ep=8, n/st=64, player_1/loss=23.807, player_2/loss=2253.472, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #243: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #244: 1025it [00:02, 366.58it/s, env_step=249856, len=8, n/ep=8, n/st=64, player_1/loss=27.663, player_2/loss=2105.050, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #244: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #245: 1025it [00:02, 366.79it/s, env_step=250880, len=7, n/ep=8, n/st=64, player_1/loss=13.154, player_2/loss=2374.276, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #245: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #246: 1025it [00:02, 367.26it/s, env_step=251904, len=9, n/ep=7, n/st=64, player_1/loss=14.168, player_2/loss=2188.430, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #246: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #247: 1025it [00:02, 366.34it/s, env_step=252928, len=7, n/ep=9, n/st=64, player_1/loss=24.086, player_2/loss=2212.515, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #247: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #248: 1025it [00:02, 374.28it/s, env_step=253952, len=8, n/ep=7, n/st=64, player_1/loss=13.830, player_2/loss=2100.498, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #248: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #249: 1025it [00:02, 377.08it/s, env_step=254976, len=7, n/ep=8, n/st=64, player_1/loss=17.698, player_2/loss=2102.055, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #249: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #250: 1025it [00:02, 379.41it/s, env_step=256000, len=7, n/ep=8, n/st=64, player_1/loss=27.068, player_2/loss=1950.890, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #250: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #251: 1025it [00:02, 364.83it/s, env_step=257024, len=8, n/ep=8, n/st=64, player_1/loss=16.543, player_2/loss=2241.036, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #251: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #252: 1025it [00:02, 363.29it/s, env_step=258048, len=8, n/ep=8, n/st=64, player_1/loss=11.636, player_2/loss=2107.682, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #252: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #253: 1025it [00:02, 365.76it/s, env_step=259072, len=7, n/ep=8, n/st=64, player_1/loss=14.874, player_2/loss=2104.030, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #253: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #254: 1025it [00:02, 366.67it/s, env_step=260096, len=8, n/ep=7, n/st=64, player_1/loss=9.999, player_2/loss=2096.849, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #254: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #255: 1025it [00:02, 363.64it/s, env_step=261120, len=7, n/ep=9, n/st=64, player_1/loss=5.431, player_2/loss=2007.916, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #255: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #256: 1025it [00:02, 365.82it/s, env_step=262144, len=8, n/ep=8, n/st=64, player_1/loss=4.196, player_2/loss=2238.086, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #256: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #257: 1025it [00:02, 366.54it/s, env_step=263168, len=7, n/ep=5, n/st=64, player_1/loss=34.203, player_2/loss=2100.552, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #257: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #258: 1025it [00:02, 367.81it/s, env_step=264192, len=7, n/ep=8, n/st=64, player_1/loss=33.739, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #258: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #259: 1025it [00:02, 367.18it/s, env_step=265216, len=9, n/ep=7, n/st=64, player_1/loss=3.948, player_2/loss=2571.085, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #259: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #260: 1025it [00:02, 362.71it/s, env_step=266240, len=7, n/ep=10, n/st=64, player_1/loss=17.906, player_2/loss=2446.531, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #260: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #261: 1025it [00:02, 363.92it/s, env_step=267264, len=7, n/ep=8, n/st=64, player_1/loss=33.582, player_2/loss=2344.348, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #261: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #262: 1025it [00:02, 364.98it/s, env_step=268288, len=7, n/ep=9, n/st=64, player_1/loss=22.571, player_2/loss=2058.371, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #262: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #263: 1025it [00:02, 366.55it/s, env_step=269312, len=8, n/ep=7, n/st=64, player_1/loss=14.777, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #263: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #264: 1025it [00:02, 367.72it/s, env_step=270336, len=9, n/ep=7, n/st=64, player_1/loss=16.064, player_2/loss=1930.145, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #264: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #265: 1025it [00:02, 366.86it/s, env_step=271360, len=7, n/ep=8, n/st=64, player_1/loss=9.576, player_2/loss=1937.933, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #265: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #266: 1025it [00:02, 368.26it/s, env_step=272384, len=7, n/ep=8, n/st=64, player_1/loss=6.174, player_2/loss=2110.765, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #266: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #267: 1025it [00:02, 363.77it/s, env_step=273408, len=9, n/ep=7, n/st=64, player_1/loss=11.213, player_2/loss=2405.086, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #267: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #268: 1025it [00:02, 368.03it/s, env_step=274432, len=8, n/ep=7, n/st=64, player_1/loss=10.561, player_2/loss=2551.953, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #268: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #269: 1025it [00:02, 366.67it/s, env_step=275456, len=8, n/ep=8, n/st=64, player_1/loss=3.391, player_2/loss=2069.608, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #269: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #270: 1025it [00:02, 369.14it/s, env_step=276480, len=7, n/ep=8, n/st=64, player_1/loss=11.793, player_2/loss=2034.524, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #270: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #271: 1025it [00:02, 365.79it/s, env_step=277504, len=7, n/ep=9, n/st=64, player_1/loss=12.539, player_2/loss=2252.087, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #271: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #272: 1025it [00:02, 365.33it/s, env_step=278528, len=7, n/ep=9, n/st=64, player_1/loss=4.746, player_2/loss=2169.375, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #272: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #273: 1025it [00:02, 363.68it/s, env_step=279552, len=8, n/ep=8, n/st=64, player_1/loss=25.115, player_2/loss=1870.228, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #273: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #274: 1025it [00:02, 366.89it/s, env_step=280576, len=8, n/ep=8, n/st=64, player_1/loss=24.385, player_2/loss=1867.079, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #274: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #275: 1025it [00:02, 363.00it/s, env_step=281600, len=8, n/ep=7, n/st=64, player_1/loss=20.571, player_2/loss=1841.170, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #275: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #276: 1025it [00:02, 365.49it/s, env_step=282624, len=8, n/ep=8, n/st=64, player_1/loss=4.553, player_2/loss=2186.359, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #276: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #277: 1025it [00:02, 366.31it/s, env_step=283648, len=9, n/ep=6, n/st=64, player_1/loss=3.041, player_2/loss=2179.772, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #277: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #278: 1025it [00:02, 365.41it/s, env_step=284672, len=7, n/ep=8, n/st=64, player_1/loss=5.300, player_2/loss=2019.490, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #278: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #279: 1025it [00:02, 365.86it/s, env_step=285696, len=7, n/ep=9, n/st=64, player_1/loss=12.445, player_2/loss=2199.243, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #279: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #280: 1025it [00:02, 365.31it/s, env_step=286720, len=8, n/ep=7, n/st=64, player_1/loss=15.019, player_2/loss=2236.997, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #280: test_reward: -25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #281: 1025it [00:02, 364.71it/s, env_step=287744, len=8, n/ep=8, n/st=64, player_1/loss=8.233, player_2/loss=2323.372, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #281: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #282: 1025it [00:02, 365.89it/s, env_step=288768, len=7, n/ep=8, n/st=64, player_1/loss=37.257, player_2/loss=2464.416, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #282: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #283: 1025it [00:02, 365.83it/s, env_step=289792, len=7, n/ep=8, n/st=64, player_1/loss=48.356, player_2/loss=2384.235, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #283: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #284: 1025it [00:02, 367.72it/s, env_step=290816, len=8, n/ep=8, n/st=64, player_1/loss=17.799, player_2/loss=2040.683, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #284: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #285: 1025it [00:02, 359.72it/s, env_step=291840, len=9, n/ep=7, n/st=64, player_1/loss=36.416, player_2/loss=1926.745, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #285: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #286: 1025it [00:03, 337.69it/s, env_step=292864, len=7, n/ep=9, n/st=64, player_1/loss=20.025, player_2/loss=2077.481, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #286: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #287: 1025it [00:02, 376.96it/s, env_step=293888, len=7, n/ep=8, n/st=64, player_1/loss=7.002, player_2/loss=2251.962, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #287: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #288: 1025it [00:02, 368.20it/s, env_step=294912, len=7, n/ep=9, n/st=64, player_1/loss=15.531, player_2/loss=2086.424, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #288: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #289: 1025it [00:02, 411.46it/s, env_step=295936, len=9, n/ep=7, n/st=64, player_1/loss=24.896, player_2/loss=2215.729, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #289: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #290: 1025it [00:03, 299.54it/s, env_step=296960, len=7, n/ep=8, n/st=64, player_1/loss=20.223, player_2/loss=2228.825, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #290: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #291: 1025it [00:03, 265.47it/s, env_step=297984, len=8, n/ep=7, n/st=64, player_1/loss=10.649, player_2/loss=2129.518, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #291: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #292: 1025it [00:03, 299.32it/s, env_step=299008, len=7, n/ep=8, n/st=64, player_1/loss=8.937, player_2/loss=2158.608, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #292: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #293: 1025it [00:02, 346.03it/s, env_step=300032, len=7, n/ep=9, n/st=64, player_1/loss=9.664, player_2/loss=2257.694, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #293: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #294: 1025it [00:02, 383.88it/s, env_step=301056, len=9, n/ep=7, n/st=64, player_1/loss=11.221, player_2/loss=2305.347, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #294: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #295: 1025it [00:02, 377.09it/s, env_step=302080, len=8, n/ep=8, n/st=64, player_1/loss=7.517, player_2/loss=2694.357, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #295: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #296: 1025it [00:02, 430.28it/s, env_step=303104, len=8, n/ep=9, n/st=64, player_1/loss=11.921, player_2/loss=2401.254, rew=19.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #296: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #297: 1025it [00:02, 416.96it/s, env_step=304128, len=8, n/ep=7, n/st=64, player_1/loss=15.460, player_2/loss=2192.599, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #297: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #298: 1025it [00:02, 440.32it/s, env_step=305152, len=9, n/ep=8, n/st=64, player_1/loss=11.669, player_2/loss=1877.262, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #298: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #299: 1025it [00:02, 409.67it/s, env_step=306176, len=7, n/ep=9, n/st=64, player_1/loss=21.399, player_2/loss=1699.820, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #299: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #300: 1025it [00:02, 434.95it/s, env_step=307200, len=7, n/ep=9, n/st=64, player_1/loss=33.816, player_2/loss=1834.083, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #300: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #301: 1025it [00:02, 444.22it/s, env_step=308224, len=7, n/ep=8, n/st=64, player_1/loss=22.514, player_2/loss=1988.856, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #301: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #302: 1025it [00:02, 448.05it/s, env_step=309248, len=7, n/ep=8, n/st=64, player_1/loss=16.055, player_2/loss=2019.815, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #302: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #303: 1025it [00:02, 390.52it/s, env_step=310272, len=7, n/ep=8, n/st=64, player_1/loss=30.557, player_2/loss=2209.543, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #303: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #304: 1025it [00:02, 407.37it/s, env_step=311296, len=8, n/ep=8, n/st=64, player_1/loss=20.538, player_2/loss=2194.258, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #304: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #305: 1025it [00:02, 363.26it/s, env_step=312320, len=7, n/ep=8, n/st=64, player_1/loss=9.427, player_2/loss=2211.839, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #305: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #306: 1025it [00:02, 444.20it/s, env_step=313344, len=8, n/ep=8, n/st=64, player_1/loss=9.679, player_2/loss=2026.739, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #306: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #307: 1025it [00:02, 443.44it/s, env_step=314368, len=7, n/ep=8, n/st=64, player_1/loss=13.145, player_2/loss=2214.164, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #307: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #308: 1025it [00:02, 454.56it/s, env_step=315392, len=9, n/ep=7, n/st=64, player_1/loss=12.324, player_2/loss=2077.446, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #308: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #309: 1025it [00:02, 443.69it/s, env_step=316416, len=8, n/ep=8, n/st=64, player_1/loss=6.408, player_2/loss=2103.656, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #309: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #310: 1025it [00:02, 417.08it/s, env_step=317440, len=8, n/ep=7, n/st=64, player_1/loss=10.813, player_2/loss=2150.970, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #310: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #311: 1025it [00:02, 404.48it/s, env_step=318464, len=7, n/ep=9, n/st=64, player_1/loss=6.445, player_2/loss=2243.094, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #311: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #312: 1025it [00:02, 376.90it/s, env_step=319488, len=8, n/ep=8, n/st=64, player_1/loss=10.109, player_2/loss=2107.304, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #312: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #313: 1025it [00:02, 380.48it/s, env_step=320512, len=8, n/ep=8, n/st=64, player_1/loss=10.448, player_2/loss=1915.181, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #313: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #314: 1025it [00:02, 378.32it/s, env_step=321536, len=8, n/ep=8, n/st=64, player_1/loss=2.739, player_2/loss=2152.990, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #314: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #315: 1025it [00:02, 405.71it/s, env_step=322560, len=8, n/ep=8, n/st=64, player_1/loss=2.765, player_2/loss=2017.418, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #315: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #316: 1025it [00:02, 393.50it/s, env_step=323584, len=9, n/ep=8, n/st=64, player_1/loss=7.203, player_2/loss=2032.634, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #316: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #317: 1025it [00:02, 406.32it/s, env_step=324608, len=7, n/ep=8, n/st=64, player_1/loss=11.470, player_2/loss=2014.777, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #317: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #318: 1025it [00:03, 325.99it/s, env_step=325632, len=8, n/ep=7, n/st=64, player_1/loss=13.475, player_2/loss=2010.601, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #318: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #319: 1025it [00:02, 366.14it/s, env_step=326656, len=7, n/ep=9, n/st=64, player_1/loss=10.648, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #319: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #320: 1025it [00:02, 408.58it/s, env_step=327680, len=7, n/ep=9, n/st=64, player_1/loss=12.911, player_2/loss=2023.813, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #320: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #321: 1025it [00:02, 391.67it/s, env_step=328704, len=7, n/ep=8, n/st=64, player_1/loss=6.566, player_2/loss=2450.903, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #321: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #322: 1025it [00:02, 411.68it/s, env_step=329728, len=7, n/ep=9, n/st=64, player_1/loss=13.293, player_2/loss=2692.135, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #322: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #323: 1025it [00:02, 416.99it/s, env_step=330752, len=7, n/ep=9, n/st=64, player_1/loss=13.565, player_2/loss=2529.017, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #323: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #324: 1025it [00:02, 427.09it/s, env_step=331776, len=7, n/ep=8, n/st=64, player_1/loss=14.810, player_2/loss=2079.587, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #324: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #325: 1025it [00:02, 425.21it/s, env_step=332800, len=9, n/ep=7, n/st=64, player_1/loss=10.929, player_2/loss=2108.034, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #325: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #326: 1025it [00:02, 430.76it/s, env_step=333824, len=7, n/ep=8, n/st=64, player_1/loss=2.789, player_2/loss=2221.553, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #326: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #327: 1025it [00:02, 457.12it/s, env_step=334848, len=8, n/ep=8, n/st=64, player_1/loss=5.792, player_2/loss=2213.182, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #327: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #328: 1025it [00:02, 437.71it/s, env_step=335872, len=8, n/ep=8, n/st=64, player_1/loss=6.712, player_2/loss=2184.360, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #328: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #329: 1025it [00:02, 471.61it/s, env_step=336896, len=7, n/ep=8, n/st=64, player_1/loss=20.521, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #329: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #330: 1025it [00:02, 429.58it/s, env_step=337920, len=7, n/ep=7, n/st=64, player_1/loss=20.966, player_2/loss=1851.115, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #330: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #331: 1025it [00:02, 428.67it/s, env_step=338944, len=8, n/ep=8, n/st=64, player_1/loss=6.025, player_2/loss=1870.687, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #331: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #332: 1025it [00:02, 393.77it/s, env_step=339968, len=8, n/ep=8, n/st=64, player_1/loss=9.226, player_2/loss=1798.296, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #332: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #333: 1025it [00:02, 392.11it/s, env_step=340992, len=7, n/ep=8, n/st=64, player_1/loss=19.475, player_2/loss=1841.350, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #333: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #334: 1025it [00:02, 398.60it/s, env_step=342016, len=7, n/ep=8, n/st=64, player_1/loss=21.116, player_2/loss=1996.408, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #334: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #335: 1025it [00:02, 374.45it/s, env_step=343040, len=8, n/ep=8, n/st=64, player_1/loss=9.342, player_2/loss=2407.511, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #335: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #336: 1025it [00:02, 378.75it/s, env_step=344064, len=7, n/ep=8, n/st=64, player_1/loss=2.474, player_2/loss=2694.475, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #336: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #337: 1025it [00:02, 383.42it/s, env_step=345088, len=8, n/ep=8, n/st=64, player_1/loss=6.106, player_2/loss=2646.188, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #337: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #338: 1025it [00:02, 370.87it/s, env_step=346112, len=9, n/ep=7, n/st=64, player_1/loss=8.041, player_2/loss=2377.635, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #338: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #339: 1025it [00:02, 361.39it/s, env_step=347136, len=7, n/ep=8, n/st=64, player_1/loss=7.618, player_2/loss=1941.459, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #339: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #340: 1025it [00:02, 389.81it/s, env_step=348160, len=7, n/ep=9, n/st=64, player_1/loss=4.995, player_2/loss=1958.559, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #340: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #341: 1025it [00:02, 397.20it/s, env_step=349184, len=7, n/ep=9, n/st=64, player_1/loss=2.636, player_2/loss=2192.595, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #341: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #342: 1025it [00:02, 383.25it/s, env_step=350208, len=7, n/ep=9, n/st=64, player_1/loss=5.726, player_2/loss=1889.478, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #342: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #343: 1025it [00:02, 387.03it/s, env_step=351232, len=7, n/ep=9, n/st=64, player_1/loss=17.204, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #343: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #344: 1025it [00:02, 373.09it/s, env_step=352256, len=8, n/ep=8, n/st=64, player_1/loss=14.746, player_2/loss=2603.433, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #344: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #345: 1025it [00:02, 414.99it/s, env_step=353280, len=7, n/ep=8, n/st=64, player_1/loss=15.226, player_2/loss=2094.978, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #345: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #346: 1025it [00:02, 405.84it/s, env_step=354304, len=7, n/ep=8, n/st=64, player_1/loss=16.079, player_2/loss=2040.186, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #346: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #347: 1025it [00:02, 402.20it/s, env_step=355328, len=7, n/ep=8, n/st=64, player_1/loss=10.205, player_2/loss=1865.433, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #347: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #348: 1025it [00:02, 408.34it/s, env_step=356352, len=8, n/ep=8, n/st=64, player_1/loss=14.321, player_2/loss=1692.295, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #348: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #349: 1025it [00:02, 402.09it/s, env_step=357376, len=7, n/ep=8, n/st=64, player_1/loss=9.993, player_2/loss=1816.944, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #349: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #350: 1025it [00:02, 413.38it/s, env_step=358400, len=8, n/ep=8, n/st=64, player_1/loss=7.976, player_2/loss=2200.651, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #350: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #351: 1025it [00:02, 416.45it/s, env_step=359424, len=8, n/ep=8, n/st=64, player_1/loss=16.345, player_2/loss=2196.429, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #351: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #352: 1025it [00:02, 423.13it/s, env_step=360448, len=7, n/ep=9, n/st=64, player_1/loss=17.056, player_2/loss=2114.341, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #352: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #353: 1025it [00:02, 421.35it/s, env_step=361472, len=7, n/ep=8, n/st=64, player_1/loss=5.569, player_2/loss=2061.470, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #353: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #354: 1025it [00:02, 410.61it/s, env_step=362496, len=7, n/ep=8, n/st=64, player_1/loss=5.707, player_2/loss=1996.404, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #354: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #355: 1025it [00:02, 396.41it/s, env_step=363520, len=7, n/ep=8, n/st=64, player_1/loss=13.804, player_2/loss=2335.445, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #355: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #356: 1025it [00:02, 393.02it/s, env_step=364544, len=7, n/ep=8, n/st=64, player_1/loss=25.995, player_2/loss=2246.081, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #356: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #357: 1025it [00:02, 409.85it/s, env_step=365568, len=9, n/ep=7, n/st=64, player_1/loss=20.612, player_2/loss=2131.736, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #357: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #358: 1025it [00:02, 402.25it/s, env_step=366592, len=8, n/ep=8, n/st=64, player_1/loss=4.614, player_2/loss=2311.219, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #358: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #359: 1025it [00:03, 336.48it/s, env_step=367616, len=8, n/ep=7, n/st=64, player_1/loss=1.305, player_2/loss=2164.683, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #359: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #360: 1025it [00:02, 350.03it/s, env_step=368640, len=7, n/ep=9, n/st=64, player_1/loss=4.229, player_2/loss=2165.153, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #360: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #361: 1025it [00:03, 334.74it/s, env_step=369664, len=7, n/ep=9, n/st=64, player_1/loss=7.628, player_2/loss=2118.939, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #361: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #362: 1025it [00:02, 366.20it/s, env_step=370688, len=7, n/ep=8, n/st=64, player_1/loss=4.300, player_2/loss=2166.384, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #362: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #363: 1025it [00:02, 418.83it/s, env_step=371712, len=9, n/ep=7, n/st=64, player_1/loss=6.653, player_2/loss=2471.722, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #363: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #364: 1025it [00:02, 432.45it/s, env_step=372736, len=7, n/ep=8, n/st=64, player_1/loss=25.747, player_2/loss=2350.983, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #364: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #365: 1025it [00:02, 417.86it/s, env_step=373760, len=7, n/ep=8, n/st=64, player_1/loss=27.670, player_2/loss=2397.742, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #365: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #366: 1025it [00:02, 405.41it/s, env_step=374784, len=8, n/ep=8, n/st=64, player_1/loss=12.534, player_2/loss=2326.599, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #366: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #367: 1025it [00:02, 389.68it/s, env_step=375808, len=8, n/ep=6, n/st=64, player_1/loss=7.366, player_2/loss=1932.143, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #367: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #368: 1025it [00:02, 365.18it/s, env_step=376832, len=10, n/ep=6, n/st=64, player_1/loss=27.452, player_2/loss=1530.323, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #368: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #369: 1025it [00:02, 378.85it/s, env_step=377856, len=9, n/ep=7, n/st=64, player_1/loss=26.911, player_2/loss=1414.791, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #369: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #370: 1025it [00:02, 379.36it/s, env_step=378880, len=10, n/ep=7, n/st=64, player_1/loss=10.526, player_2/loss=1500.789, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #370: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #371: 1025it [00:02, 362.10it/s, env_step=379904, len=10, n/ep=6, n/st=64, player_1/loss=14.691, player_2/loss=1719.682, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #371: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #372: 1025it [00:02, 365.26it/s, env_step=380928, len=9, n/ep=7, n/st=64, player_1/loss=9.336, player_2/loss=1920.922, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #372: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #373: 1025it [00:02, 451.43it/s, env_step=381952, len=9, n/ep=7, n/st=64, player_1/loss=7.588, player_2/loss=1813.524, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #373: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #374: 1025it [00:02, 456.23it/s, env_step=382976, len=11, n/ep=6, n/st=64, player_1/loss=9.377, player_2/loss=1882.586, rew=16.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #374: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #375: 1025it [00:02, 459.54it/s, env_step=384000, len=13, n/ep=5, n/st=64, player_1/loss=28.588, player_2/loss=1988.598, rew=15.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #375: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #376: 1025it [00:02, 440.84it/s, env_step=385024, len=8, n/ep=8, n/st=64, player_1/loss=118.550, player_2/loss=1743.149, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #376: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #377: 1025it [00:02, 445.18it/s, env_step=386048, len=9, n/ep=7, n/st=64, player_1/loss=145.844, player_2/loss=1559.001, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #377: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #378: 1025it [00:02, 455.28it/s, env_step=387072, len=7, n/ep=8, n/st=64, player_1/loss=92.450, player_2/loss=2083.603, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #378: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #379: 1025it [00:02, 438.82it/s, env_step=388096, len=7, n/ep=9, n/st=64, player_1/loss=65.587, player_2/loss=1972.338, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #379: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #380: 1025it [00:02, 454.35it/s, env_step=389120, len=8, n/ep=8, n/st=64, player_1/loss=57.692, player_2/loss=1902.946, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #380: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #381: 1025it [00:02, 453.78it/s, env_step=390144, len=7, n/ep=9, n/st=64, player_1/loss=54.378, player_2/loss=2159.434, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #381: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #382: 1025it [00:02, 449.55it/s, env_step=391168, len=7, n/ep=8, n/st=64, player_1/loss=52.338, player_2/loss=2249.807, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #382: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #383: 1025it [00:02, 456.72it/s, env_step=392192, len=8, n/ep=8, n/st=64, player_1/loss=51.689, player_2/loss=1916.527, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #383: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #384: 1025it [00:02, 443.26it/s, env_step=393216, len=7, n/ep=9, n/st=64, player_1/loss=61.833, player_2/loss=2122.789, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #384: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #385: 1025it [00:02, 421.80it/s, env_step=394240, len=7, n/ep=8, n/st=64, player_1/loss=51.587, player_2/loss=2360.319, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #385: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #386: 1025it [00:02, 438.36it/s, env_step=395264, len=8, n/ep=8, n/st=64, player_1/loss=43.849, player_2/loss=2264.615, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #386: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #387: 1025it [00:02, 396.23it/s, env_step=396288, len=8, n/ep=8, n/st=64, player_1/loss=33.646, player_2/loss=1867.193, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #387: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #388: 1025it [00:02, 391.97it/s, env_step=397312, len=8, n/ep=7, n/st=64, player_1/loss=28.489, player_2/loss=1877.678, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #388: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #389: 1025it [00:02, 390.70it/s, env_step=398336, len=7, n/ep=9, n/st=64, player_1/loss=23.777, player_2/loss=1848.951, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #389: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #390: 1025it [00:02, 376.43it/s, env_step=399360, len=8, n/ep=8, n/st=64, player_1/loss=31.947, player_2/loss=2068.239, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #390: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #391: 1025it [00:02, 358.61it/s, env_step=400384, len=8, n/ep=8, n/st=64, player_1/loss=59.250, player_2/loss=2154.810, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #391: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #392: 1025it [00:02, 379.73it/s, env_step=401408, len=7, n/ep=9, n/st=64, player_1/loss=74.099, player_2/loss=2011.068, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #392: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #393: 1025it [00:02, 419.70it/s, env_step=402432, len=7, n/ep=7, n/st=64, player_1/loss=42.447, player_2/loss=1660.080, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #393: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #394: 1025it [00:02, 399.48it/s, env_step=403456, len=7, n/ep=9, n/st=64, player_1/loss=31.316, player_2/loss=1677.629, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #394: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #395: 1025it [00:02, 414.68it/s, env_step=404480, len=8, n/ep=8, n/st=64, player_1/loss=25.108, player_2/loss=1772.894, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #395: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #396: 1025it [00:02, 423.58it/s, env_step=405504, len=8, n/ep=8, n/st=64, player_1/loss=21.628, player_2/loss=2101.266, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #396: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #397: 1025it [00:02, 453.51it/s, env_step=406528, len=8, n/ep=8, n/st=64, player_1/loss=23.931, player_2/loss=2029.919, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #397: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #398: 1025it [00:02, 431.58it/s, env_step=407552, len=8, n/ep=8, n/st=64, player_1/loss=23.261, player_2/loss=1846.938, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #398: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #399: 1025it [00:02, 394.63it/s, env_step=408576, len=8, n/ep=8, n/st=64, player_1/loss=19.739, player_2/loss=1773.630, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #399: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #400: 1025it [00:02, 386.03it/s, env_step=409600, len=7, n/ep=8, n/st=64, player_1/loss=39.302, player_2/loss=2096.749, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #400: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #401: 1025it [00:02, 422.84it/s, env_step=410624, len=10, n/ep=6, n/st=64, player_1/loss=41.060, player_2/loss=1923.355, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #401: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #402: 1025it [00:02, 423.65it/s, env_step=411648, len=7, n/ep=9, n/st=64, player_1/loss=29.932, player_2/loss=1981.260, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #402: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #403: 1025it [00:02, 396.78it/s, env_step=412672, len=7, n/ep=9, n/st=64, player_1/loss=41.848, player_2/loss=1877.240, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #403: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #404: 1025it [00:02, 447.86it/s, env_step=413696, len=7, n/ep=8, n/st=64, player_1/loss=38.213, player_2/loss=1549.595, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #404: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #405: 1025it [00:02, 438.48it/s, env_step=414720, len=9, n/ep=7, n/st=64, player_1/loss=26.321, player_2/loss=1472.345, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #405: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #406: 1025it [00:02, 450.24it/s, env_step=415744, len=12, n/ep=6, n/st=64, player_1/loss=27.296, player_2/loss=1857.383, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #406: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #407: 1025it [00:02, 451.05it/s, env_step=416768, len=7, n/ep=9, n/st=64, player_1/loss=26.061, player_2/loss=2022.576, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #407: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #408: 1025it [00:02, 448.52it/s, env_step=417792, len=7, n/ep=9, n/st=64, player_1/loss=22.295, player_2/loss=2019.519, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #408: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #409: 1025it [00:02, 399.84it/s, env_step=418816, len=8, n/ep=8, n/st=64, player_1/loss=21.092, player_2/loss=1915.799, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #409: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #410: 1025it [00:02, 422.59it/s, env_step=419840, len=8, n/ep=7, n/st=64, player_1/loss=29.366, player_2/loss=1957.258, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #410: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #411: 1025it [00:02, 405.86it/s, env_step=420864, len=7, n/ep=8, n/st=64, player_1/loss=31.157, player_2/loss=2058.732, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #411: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #412: 1025it [00:02, 426.14it/s, env_step=421888, len=7, n/ep=8, n/st=64, player_1/loss=26.159, player_2/loss=2019.786, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #412: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #413: 1025it [00:02, 414.58it/s, env_step=422912, len=7, n/ep=8, n/st=64, player_1/loss=29.873, player_2/loss=1933.304, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #413: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #414: 1025it [00:02, 418.02it/s, env_step=423936, len=8, n/ep=8, n/st=64, player_1/loss=24.107, player_2/loss=1920.563, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #414: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #415: 1025it [00:02, 434.00it/s, env_step=424960, len=7, n/ep=9, n/st=64, player_1/loss=26.286, player_2/loss=1988.838, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #415: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #416: 1025it [00:02, 415.07it/s, env_step=425984, len=9, n/ep=7, n/st=64, player_1/loss=23.870, player_2/loss=1921.038, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #416: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #417: 1025it [00:02, 424.96it/s, env_step=427008, len=7, n/ep=9, n/st=64, player_1/loss=29.943, player_2/loss=1935.776, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #417: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #418: 1025it [00:02, 463.78it/s, env_step=428032, len=8, n/ep=8, n/st=64, player_1/loss=24.868, player_2/loss=1773.797, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #418: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #419: 1025it [00:02, 464.50it/s, env_step=429056, len=8, n/ep=8, n/st=64, player_1/loss=42.827, player_2/loss=1423.342, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #419: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #420: 1025it [00:02, 460.97it/s, env_step=430080, len=7, n/ep=9, n/st=64, player_1/loss=45.918, player_2/loss=1680.890, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #420: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #421: 1025it [00:02, 464.73it/s, env_step=431104, len=8, n/ep=8, n/st=64, player_1/loss=33.237, player_2/loss=1760.177, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #421: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #422: 1025it [00:02, 463.80it/s, env_step=432128, len=7, n/ep=9, n/st=64, player_1/loss=29.930, player_2/loss=1919.411, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #422: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #423: 1025it [00:02, 458.27it/s, env_step=433152, len=8, n/ep=8, n/st=64, player_1/loss=28.229, player_2/loss=1880.360, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #423: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #424: 1025it [00:02, 463.76it/s, env_step=434176, len=7, n/ep=8, n/st=64, player_1/loss=24.478, player_2/loss=2161.889, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #424: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #425: 1025it [00:02, 461.62it/s, env_step=435200, len=7, n/ep=9, n/st=64, player_1/loss=23.853, player_2/loss=2273.059, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #425: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #426: 1025it [00:02, 450.98it/s, env_step=436224, len=8, n/ep=7, n/st=64, player_1/loss=14.411, player_2/loss=2406.472, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #426: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #427: 1025it [00:02, 463.91it/s, env_step=437248, len=7, n/ep=8, n/st=64, player_1/loss=25.325, player_2/loss=2346.701, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #427: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #428: 1025it [00:02, 462.59it/s, env_step=438272, len=7, n/ep=8, n/st=64, player_1/loss=26.764, player_2/loss=1913.529, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #428: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #429: 1025it [00:02, 464.25it/s, env_step=439296, len=7, n/ep=9, n/st=64, player_1/loss=15.571, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #429: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #430: 1025it [00:02, 458.77it/s, env_step=440320, len=8, n/ep=8, n/st=64, player_1/loss=14.049, player_2/loss=2083.554, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #430: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #431: 1025it [00:02, 463.72it/s, env_step=441344, len=8, n/ep=8, n/st=64, player_1/loss=23.098, player_2/loss=2113.632, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #431: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #432: 1025it [00:02, 458.32it/s, env_step=442368, len=8, n/ep=8, n/st=64, player_1/loss=16.258, player_2/loss=2056.939, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #432: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #433: 1025it [00:02, 460.96it/s, env_step=443392, len=7, n/ep=9, n/st=64, player_1/loss=15.809, player_2/loss=2153.644, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #433: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #434: 1025it [00:02, 461.21it/s, env_step=444416, len=7, n/ep=7, n/st=64, player_1/loss=11.080, player_2/loss=2313.542, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #434: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #435: 1025it [00:02, 463.46it/s, env_step=445440, len=8, n/ep=8, n/st=64, player_1/loss=15.705, player_2/loss=2163.544, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #435: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #436: 1025it [00:02, 462.15it/s, env_step=446464, len=8, n/ep=8, n/st=64, player_1/loss=18.277, player_2/loss=2120.261, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #436: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #437: 1025it [00:02, 454.88it/s, env_step=447488, len=8, n/ep=7, n/st=64, player_1/loss=14.145, player_2/loss=2069.583, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #437: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #438: 1025it [00:02, 432.52it/s, env_step=448512, len=9, n/ep=7, n/st=64, player_1/loss=14.689, player_2/loss=2129.523, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #438: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #439: 1025it [00:02, 351.87it/s, env_step=449536, len=8, n/ep=8, n/st=64, player_1/loss=14.653, player_2/loss=2498.367, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #439: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #440: 1025it [00:03, 339.43it/s, env_step=450560, len=8, n/ep=8, n/st=64, player_1/loss=15.383, player_2/loss=2008.808, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #440: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #441: 1025it [00:02, 424.54it/s, env_step=451584, len=8, n/ep=7, n/st=64, player_1/loss=26.764, player_2/loss=1883.493, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #441: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #442: 1025it [00:02, 399.03it/s, env_step=452608, len=7, n/ep=9, n/st=64, player_1/loss=19.900, player_2/loss=1974.247, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #442: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #443: 1025it [00:02, 408.83it/s, env_step=453632, len=7, n/ep=9, n/st=64, player_1/loss=29.669, player_2/loss=1936.352, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #443: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #444: 1025it [00:02, 444.80it/s, env_step=454656, len=11, n/ep=5, n/st=64, player_1/loss=40.555, player_2/loss=1759.976, rew=5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #444: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #445: 1025it [00:02, 440.67it/s, env_step=455680, len=7, n/ep=8, n/st=64, player_1/loss=32.236, player_2/loss=1912.771, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #445: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #446: 1025it [00:02, 441.98it/s, env_step=456704, len=8, n/ep=7, n/st=64, player_1/loss=25.543, player_2/loss=2076.236, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #446: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #447: 1025it [00:02, 444.63it/s, env_step=457728, len=7, n/ep=8, n/st=64, player_1/loss=21.438, player_2/loss=2260.965, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #447: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #448: 1025it [00:02, 439.82it/s, env_step=458752, len=7, n/ep=8, n/st=64, player_1/loss=9.812, player_2/loss=2288.214, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #448: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #449: 1025it [00:02, 428.95it/s, env_step=459776, len=7, n/ep=8, n/st=64, player_1/loss=11.553, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #449: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #450: 1025it [00:02, 380.47it/s, env_step=460800, len=9, n/ep=7, n/st=64, player_1/loss=19.419, player_2/loss=2054.058, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #450: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #451: 1025it [00:02, 395.15it/s, env_step=461824, len=9, n/ep=8, n/st=64, player_1/loss=21.921, player_2/loss=1983.993, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #451: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #452: 1025it [00:02, 440.57it/s, env_step=462848, len=7, n/ep=8, n/st=64, player_1/loss=24.123, player_2/loss=2400.233, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #452: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #453: 1025it [00:02, 439.80it/s, env_step=463872, len=8, n/ep=8, n/st=64, player_1/loss=41.146, player_2/loss=2118.403, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #453: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #454: 1025it [00:02, 440.68it/s, env_step=464896, len=7, n/ep=8, n/st=64, player_1/loss=31.132, player_2/loss=2168.308, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #454: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #455: 1025it [00:02, 437.70it/s, env_step=465920, len=7, n/ep=8, n/st=64, player_1/loss=12.136, player_2/loss=1856.638, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #455: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #456: 1025it [00:02, 441.24it/s, env_step=466944, len=7, n/ep=8, n/st=64, player_1/loss=13.874, player_2/loss=1908.489, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #456: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #457: 1025it [00:02, 420.94it/s, env_step=467968, len=7, n/ep=8, n/st=64, player_1/loss=23.607, player_2/loss=1942.734, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #457: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #458: 1025it [00:02, 405.18it/s, env_step=468992, len=7, n/ep=8, n/st=64, player_1/loss=21.147, player_2/loss=1964.278, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #458: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #459: 1025it [00:02, 402.53it/s, env_step=470016, len=9, n/ep=7, n/st=64, player_1/loss=13.312, player_2/loss=1875.946, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #459: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #460: 1025it [00:02, 458.91it/s, env_step=471040, len=8, n/ep=8, n/st=64, player_1/loss=24.749, player_2/loss=2012.505, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #460: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #461: 1025it [00:02, 458.06it/s, env_step=472064, len=8, n/ep=7, n/st=64, player_1/loss=19.740, player_2/loss=2033.405, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #461: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #462: 1025it [00:02, 450.43it/s, env_step=473088, len=7, n/ep=8, n/st=64, player_1/loss=16.021, player_2/loss=2005.410, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #462: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #463: 1025it [00:02, 449.50it/s, env_step=474112, len=8, n/ep=7, n/st=64, player_1/loss=22.755, player_2/loss=1858.660, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #463: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #464: 1025it [00:02, 454.00it/s, env_step=475136, len=7, n/ep=9, n/st=64, player_1/loss=20.576, player_2/loss=1804.277, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #464: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #465: 1025it [00:02, 450.65it/s, env_step=476160, len=8, n/ep=8, n/st=64, player_1/loss=21.526, player_2/loss=1907.760, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #465: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #466: 1025it [00:02, 448.64it/s, env_step=477184, len=8, n/ep=8, n/st=64, player_1/loss=14.578, player_2/loss=1891.461, rew=18.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #466: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #467: 1025it [00:02, 454.26it/s, env_step=478208, len=8, n/ep=8, n/st=64, player_1/loss=12.132, player_2/loss=2015.140, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #467: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #468: 1025it [00:02, 457.35it/s, env_step=479232, len=7, n/ep=8, n/st=64, player_1/loss=11.907, player_2/loss=2086.621, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #468: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #469: 1025it [00:02, 456.28it/s, env_step=480256, len=7, n/ep=8, n/st=64, player_1/loss=9.800, player_2/loss=2257.145, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #469: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #470: 1025it [00:02, 463.75it/s, env_step=481280, len=7, n/ep=9, n/st=64, player_1/loss=15.754, player_2/loss=2033.828, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #470: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #471: 1025it [00:02, 461.44it/s, env_step=482304, len=7, n/ep=8, n/st=64, player_1/loss=15.922, player_2/loss=1942.350, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #471: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #472: 1025it [00:02, 457.56it/s, env_step=483328, len=9, n/ep=7, n/st=64, player_1/loss=11.732, player_2/loss=1865.700, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #472: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #473: 1025it [00:02, 456.90it/s, env_step=484352, len=7, n/ep=9, n/st=64, player_1/loss=17.632, player_2/loss=1907.476, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #473: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #474: 1025it [00:02, 459.12it/s, env_step=485376, len=7, n/ep=8, n/st=64, player_1/loss=29.695, player_2/loss=1884.374, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #474: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #475: 1025it [00:02, 460.26it/s, env_step=486400, len=7, n/ep=9, n/st=64, player_1/loss=36.524, player_2/loss=1943.375, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #475: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #476: 1025it [00:02, 460.50it/s, env_step=487424, len=8, n/ep=8, n/st=64, player_1/loss=31.263, player_2/loss=1740.426, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #476: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #477: 1025it [00:02, 441.39it/s, env_step=488448, len=8, n/ep=8, n/st=64, player_1/loss=27.264, player_2/loss=1854.979, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #477: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #478: 1025it [00:02, 431.01it/s, env_step=489472, len=10, n/ep=6, n/st=64, player_1/loss=16.115, player_2/loss=2008.762, rew=8.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #478: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #479: 1025it [00:02, 387.31it/s, env_step=490496, len=7, n/ep=8, n/st=64, player_1/loss=9.554, player_2/loss=1919.581, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #479: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #480: 1025it [00:02, 389.12it/s, env_step=491520, len=7, n/ep=9, n/st=64, player_1/loss=12.717, player_2/loss=1846.085, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #480: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #481: 1025it [00:02, 366.54it/s, env_step=492544, len=8, n/ep=7, n/st=64, player_1/loss=17.957, player_2/loss=1767.173, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #481: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #482: 1025it [00:02, 350.56it/s, env_step=493568, len=7, n/ep=8, n/st=64, player_1/loss=13.135, player_2/loss=1928.158, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #482: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #483: 1025it [00:02, 368.64it/s, env_step=494592, len=16, n/ep=4, n/st=64, player_1/loss=20.432, player_2/loss=1923.534, rew=12.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #483: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #484: 1025it [00:02, 368.58it/s, env_step=495616, len=9, n/ep=7, n/st=64, player_1/loss=24.653, player_2/loss=2080.934, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #484: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #485: 1025it [00:02, 367.38it/s, env_step=496640, len=7, n/ep=8, n/st=64, player_1/loss=18.848, player_2/loss=2179.602, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #485: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #486: 1025it [00:02, 359.43it/s, env_step=497664, len=11, n/ep=6, n/st=64, player_1/loss=17.461, player_2/loss=2219.586, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #486: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #487: 1025it [00:02, 373.71it/s, env_step=498688, len=7, n/ep=8, n/st=64, player_1/loss=16.695, player_2/loss=2337.896, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #487: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #488: 1025it [00:02, 369.53it/s, env_step=499712, len=7, n/ep=9, n/st=64, player_1/loss=22.980, player_2/loss=2075.954, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #488: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #489: 1025it [00:02, 377.33it/s, env_step=500736, len=7, n/ep=9, n/st=64, player_1/loss=21.095, player_2/loss=1994.048, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #489: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #490: 1025it [00:02, 362.39it/s, env_step=501760, len=9, n/ep=7, n/st=64, player_1/loss=18.374, player_2/loss=1955.109, rew=17.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #490: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #491: 1025it [00:02, 346.20it/s, env_step=502784, len=7, n/ep=8, n/st=64, player_1/loss=21.073, rew=25.00]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #491: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #492: 1025it [00:02, 351.19it/s, env_step=503808, len=7, n/ep=9, n/st=64, player_1/loss=15.185, player_2/loss=2272.296, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #492: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #493: 1025it [00:02, 355.15it/s, env_step=504832, len=7, n/ep=8, n/st=64, player_1/loss=14.712, player_2/loss=2375.737, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #493: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #494: 1025it [00:02, 354.88it/s, env_step=505856, len=7, n/ep=9, n/st=64, player_1/loss=27.065, player_2/loss=2255.785, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #494: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #495: 1025it [00:02, 441.30it/s, env_step=506880, len=7, n/ep=8, n/st=64, player_1/loss=32.924, player_2/loss=1817.314, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #495: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #496: 1025it [00:02, 436.35it/s, env_step=507904, len=8, n/ep=8, n/st=64, player_1/loss=10.852, player_2/loss=1793.304, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #496: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #497: 1025it [00:02, 441.38it/s, env_step=508928, len=7, n/ep=8, n/st=64, player_1/loss=13.332, player_2/loss=1675.778, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #497: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #498: 1025it [00:02, 437.59it/s, env_step=509952, len=7, n/ep=9, n/st=64, player_1/loss=15.270, player_2/loss=1903.228, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #498: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #499: 1025it [00:02, 439.32it/s, env_step=510976, len=7, n/ep=8, n/st=64, player_1/loss=18.556, player_2/loss=1950.944, rew=25.00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #499: test_reward: 25.000000 ± 0.000000, best_reward: 100.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: TRAINING AGENTS\n",
    "####################################################\n",
    "\n",
    "# Configs for the agents\n",
    "freeze_agent1 = False\n",
    "agent1_starting_params = \"./saved_variables/paper_notebooks/7/2-cnn_dqn_frozen_agent2/best_policy_agent1.pth\"\n",
    "\n",
    "freeze_agent2 = True\n",
    "agent2_starting_params = \"./saved_variables/paper_notebooks/7/3-cnn_dqn_frozen_agent1/best_policy_agent2.pth\"\n",
    "\n",
    "single_agent_score_as_reward = True # To use combined reward or non frozen agent reward as scoring\n",
    "filename = \"4-cnn_dqn_frozen_agent2\"\n",
    "epochs = 50\n",
    "\n",
    "learning_rate = 0.000001\n",
    "training_eps = 0.1\n",
    "gamma = 0.8\n",
    "n_step = 4\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure agent 1\n",
    "agent1 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                           action_shape= action_shape,\n",
    "                           gamma= gamma,\n",
    "                           frozen= freeze_agent1,\n",
    "                           learning_rate = learning_rate,\n",
    "                           n_step= n_step)\n",
    "\n",
    "if agent1_starting_params:\n",
    "    agent1.load_state_dict(torch.load(agent1_starting_params))\n",
    "\n",
    "# Configure agent 2\n",
    "agent2 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                           action_shape= action_shape,\n",
    "                           gamma= gamma,\n",
    "                           frozen= freeze_agent2,\n",
    "                           learning_rate = learning_rate,\n",
    "                           n_step= n_step)\n",
    "\n",
    "if agent2_starting_params:\n",
    "    agent2.load_state_dict(torch.load(agent2_starting_params))\n",
    "\n",
    "\n",
    "# Train the agent\n",
    "off_policy_traininer_results, final_agent_player1, final_agent_player2 = train_agent(epochs= epochs,\n",
    "                                                                                     agent_player1= agent1,\n",
    "                                                                                     agent_player1_frozen = freeze_agent1,\n",
    "                                                                                     agent_player2= agent2,\n",
    "                                                                                     agent_player2_frozen = freeze_agent2,\n",
    "                                                                                     filename= filename,\n",
    "                                                                                     single_agent_score_as_reward = single_agent_score_as_reward,\n",
    "                                                                                     training_eps= training_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c8f3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  38.666666666666664\n",
      "Final mean reward agent 1: 50.0, std: 35.35533905932738\n",
      "Final mean reward agent 2: 16.666666666666668, std: 58.92556509887896\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE BEST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure the best agent\n",
    "best_agent1 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                action_shape= action_shape)\n",
    "best_agent1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/7/4-cnn_dqn_frozen_agent2/best_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "\n",
    "best_agent2 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                action_shape= action_shape)\n",
    "best_agent2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/7/3-cnn_dqn_frozen_agent1/best_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= best_agent1,\n",
    "      agent_player2= best_agent2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c704acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  7.0\n",
      "Final mean reward agent 1: 25.0, std: 0.0\n",
      "Final mean reward agent 2: -25.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE LAST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Configure the final agent\n",
    "final_agent_player1 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                        action_shape= action_shape)\n",
    "final_agent_player1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/7/4-cnn_dqn_frozen_agent2/final_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "final_agent_player2 = cf_cnn_dqn_policy(state_shape= state_shape,\n",
    "                                        action_shape= action_shape)\n",
    "final_agent_player2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/7/3-cnn_dqn_frozen_agent1/best_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= final_agent_player1,\n",
    "      agent_player2= final_agent_player2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84478519",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The performance of this model based on a CNN is similar to the previous model used.\n",
    "We will address other difficult points in the next notebooks to build an appropriate bot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d9110be",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CLEAN VARIABLES\n",
    "####################################################\n",
    "\n",
    "del action_shape\n",
    "del agent1\n",
    "del agent2\n",
    "del best_agent1\n",
    "del best_agent2\n",
    "del env\n",
    "del final_agent_player1\n",
    "del final_agent_player2\n",
    "del observation_space\n",
    "del off_policy_traininer_results\n",
    "del state_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d3da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b88c88564fefe7444548986d165ad8d7f764d0079ffa923785a3f5a89d52c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
