{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Using the Rainbow algorithm to learn connect four\n",
    "\n",
    "The previous notebooks all used Deep Q-Networks (DQN) to learn to play connect four and no real desired behaviour was obtained.\n",
    "Since rainbow by [Hessel et al](https://doi.org/10.48550/arXiv.1710.02298) is known to outperform DQN in both sample efficiency and overall performance for Atari games, we explore its performance on the connect four game as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Contact information\n",
    "- Checking requirements\n",
    "  - Correct Anaconda environment\n",
    "  - Correct module access\n",
    "  - Correct CUDA access\n",
    "- Training two Rainbow agents on connect four Gym\n",
    "  - Building the environment\n",
    "  - Implementing the Rainbow policy\n",
    "  - Building agents\n",
    "  - Function for letting agents learn\n",
    "  - Function for watching learned agent\n",
    "  - Doing the experiment\n",
    "- Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Contact information\n",
    "\n",
    "| Name             | Student ID | VUB mail                                                  | Personal mail                                               |\n",
    "| ---------------- | ---------- | --------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Lennert Bontinck | 0568702    | [lennert.bontinck@vub.be](mailto:lennert.bontinck@vub.be) | [info@lennertbontinck.com](mailto:info@lennertbontinck.com) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a405d24",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements\n",
    "\n",
    "### Correct Anaconda environment\n",
    "\n",
    "The `rl-project` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the RL course project and homeworks](https://github.com/pikawika/vub-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: rl-project\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'rl-project'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following code block will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version (3.5.1 recommended): 3.5.1\n",
      "Pygame version (2.1.2 recommended): 2.1.2\n",
      "Gym version (0.21.0 recommended): 0.21.0\n",
      "Tianshou version (0.4.8 recommended): 0.4.8\n",
      "Torch version (1.12.0 recommended): 1.12.0.dev20220520+cu116\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Allow reloading of libraries\n",
    "import importlib\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Argparser\n",
    "import argparse\n",
    "\n",
    "# More data types\n",
    "import typing\n",
    "import numpy as np\n",
    "\n",
    "# Pygame\n",
    "import pygame; print(f\"Pygame version (2.1.2 recommended): {pygame.__version__}\")\n",
    "\n",
    "# Gym environment\n",
    "import gym; print(f\"Gym version (0.21.0 recommended): {gym.__version__}\")\n",
    "\n",
    "# Tianshou for RL algorithms\n",
    "import tianshou as ts; print(f\"Tianshou version (0.4.8 recommended): {ts.__version__}\")\n",
    "\n",
    "# Torch is a popular DL framework\n",
    "import torch; print(f\"Torch version (1.12.0 recommended): {torch.__version__}\")\n",
    "\n",
    "# PPrint is a pretty print for variables\n",
    "from pprint import pprint\n",
    "\n",
    "# Our custom connect four gym environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import gym_connect4_pygame.envs.ConnectFourPygameEnvV2 as cfgym\n",
    "importlib.invalidate_caches()\n",
    "importlib.reload(cfgym)\n",
    "\n",
    "# Time for allowing \"freezes\" in execution\n",
    "import time;\n",
    "\n",
    "# Allow for copying objects in a non reference manner\n",
    "import copy\n",
    "\n",
    "# Used for updating notebook display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617a21",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct CUDA access\n",
    "\n",
    "The installation instructions specify how to install PyTorch with CUDA 11.6.\n",
    "The following code block tests if this was done successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9f5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "\n",
      "Amount of connected devices supporting CUDA: 1\n",
      "\n",
      "Current CUDA device: 0\n",
      "Cuda device 0 name: NVIDIA GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CUDA VALIDATION\n",
    "####################################################\n",
    "\n",
    "# Check cuda available\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Show cuda devices\n",
    "print(f\"\\nAmount of connected devices supporting CUDA: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Show current cuda device\n",
    "print(f\"\\nCurrent CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "# Show cuda device name\n",
    "print(f\"Cuda device 0 name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826657c4",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Training two Rainbow agents on connect four Gym\n",
    "\n",
    "Our connect four gym setup requires two agents, one for each player.\n",
    "To reduce complexity, agents will always play as the same player, e.g. always as player 1.\n",
    "It is important to note that connect four is a *solved game*.\n",
    "According to [The Washington Post](https://www.washingtonpost.com/news/wonk/wp/2015/05/08/how-to-win-any-popular-game-according-to-data-scientists/):\n",
    "\n",
    "> Connect Four is what mathematicians call a \"solved game,\" meaning you can play it perfectly every time, no matter what your opponent does. You will need to get the first move, but as long as you do so, you can always win within 41 moves.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Building the environment\n",
    "\n",
    "This code is taken from previous notebooks.\n",
    "We don't allow invalid moves to make the problem easier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b47a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]], [[2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]], (6, 7), int8))\n",
      "\n",
      "Action space: Discrete(7)\n",
      "\n",
      " Initial player id:\n",
      "player_1\n",
      "\n",
      " Initial observation:\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " Initial mask:\n",
      "[True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CONNECT FOUR V2 ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "def get_env():\n",
    "    \"\"\"\n",
    "    Returns the connect four gym environment V2 altered for Tianshou and Petting Zoo compatibility.\n",
    "    Already wrapped with a ts.env.PettingZooEnv wrapper.\n",
    "    \"\"\"\n",
    "    return ts.env.PettingZooEnv(cfgym.env(reward_move= 0, # Set to 1 for reward to make moves (incentivise longer games)\n",
    "                                          reward_blocking= 1, # Set to 1 for reward to make blocking moves (incentivise defensive games)\n",
    "                                          reward_invalid= -3,\n",
    "                                          reward_draw= 3,\n",
    "                                          reward_win= 5,\n",
    "                                          reward_loss= -5,\n",
    "                                          allow_invalid_move= False))\n",
    "    \n",
    "    \n",
    "# Test the environment\n",
    "env = get_env()\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"\\nAction space: {env.action_space}\")\n",
    "\n",
    "# Reset the environment to start from a clean state, returns the initial observation\n",
    "observation = env.reset()\n",
    "\n",
    "print(\"\\n Initial player id:\")\n",
    "print(observation[\"agent_id\"])\n",
    "\n",
    "print(\"\\n Initial observation:\")\n",
    "print(observation[\"obs\"])\n",
    "\n",
    "print(\"\\n Initial mask:\")\n",
    "print(observation[\"mask\"])\n",
    "\n",
    "# Clean unused variables\n",
    "del observation\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c2e15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "Blocking move made by player 1: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# BLOCKING MOVE CHECK\n",
    "####################################################\n",
    "\n",
    "# Check if a reward is received for playing a blocking move\n",
    "\n",
    "env = get_env()\n",
    "env.reset()\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(f\"Blocking move made by player 1: {env.rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7e7da",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Implementing the Rainbow policy\n",
    "\n",
    "The Rainbow policy for the agent is configured and set up below.\n",
    "This is based on the Atari rainbow example by the [Tianshou doc](https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py).\n",
    "Tianshou uses a DQN as base class for Rainbow, so we will do this to but adopt both classes to better represent our previous DQN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2f43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# DQN ARCHITECTURE\n",
    "####################################################\n",
    "\n",
    "class CNNForRainbow(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom CNN to be used as baseclass for the Rainbow algorithm.\n",
    "    Extracts \"feautures\" for the Rainbow algorithm by doing a 4x4 cnn kernel pass and providing 16 filters.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_shape: typing.Sequence[int],\n",
    "                 device: typing.Union[str, int, torch.device] = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        \n",
    "        # Torch init\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store device to be used\n",
    "        self.device = device\n",
    "        \n",
    "        # The input layer is singular -> we have 1 board vector\n",
    "        input_channels_cnn = 1\n",
    "        \n",
    "        # We output 64/16 filters per kernel \n",
    "        output_channels_cnn = 64 # Updated from previous 16\n",
    "        \n",
    "        # We store the output dimension of the CNN \"feature\" layer\n",
    "        self.output_dim = (state_shape[0] - 3) * (state_shape[1] - 3) * output_channels_cnn\n",
    "        \n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels= input_channels_cnn, out_channels= output_channels_cnn, kernel_size= 4, stride= 1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                obs: typing.Union[np.ndarray, torch.Tensor],\n",
    "                state: typing.Optional[typing.Any] = None,\n",
    "                info: typing.Dict[str, typing.Any] = {}):\n",
    "        # Make a torch instance (from regular vector of board)\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float, device=self.device)\n",
    "            \n",
    "        # Tianshou bugs the batch output, reshape to work properly with our torch version\n",
    "        if (len(np.shape(obs)) != 4):\n",
    "            obs = obs[:, None, :, :]\n",
    "        \n",
    "        # Return what is needed (network output & state)\n",
    "        return self.net(obs), state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b137ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RAINBOW ARCHITECTURE\n",
    "####################################################\n",
    "\n",
    "class Rainbow(CNNForRainbow):\n",
    "    \"\"\"\n",
    "    Implementation of the Rainbow algorithm making using of the CNNForRainbow baseclass.\n",
    "    Default parameters adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 state_shape: typing.Sequence[int],\n",
    "                 action_shape: typing.Sequence[int],\n",
    "                 device: typing.Union[str, int, torch.device] = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                 num_atoms: int = 51,\n",
    "                 is_noisy: bool = True,\n",
    "                 noisy_std: float = 0.1,\n",
    "                 is_dueling: bool = True):\n",
    "        \n",
    "        # Init CNN feature extraction parent class\n",
    "        super().__init__(state_shape= state_shape, device= device)\n",
    "        \n",
    "        # the amount of actions we have is just the action shape\n",
    "        self.action_num = np.prod(action_shape)\n",
    "        \n",
    "        # Store class specific info\n",
    "        self.num_atoms = num_atoms\n",
    "        self._is_dueling = is_dueling\n",
    "\n",
    "        # Our linear layer depends on wether or not we want to use a noisy environment\n",
    "        # Noisy implementation based on https://arxiv.org/abs/1706.10295\n",
    "        def linear(x, y):\n",
    "            if is_noisy:\n",
    "                return ts.utils.net.discrete.NoisyLinear(x, y, noisy_std)\n",
    "            else:\n",
    "                return torch.nn.Linear(x, y)\n",
    "            \n",
    "        # Specify Q and V based on wether or not agent is dueling\n",
    "        # Setting agent on dueling mode should help generalisation according to rainbow paper\n",
    "        # NOTE: this uses the output dim from the feature extraction CNN\n",
    "        self.Q = torch.nn.Sequential(\n",
    "            linear(self.output_dim, 512), torch.nn.ReLU(inplace=True),\n",
    "            linear(512, self.action_num * self.num_atoms))\n",
    "        \n",
    "        if self._is_dueling:\n",
    "            self.V = torch.nn.Sequential(\n",
    "                linear(self.output_dim, 512), torch.nn.ReLU(inplace=True),\n",
    "                linear(512, self.num_atoms))\n",
    "            \n",
    "        # New output dim for this rainbow network\n",
    "        self.output_dim = self.action_num * self.num_atoms\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                obs: typing.Union[np.ndarray, torch.Tensor],\n",
    "                state: typing.Optional[typing.Any] = None,\n",
    "                info: typing.Dict[str, typing.Any] = {}):\n",
    "        \n",
    "        # Use our parent CNN based network to get \"features\"\n",
    "        obs, state = super().forward(obs)\n",
    "        \n",
    "        # Get our Rainbow specific values\n",
    "        q = self.Q(obs)\n",
    "        q = q.view(-1, self.action_num, self.num_atoms)\n",
    "        \n",
    "        if self._is_dueling:\n",
    "            v = self.V(obs)\n",
    "            v = v.view(-1, 1, self.num_atoms)\n",
    "            logits = q - q.mean(dim=1, keepdim=True) + v\n",
    "        else:\n",
    "            logits = q\n",
    "        \n",
    "        # We need to go from our logits to an accepted dimension of probability outputs\n",
    "        probs = logits.softmax(dim=2)\n",
    "        \n",
    "        return probs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RAINBOW POLICY\n",
    "####################################################\n",
    "\n",
    "def rainbow_policy(state_shape: tuple,\n",
    "                   action_shape: tuple,\n",
    "                   optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                   learning_rate: float =  0.0000625,\n",
    "                   gamma: float = 0.9,\n",
    "                   n_step: int = 3, # Number of steps to look ahead\n",
    "                   num_atoms: int = 51,\n",
    "                   is_noisy: bool = True,\n",
    "                   noisy_std: float = 0.1,\n",
    "                   is_dueling: bool = True,\n",
    "                   target_update_freq: int = 500):\n",
    "    \"\"\"\n",
    "    Implementation of the Rainbow policy.\n",
    "    Default parameters adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use cuda device if possible\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Rainbow network to be used by policy\n",
    "    net = Rainbow(state_shape= state_shape,\n",
    "                  action_shape= action_shape,\n",
    "                  device= device,\n",
    "                  num_atoms= num_atoms,\n",
    "                  is_noisy= is_noisy,\n",
    "                  noisy_std= noisy_std,\n",
    "                  is_dueling= is_dueling).to(device)\n",
    "    \n",
    "    # Default optimizer is an adam optimizer with the argparser learning rate\n",
    "    if optim is None:\n",
    "        optim = torch.optim.Adam(net.parameters(), lr= learning_rate)\n",
    "        \n",
    "    # Our agents Rainbow policy\n",
    "    return ts.policy.RainbowPolicy(model= net,\n",
    "                                   optim= optim,\n",
    "                                   discount_factor= gamma,\n",
    "                                   num_atoms= num_atoms,\n",
    "                                   estimation_step= n_step,\n",
    "                                   target_update_freq= target_update_freq).to(device)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd411318",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Building agents\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06d25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT CREATION\n",
    "####################################################\n",
    "\n",
    "def get_agent_manager(agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                      agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                      optim: typing.Optional[torch.optim.Optimizer] = None):\n",
    "    \"\"\"\n",
    "    Gets a multi agent policy manager, optimizer and player ids for the connect four V2 gym environment.\n",
    "    Per default this returns \n",
    "        - Multi agent manager for 2 agents using Rainbow\n",
    "        - Adam optimizer\n",
    "        - ['player_1', 'player_2'] from the connect four environment\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the environment to play in (Connect four gym V2)\n",
    "    env = get_env()\n",
    "    \n",
    "    # Get the observation space from the environment, depending on typo of space (ternary operator)\n",
    "    observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "    \n",
    "    # Set the arguments\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    \n",
    "    # Configure agent player 1 to be a Rainbow if no policy is passed.\n",
    "    if agent_player1 is None:\n",
    "        # Our agent1 uses a Rainbow policy\n",
    "        agent_player1 = rainbow_policy(state_shape= state_shape,\n",
    "                                       action_shape= action_shape,\n",
    "                                       optim= optim)\n",
    "    \n",
    "    # Configure agent player 2 to be a Rainbow if no policy is passed.\n",
    "    if agent_player2 is None:\n",
    "        # Our agent1 uses a Rainbow policy\n",
    "        agent_player2 = rainbow_policy(state_shape= state_shape,\n",
    "                                       action_shape= action_shape,\n",
    "                                       optim= optim)\n",
    "\n",
    "    # Default order of the agents\n",
    "    agents = [agent_player1, agent_player2]\n",
    "        \n",
    "    # Create the multi agent policy\n",
    "    policy = ts.policy.MultiAgentPolicyManager(agents, env)\n",
    "    \n",
    "    # Return our policy, optimizer and the available agents in the environment\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using Rainbow\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    \n",
    "    return policy, optim, env.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8f3a6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for letting agents learn\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d364383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT TRAINING\n",
    "####################################################\n",
    "\n",
    "def train_agent(filename: str = \"rainbow_vs_rainbow\",\n",
    "                agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                training_env_num: int = 10,\n",
    "                testing_env_num: int = 10,\n",
    "                buffer_size: int = 100000,\n",
    "                batch_size: int = 32, \n",
    "                epochs: int = 50,\n",
    "                step_per_epoch: int = 100000,\n",
    "                step_per_collect: int = 10, # Should be multiple of the test/training envs\n",
    "                update_per_step: float = 0.1,\n",
    "                testing_eps: float = 0.005,\n",
    "                training_eps_init: float = 1,\n",
    "                training_eps_final: float = 0.05):\n",
    "    \"\"\"\n",
    "    Trains two agents in the connect four V2 environment and saves their best model and logs.\n",
    "    Returns:\n",
    "        - result from offpolicy_trainer\n",
    "        - final version of agent 1\n",
    "        - final version of agent 2\n",
    "    Defaults adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "\n",
    "    # ======== notebook specific =========\n",
    "    notebook_version = '9' # Used for foldering logs and models\n",
    "\n",
    "    # ======== environment setup =========\n",
    "    train_envs = ts.env.DummyVectorEnv([get_env for _ in range(training_env_num)])\n",
    "    test_envs = ts.env.DummyVectorEnv([get_env for _ in range(testing_env_num)])\n",
    "    \n",
    "    # set the seed for reproducibility\n",
    "    np.random.seed(1998)\n",
    "    torch.manual_seed(1998)\n",
    "    train_envs.seed(1998)\n",
    "    test_envs.seed(1998)\n",
    "\n",
    "    # ======== agent setup =========\n",
    "    # Gets our agents from the previously made function\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using Rainbow\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    policy, optim, agents = get_agent_manager(agent_player1=agent_player1,\n",
    "                                              agent_player2=agent_player2,\n",
    "                                              optim=optim)\n",
    "\n",
    "    # ======== collector setup =========\n",
    "    # Make a collector for the training environments\n",
    "    buffer= ts.data.VectorReplayBuffer(total_size= buffer_size,\n",
    "                                       buffer_num=len(train_envs))\n",
    "    \n",
    "    train_collector = ts.data.Collector(policy= policy,\n",
    "                                        env= train_envs,\n",
    "                                        buffer= buffer,\n",
    "                                        exploration_noise= True)\n",
    "    \n",
    "    # Make a collector for the testing environments\n",
    "    test_collector = ts.data.Collector(policy= policy,\n",
    "                                       env= test_envs,\n",
    "                                       exploration_noise= True)\n",
    "    \n",
    "    # ======== ensure folders exist =========\n",
    "    if not os.path.exists(os.path.join('./logs', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./logs', 'paper_notebooks', notebook_version, filename))\n",
    "    if not os.path.exists(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename))\n",
    "\n",
    "    # ======== tensorboard logging setup =========\n",
    "    # Allows to save the training progress to tensorboard compatable logs\n",
    "    log_path = os.path.join('./logs', 'paper_notebooks', notebook_version, filename)\n",
    "    writer = torch.utils.tensorboard.SummaryWriter(log_path)\n",
    "    logger = ts.utils.TensorboardLogger(writer)\n",
    "\n",
    "    # ======== callback functions used during training =========\n",
    "    # We want to save our best policy\n",
    "    def save_best_fn(policy):\n",
    "        \"\"\"\n",
    "        Callback to save the best model\n",
    "        \"\"\"\n",
    "        # Save best agent 1\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent1.pth')\n",
    "        torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save best agent 2\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent2.pth')\n",
    "        torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save agent2\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        \"\"\"\n",
    "        Callback to stop training when we've reached the win rate\n",
    "        \"\"\"\n",
    "        return False # Not implemented\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback before training, sets the training epsilon in a decaying manner.\n",
    "        Adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "        \"\"\"        \n",
    "        # Nature DQN setting to have a \"linear decaying epsilon\" for the first one million iterations\n",
    "        if env_step <= 1000000:\n",
    "            training_eps = training_eps_init - env_step / 1000000 * (training_eps_init - training_eps_final)\n",
    "        else:\n",
    "            training_eps = training_eps_final\n",
    "            \n",
    "            \n",
    "        # Set epsilon\n",
    "        policy.policies[agents[0]].set_eps(training_eps)\n",
    "        policy.policies[agents[1]].set_eps(training_eps)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback beore testing, sets the testing epsilon.\n",
    "        \"\"\"        \n",
    "        # Before testing we want to configure the epsilon for the agents\n",
    "        # In general more greedy than the train case but not\n",
    "        #   to avoid getting stuck on invalid moves\n",
    "        policy.policies[agents[0]].set_eps(testing_eps)\n",
    "        policy.policies[agents[1]].set_eps(testing_eps)\n",
    "\n",
    "    def reward_metric(rews):\n",
    "        \"\"\"\n",
    "        Callback for reward collection.\n",
    "        Currently the reward is the sum of both agents.\n",
    "        \"\"\"        \n",
    "        # We are interested in having a high total total reward,\n",
    "        #   as this would mean equally good agents.\n",
    "        return rews[:, 0] + rews[:, 1]\n",
    "\n",
    "    # ======== Training =========\n",
    "    # off policy training\n",
    "    result = ts.trainer.offpolicy_trainer(policy= policy,\n",
    "                                          train_collector= train_collector,\n",
    "                                          test_collector= test_collector,\n",
    "                                          max_epoch= epochs,\n",
    "                                          step_per_epoch= step_per_epoch,\n",
    "                                          step_per_collect= step_per_collect,\n",
    "                                          episode_per_test= testing_env_num,\n",
    "                                          batch_size= batch_size,\n",
    "                                          train_fn= train_fn,\n",
    "                                          test_fn= test_fn,\n",
    "                                          stop_fn= stop_fn,\n",
    "                                          save_best_fn= save_best_fn,\n",
    "                                          update_per_step= update_per_step,\n",
    "                                          logger= logger,\n",
    "                                          test_in_train= False,\n",
    "                                          reward_metric= reward_metric)\n",
    "    \n",
    "    # Save final agent 1\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent1.pth')\n",
    "    torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "\n",
    "    # Save final agent 2\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent2.pth')\n",
    "    torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "\n",
    "    return result, policy.policies[agents[0]], policy.policies[agents[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161cc0f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for watching learned agent\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b526e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# WATCHING THE LEARNED POLICY IN ACTION\n",
    "####################################################\n",
    "\n",
    "def watch(numer_of_games: int = 3,\n",
    "          agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          test_epsilon: float = 0.005, # For the watching we act completely greedy but low random for not getting stuck on invalid move\n",
    "          render_speed: float = 0.15, # Amount of seconds to update frame/ do a step\n",
    "          ) -> None:\n",
    "    \n",
    "    # Get the connect four V2 environment (must be a list)\n",
    "    env= ts.env.DummyVectorEnv([get_env])\n",
    "    \n",
    "    # Get the agents from the trained agents\n",
    "    policy, optim, agents = get_agent_manager(agent_player1= agent_player1,\n",
    "                                              agent_player2= agent_player2)\n",
    "    \n",
    "    # Evaluate the policy\n",
    "    policy.eval()\n",
    "    \n",
    "    # Set the testing policy epsilon for our agents\n",
    "    policy.policies[agents[0]].set_eps(test_epsilon)\n",
    "    policy.policies[agents[1]].set_eps(test_epsilon)\n",
    "    \n",
    "    # Collect the test data\n",
    "    collector = ts.data.Collector(policy= policy,\n",
    "                                  env= env,\n",
    "                                  exploration_noise= True)\n",
    "    \n",
    "    # Render games in human mode to see how it plays\n",
    "    result = collector.collect(n_episode= numer_of_games, render= render_speed)\n",
    "    \n",
    "    # Close the environment aftering collecting the results\n",
    "    # This closes the pygame window after completion\n",
    "    env.close()\n",
    "    \n",
    "    # Get the rewards and length from the test trials\n",
    "    rewards, length = result[\"rews\"], result[\"lens\"]\n",
    "    \n",
    "    # Print the final reward for the first agent\n",
    "    print(f\"Average steps of game:  {length.mean()}\")\n",
    "    print(f\"Final mean reward agent 1: {rewards[:, 0].mean()}, std: {rewards[:, 0].std()}\")\n",
    "    print(f\"Final mean reward agent 2: {rewards[:, 1].mean()}, std: {rewards[:, 1].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31784e9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Doing the experiment\n",
    "\n",
    "We now do the experiment with using our previously created functions.\n",
    "We update some parameter settings to find if we can improve our DQN agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c453e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 10001it [00:34, 286.73it/s, env_step=10000, len=30, n/ep=0, n/st=10, player_1/loss=2.870, player_2/loss=2.906, rew=15.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 14.000000 ± 0.000000, best_reward: 14.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 10001it [00:33, 294.67it/s, env_step=20000, len=18, n/ep=0, n/st=10, player_1/loss=2.396, player_2/loss=2.533, rew=5.50]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 6.000000 ± 0.000000, best_reward: 14.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 10001it [00:34, 286.22it/s, env_step=30000, len=22, n/ep=0, n/st=10, player_1/loss=2.144, player_2/loss=2.369, rew=15.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 8.000000 ± 0.000000, best_reward: 14.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 10001it [00:33, 300.87it/s, env_step=40000, len=17, n/ep=0, n/st=10, player_1/loss=2.082, player_2/loss=2.311, rew=0.00]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 0.000000 ± 0.000000, best_reward: 14.000000 ± 0.000000 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 10001it [00:33, 295.42it/s, env_step=50000, len=28, n/ep=0, n/st=10, player_1/loss=2.037, player_2/loss=2.267, rew=0.00]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 50.400000 ± 13.800000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 10001it [00:33, 294.44it/s, env_step=60000, len=16, n/ep=0, n/st=10, player_1/loss=2.068, player_2/loss=2.299, rew=0.00]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 0.400000 ± 1.200000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 10001it [00:33, 297.97it/s, env_step=70000, len=20, n/ep=0, n/st=10, player_1/loss=2.074, player_2/loss=2.306, rew=9.00]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 14.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 10001it [00:33, 295.81it/s, env_step=80000, len=28, n/ep=0, n/st=10, player_1/loss=2.038, player_2/loss=2.352, rew=8.00]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 10001it [00:33, 296.52it/s, env_step=90000, len=19, n/ep=0, n/st=10, player_1/loss=2.040, player_2/loss=2.298, rew=6.50]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 18.400000 ± 1.800000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 10001it [00:33, 296.49it/s, env_step=100000, len=13, n/ep=1, n/st=10, player_1/loss=2.016, player_2/loss=2.308, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 10001it [00:33, 296.82it/s, env_step=110000, len=18, n/ep=0, n/st=10, player_1/loss=2.034, player_2/loss=2.287, rew=15.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 15.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 10001it [00:33, 296.83it/s, env_step=120000, len=11, n/ep=0, n/st=10, player_1/loss=2.026, player_2/loss=2.318, rew=2.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 10001it [00:33, 296.89it/s, env_step=130000, len=14, n/ep=0, n/st=10, player_1/loss=2.048, player_2/loss=2.320, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 11.200000 ± 1.833030, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 10001it [00:33, 296.46it/s, env_step=140000, len=31, n/ep=0, n/st=10, player_1/loss=2.027, player_2/loss=2.343, rew=42.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 14.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 10001it [00:33, 295.44it/s, env_step=150000, len=14, n/ep=0, n/st=10, player_1/loss=2.069, player_2/loss=2.357, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 8.500000 ± 1.500000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 10001it [00:33, 300.37it/s, env_step=160000, len=15, n/ep=1, n/st=10, player_1/loss=2.030, player_2/loss=2.280, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 15.000000 ± 3.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 10001it [00:33, 300.38it/s, env_step=170000, len=30, n/ep=0, n/st=10, player_1/loss=2.010, player_2/loss=2.294, rew=20.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 10001it [00:33, 302.14it/s, env_step=180000, len=12, n/ep=1, n/st=10, player_1/loss=1.974, player_2/loss=2.306, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 10001it [00:33, 303.00it/s, env_step=190000, len=22, n/ep=3, n/st=10, player_1/loss=1.981, player_2/loss=2.259, rew=2.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 17.900000 ± 3.300000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 10001it [00:33, 302.30it/s, env_step=200000, len=27, n/ep=0, n/st=10, player_1/loss=2.030, player_2/loss=2.253, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #21: 10001it [00:33, 302.75it/s, env_step=210000, len=15, n/ep=2, n/st=10, player_1/loss=2.106, player_2/loss=2.276, rew=1.50]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #21: test_reward: 3.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #22: 10001it [00:33, 302.94it/s, env_step=220000, len=20, n/ep=0, n/st=10, player_1/loss=2.064, player_2/loss=2.279, rew=8.50]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #22: test_reward: 0.300000 ± 0.900000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #23: 10001it [00:33, 302.28it/s, env_step=230000, len=23, n/ep=0, n/st=10, player_1/loss=1.986, player_2/loss=2.314, rew=38.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #23: test_reward: 17.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #24: 10001it [00:32, 303.49it/s, env_step=240000, len=18, n/ep=1, n/st=10, player_1/loss=2.023, player_2/loss=2.355, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #24: test_reward: 26.600000 ± 10.316976, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #25: 10001it [00:33, 302.29it/s, env_step=250000, len=9, n/ep=0, n/st=10, player_1/loss=2.096, player_2/loss=2.299, rew=0.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #25: test_reward: 15.600000 ± 4.200000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #26: 10001it [00:32, 303.25it/s, env_step=260000, len=15, n/ep=0, n/st=10, player_1/loss=2.031, player_2/loss=2.313, rew=4.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #26: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #27: 10001it [00:32, 303.18it/s, env_step=270000, len=23, n/ep=0, n/st=10, player_1/loss=2.037, player_2/loss=2.272, rew=13.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #27: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #28: 10001it [00:32, 303.17it/s, env_step=280000, len=18, n/ep=0, n/st=10, player_1/loss=2.044, player_2/loss=2.266, rew=11.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #28: test_reward: 15.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #29: 10001it [00:32, 303.07it/s, env_step=290000, len=14, n/ep=2, n/st=10, player_1/loss=2.030, player_2/loss=2.273, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #29: test_reward: 0.000000 ± 0.000000, best_reward: 50.400000 ± 13.800000 in #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #30: 10001it [00:33, 302.82it/s, env_step=300000, len=22, n/ep=1, n/st=10, player_1/loss=1.995, player_2/loss=2.265, rew=36.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #30: test_reward: 69.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #31: 10001it [00:33, 302.25it/s, env_step=310000, len=24, n/ep=0, n/st=10, player_1/loss=2.033, player_2/loss=2.271, rew=21.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #31: test_reward: 6.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #32: 10001it [00:33, 301.33it/s, env_step=320000, len=10, n/ep=0, n/st=10, player_1/loss=2.046, player_2/loss=2.298, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #32: test_reward: 0.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #33: 10001it [00:33, 301.17it/s, env_step=330000, len=26, n/ep=1, n/st=10, player_1/loss=2.010, player_2/loss=2.323, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #33: test_reward: 16.000000 ± 12.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #34: 10001it [00:33, 300.97it/s, env_step=340000, len=21, n/ep=0, n/st=10, player_1/loss=2.064, player_2/loss=2.328, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #34: test_reward: 9.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #35: 10001it [00:33, 301.52it/s, env_step=350000, len=21, n/ep=1, n/st=10, player_1/loss=2.046, player_2/loss=2.225, rew=11.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35: test_reward: 0.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #36: 10001it [00:33, 300.76it/s, env_step=360000, len=17, n/ep=1, n/st=10, player_1/loss=2.035, player_2/loss=2.244, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #36: test_reward: 37.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #37: 10001it [00:33, 300.22it/s, env_step=370000, len=30, n/ep=1, n/st=10, player_1/loss=1.983, player_2/loss=2.206, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #37: test_reward: 21.900000 ± 2.467793, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #38: 10001it [00:33, 301.55it/s, env_step=380000, len=16, n/ep=3, n/st=10, player_1/loss=1.922, player_2/loss=2.174, rew=4.67]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #38: test_reward: 15.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #39: 10001it [00:33, 300.73it/s, env_step=390000, len=11, n/ep=0, n/st=10, player_1/loss=1.978, player_2/loss=2.178, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #39: test_reward: 19.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #40: 10001it [00:33, 302.00it/s, env_step=400000, len=13, n/ep=0, n/st=10, player_1/loss=1.989, player_2/loss=2.163, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40: test_reward: 0.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #41: 10001it [00:33, 301.50it/s, env_step=410000, len=16, n/ep=0, n/st=10, player_1/loss=1.995, player_2/loss=2.195, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #41: test_reward: 51.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #42: 10001it [00:34, 286.53it/s, env_step=420000, len=9, n/ep=0, n/st=10, player_1/loss=1.956, player_2/loss=2.223, rew=4.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #42: test_reward: 7.900000 ± 2.700000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #43: 10001it [00:33, 302.10it/s, env_step=430000, len=22, n/ep=0, n/st=10, player_1/loss=1.986, player_2/loss=2.156, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #43: test_reward: 21.100000 ± 2.211334, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #44: 10001it [00:33, 302.59it/s, env_step=440000, len=13, n/ep=0, n/st=10, player_1/loss=1.966, player_2/loss=2.141, rew=6.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #44: test_reward: 10.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #45: 10001it [00:33, 302.16it/s, env_step=450000, len=14, n/ep=0, n/st=10, player_1/loss=1.959, player_2/loss=2.152, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #45: test_reward: 4.500000 ± 7.500000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #46: 10001it [00:33, 302.66it/s, env_step=460000, len=22, n/ep=0, n/st=10, player_1/loss=1.955, player_2/loss=2.165, rew=16.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #46: test_reward: 21.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #47: 10001it [00:33, 302.39it/s, env_step=470000, len=13, n/ep=0, n/st=10, player_1/loss=1.920, player_2/loss=2.216, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #47: test_reward: 15.900000 ± 0.300000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #48: 10001it [00:33, 301.92it/s, env_step=480000, len=17, n/ep=0, n/st=10, player_1/loss=1.900, player_2/loss=2.127, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #48: test_reward: 20.500000 ± 4.364631, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #49: 10001it [00:33, 302.33it/s, env_step=490000, len=26, n/ep=0, n/st=10, player_1/loss=1.915, player_2/loss=2.080, rew=40.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #49: test_reward: 5.400000 ± 1.800000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #50: 10001it [00:33, 299.06it/s, env_step=500000, len=18, n/ep=0, n/st=10, player_1/loss=1.884, player_2/loss=2.090, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50: test_reward: 7.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #51: 10001it [00:33, 299.20it/s, env_step=510000, len=10, n/ep=1, n/st=10, player_1/loss=1.906, player_2/loss=2.117, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #51: test_reward: 13.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #52: 10001it [00:33, 299.28it/s, env_step=520000, len=20, n/ep=1, n/st=10, player_1/loss=1.902, player_2/loss=2.075, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #52: test_reward: 8.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #53: 10001it [00:33, 298.29it/s, env_step=530000, len=23, n/ep=0, n/st=10, player_1/loss=1.957, player_2/loss=2.074, rew=11.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #53: test_reward: 14.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #54: 10001it [00:33, 298.51it/s, env_step=540000, len=15, n/ep=0, n/st=10, player_1/loss=1.878, player_2/loss=1.992, rew=3.40]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #54: test_reward: 17.200000 ± 2.400000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #55: 10001it [00:33, 298.81it/s, env_step=550000, len=15, n/ep=0, n/st=10, player_1/loss=1.870, player_2/loss=2.048, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #55: test_reward: 9.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #56: 10001it [00:33, 298.74it/s, env_step=560000, len=16, n/ep=1, n/st=10, player_1/loss=1.906, player_2/loss=2.061, rew=10.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #56: test_reward: 6.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #57: 10001it [00:33, 297.70it/s, env_step=570000, len=14, n/ep=0, n/st=10, player_1/loss=1.869, player_2/loss=2.032, rew=5.50]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #57: test_reward: 31.200000 ± 3.600000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #58: 10001it [00:33, 299.13it/s, env_step=580000, len=16, n/ep=2, n/st=10, player_1/loss=1.847, player_2/loss=2.011, rew=4.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #58: test_reward: 22.400000 ± 4.200000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #59: 10001it [00:33, 297.91it/s, env_step=590000, len=16, n/ep=0, n/st=10, player_1/loss=1.869, player_2/loss=1.905, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #59: test_reward: 55.300000 ± 6.197580, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #60: 10001it [00:33, 297.69it/s, env_step=600000, len=10, n/ep=0, n/st=10, player_1/loss=1.891, player_2/loss=2.004, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #60: test_reward: 8.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #61: 10001it [00:33, 298.52it/s, env_step=610000, len=19, n/ep=0, n/st=10, player_1/loss=1.926, player_2/loss=2.021, rew=7.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #61: test_reward: 24.400000 ± 1.800000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #62: 10001it [00:33, 299.49it/s, env_step=620000, len=19, n/ep=0, n/st=10, player_1/loss=1.840, player_2/loss=2.007, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #62: test_reward: 22.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #63: 10001it [00:33, 299.58it/s, env_step=630000, len=16, n/ep=1, n/st=10, player_1/loss=1.903, player_2/loss=2.085, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #63: test_reward: 28.000000 ± 18.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #64: 10001it [00:33, 299.25it/s, env_step=640000, len=16, n/ep=1, n/st=10, player_1/loss=1.920, player_2/loss=2.044, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #64: test_reward: 2.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #65: 10001it [00:33, 298.68it/s, env_step=650000, len=25, n/ep=1, n/st=10, player_1/loss=1.824, player_2/loss=1.965, rew=18.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #65: test_reward: 8.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #66: 10001it [00:33, 299.67it/s, env_step=660000, len=20, n/ep=0, n/st=10, player_1/loss=1.790, player_2/loss=1.873, rew=13.33]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #66: test_reward: 36.000000 ± 6.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #67: 10001it [00:33, 299.13it/s, env_step=670000, len=24, n/ep=0, n/st=10, player_1/loss=1.853, player_2/loss=1.885, rew=18.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #67: test_reward: 14.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #68: 10001it [00:33, 297.06it/s, env_step=680000, len=19, n/ep=0, n/st=10, player_1/loss=1.828, player_2/loss=1.801, rew=8.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #68: test_reward: 31.600000 ± 1.200000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #69: 10001it [00:33, 298.21it/s, env_step=690000, len=19, n/ep=0, n/st=10, player_1/loss=1.849, player_2/loss=1.852, rew=4.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #69: test_reward: 62.800000 ± 28.526479, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #70: 10001it [00:33, 299.59it/s, env_step=700000, len=15, n/ep=1, n/st=10, player_1/loss=1.883, player_2/loss=1.971, rew=9.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #70: test_reward: 2.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #71: 10001it [00:33, 299.74it/s, env_step=710000, len=15, n/ep=1, n/st=10, player_1/loss=1.796, player_2/loss=1.934, rew=9.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #71: test_reward: 6.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #72: 10001it [00:33, 299.44it/s, env_step=720000, len=21, n/ep=0, n/st=10, player_1/loss=1.779, player_2/loss=2.006, rew=17.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #72: test_reward: 11.000000 ± 3.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #73: 10001it [00:33, 299.15it/s, env_step=730000, len=26, n/ep=0, n/st=10, player_1/loss=1.792, player_2/loss=2.004, rew=27.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #73: test_reward: 14.900000 ± 16.324521, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #74: 10001it [00:33, 299.46it/s, env_step=740000, len=23, n/ep=1, n/st=10, player_1/loss=1.817, player_2/loss=1.910, rew=24.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #74: test_reward: 12.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #75: 10001it [00:33, 300.15it/s, env_step=750000, len=22, n/ep=2, n/st=10, player_1/loss=1.767, player_2/loss=1.882, rew=27.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #75: test_reward: 43.100000 ± 5.593747, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #76: 10001it [00:33, 300.06it/s, env_step=760000, len=18, n/ep=0, n/st=10, player_1/loss=1.785, player_2/loss=1.928, rew=7.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #76: test_reward: 12.800000 ± 1.833030, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #77: 10001it [00:33, 299.04it/s, env_step=770000, len=13, n/ep=0, n/st=10, player_1/loss=1.868, player_2/loss=2.004, rew=7.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #77: test_reward: 21.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #78: 10001it [00:33, 300.57it/s, env_step=780000, len=8, n/ep=1, n/st=10, player_1/loss=1.841, player_2/loss=1.951, rew=0.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #78: test_reward: 24.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #79: 10001it [00:33, 300.29it/s, env_step=790000, len=11, n/ep=1, n/st=10, player_1/loss=1.796, player_2/loss=1.832, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #79: test_reward: 22.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #80: 10001it [00:33, 302.34it/s, env_step=800000, len=8, n/ep=0, n/st=10, player_1/loss=1.840, player_2/loss=1.876, rew=2.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #80: test_reward: 8.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #81: 10001it [00:33, 302.77it/s, env_step=810000, len=25, n/ep=0, n/st=10, player_1/loss=1.845, player_2/loss=1.955, rew=7.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #81: test_reward: 20.500000 ± 1.500000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #82: 10001it [00:33, 301.08it/s, env_step=820000, len=14, n/ep=0, n/st=10, player_1/loss=1.911, player_2/loss=1.943, rew=11.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #82: test_reward: 14.400000 ± 4.200000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #83: 10001it [00:33, 302.34it/s, env_step=830000, len=12, n/ep=1, n/st=10, player_1/loss=1.898, player_2/loss=1.989, rew=6.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #83: test_reward: 46.700000 ± 12.900000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #84: 10001it [00:33, 302.56it/s, env_step=840000, len=22, n/ep=1, n/st=10, player_1/loss=1.836, player_2/loss=2.017, rew=13.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #84: test_reward: 13.000000 ± 0.000000, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #85: 10001it [00:33, 302.21it/s, env_step=850000, len=20, n/ep=0, n/st=10, player_1/loss=1.867, player_2/loss=2.033, rew=3.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #85: test_reward: 18.200000 ± 8.506468, best_reward: 69.000000 ± 0.000000 in #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #86: 10001it [00:33, 301.49it/s, env_step=860000, len=30, n/ep=1, n/st=10, player_1/loss=1.847, player_2/loss=1.916, rew=57.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #86: test_reward: 85.000000 ± 0.000000, best_reward: 85.000000 ± 0.000000 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #87: 10001it [00:33, 301.74it/s, env_step=870000, len=18, n/ep=0, n/st=10, player_1/loss=1.866, player_2/loss=1.916, rew=14.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #87: test_reward: 8.000000 ± 0.000000, best_reward: 85.000000 ± 0.000000 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #88: 10001it [00:33, 302.59it/s, env_step=880000, len=24, n/ep=0, n/st=10, player_1/loss=1.788, player_2/loss=1.807, rew=37.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #88: test_reward: 15.000000 ± 3.000000, best_reward: 85.000000 ± 0.000000 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #89: 10001it [00:33, 302.56it/s, env_step=890000, len=29, n/ep=1, n/st=10, player_1/loss=1.785, player_2/loss=1.821, rew=100.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #89: test_reward: 33.800000 ± 3.600000, best_reward: 85.000000 ± 0.000000 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #90: 10001it [00:33, 302.57it/s, env_step=900000, len=12, n/ep=2, n/st=10, player_1/loss=1.787, player_2/loss=1.856, rew=6.50]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #90: test_reward: 42.400000 ± 1.800000, best_reward: 85.000000 ± 0.000000 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #91: 10001it [00:33, 302.45it/s, env_step=910000, len=7, n/ep=1, n/st=10, player_1/loss=1.727, player_2/loss=1.823, rew=2.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #91: test_reward: 104.300000 ± 48.900000, best_reward: 104.300000 ± 48.900000 in #91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #92: 10001it [00:33, 302.21it/s, env_step=920000, len=7, n/ep=0, n/st=10, player_1/loss=1.706, player_2/loss=1.843, rew=0.00]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #92: test_reward: 51.500000 ± 4.500000, best_reward: 104.300000 ± 48.900000 in #91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #93: 10001it [00:33, 302.41it/s, env_step=930000, len=17, n/ep=0, n/st=10, player_1/loss=1.668, player_2/loss=1.692, rew=14.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #93: test_reward: 23.000000 ± 0.000000, best_reward: 104.300000 ± 48.900000 in #91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #94: 10001it [00:33, 302.63it/s, env_step=940000, len=31, n/ep=0, n/st=10, player_1/loss=1.846, player_2/loss=1.946, rew=144.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #94: test_reward: 31.300000 ± 8.100000, best_reward: 104.300000 ± 48.900000 in #91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #95: 10001it [00:33, 301.93it/s, env_step=950000, len=20, n/ep=0, n/st=10, player_1/loss=1.719, player_2/loss=1.897, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #95: test_reward: 28.000000 ± 0.000000, best_reward: 104.300000 ± 48.900000 in #91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #96: 10001it [00:33, 302.63it/s, env_step=960000, len=11, n/ep=0, n/st=10, player_1/loss=1.745, player_2/loss=1.960, rew=5.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #96: test_reward: 153.300000 ± 40.437730, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #97: 10001it [00:33, 302.38it/s, env_step=970000, len=18, n/ep=0, n/st=10, player_1/loss=1.693, player_2/loss=1.851, rew=41.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #97: test_reward: 89.900000 ± 8.700000, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #98: 10001it [00:33, 302.68it/s, env_step=980000, len=18, n/ep=0, n/st=10, player_1/loss=1.654, player_2/loss=1.859, rew=0.00]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #98: test_reward: 135.900000 ± 46.554162, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #99: 10001it [00:33, 302.12it/s, env_step=990000, len=36, n/ep=0, n/st=10, player_1/loss=1.691, player_2/loss=1.760, rew=72.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #99: test_reward: 20.900000 ± 3.300000, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #100: 10001it [00:33, 302.12it/s, env_step=1000000, len=16, n/ep=0, n/st=10, player_1/loss=1.686, player_2/loss=1.901, rew=21.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #100: test_reward: 30.000000 ± 3.000000, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #101: 10001it [00:33, 302.48it/s, env_step=1010000, len=22, n/ep=2, n/st=10, player_1/loss=1.604, player_2/loss=1.759, rew=33.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #101: test_reward: 48.500000 ± 37.510665, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #102: 10001it [00:33, 302.75it/s, env_step=1020000, len=23, n/ep=1, n/st=10, player_1/loss=1.698, player_2/loss=1.733, rew=44.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #102: test_reward: 45.000000 ± 3.000000, best_reward: 153.300000 ± 40.437730 in #96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #103: 10001it [00:33, 302.83it/s, env_step=1030000, len=18, n/ep=0, n/st=10, player_1/loss=1.668, player_2/loss=1.708, rew=15.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #103: test_reward: 158.400000 ± 52.800000, best_reward: 158.400000 ± 52.800000 in #103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #104: 10001it [00:33, 301.85it/s, env_step=1040000, len=13, n/ep=1, n/st=10, player_1/loss=1.555, player_2/loss=1.679, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #104: test_reward: 81.000000 ± 27.000000, best_reward: 158.400000 ± 52.800000 in #103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #105: 10001it [00:33, 302.44it/s, env_step=1050000, len=8, n/ep=0, n/st=10, player_1/loss=1.583, player_2/loss=1.775, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #105: test_reward: 68.400000 ± 19.800000, best_reward: 158.400000 ± 52.800000 in #103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #106: 10001it [00:33, 302.64it/s, env_step=1060000, len=18, n/ep=1, n/st=10, player_1/loss=1.703, player_2/loss=1.853, rew=27.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #106: test_reward: 51.000000 ± 0.000000, best_reward: 158.400000 ± 52.800000 in #103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #107: 10001it [00:33, 302.10it/s, env_step=1070000, len=7, n/ep=0, n/st=10, player_1/loss=1.638, player_2/loss=1.742, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #107: test_reward: 83.700000 ± 27.900000, best_reward: 158.400000 ± 52.800000 in #103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #108: 10001it [00:33, 302.52it/s, env_step=1080000, len=15, n/ep=0, n/st=10, player_1/loss=1.604, player_2/loss=1.700, rew=11.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #108: test_reward: 171.700000 ± 36.997432, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #109: 10001it [00:33, 302.45it/s, env_step=1090000, len=37, n/ep=0, n/st=10, player_1/loss=1.557, player_2/loss=1.681, rew=132.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #109: test_reward: 9.000000 ± 0.000000, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #110: 10001it [00:33, 302.24it/s, env_step=1100000, len=17, n/ep=0, n/st=10, player_1/loss=1.605, player_2/loss=1.646, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #110: test_reward: 78.400000 ± 22.800000, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #111: 10001it [00:33, 302.62it/s, env_step=1110000, len=31, n/ep=0, n/st=10, player_1/loss=1.540, player_2/loss=1.667, rew=99.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #111: test_reward: 130.700000 ± 7.849204, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #112: 10001it [00:33, 302.06it/s, env_step=1120000, len=20, n/ep=1, n/st=10, player_1/loss=1.561, player_2/loss=1.815, rew=10.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #112: test_reward: 108.300000 ± 17.911170, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #113: 10001it [00:33, 302.00it/s, env_step=1130000, len=15, n/ep=1, n/st=10, player_1/loss=1.634, player_2/loss=1.655, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #113: test_reward: 137.700000 ± 45.812771, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #114: 10001it [00:33, 302.02it/s, env_step=1140000, len=12, n/ep=0, n/st=10, player_1/loss=1.579, player_2/loss=1.603, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #114: test_reward: 111.000000 ± 0.000000, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #115: 10001it [00:33, 302.64it/s, env_step=1150000, len=22, n/ep=1, n/st=10, player_1/loss=1.455, player_2/loss=1.675, rew=43.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #115: test_reward: 147.000000 ± 0.000000, best_reward: 171.700000 ± 36.997432 in #108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #116: 10001it [00:33, 302.23it/s, env_step=1160000, len=23, n/ep=0, n/st=10, player_1/loss=1.514, player_2/loss=1.671, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #116: test_reward: 217.600000 ± 10.229369, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #117: 10001it [00:33, 302.27it/s, env_step=1170000, len=8, n/ep=1, n/st=10, player_1/loss=1.518, player_2/loss=1.600, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #117: test_reward: 128.000000 ± 0.000000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #118: 10001it [00:33, 302.34it/s, env_step=1180000, len=18, n/ep=1, n/st=10, player_1/loss=1.531, player_2/loss=1.650, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #118: test_reward: 133.600000 ± 4.200000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #119: 10001it [00:33, 302.22it/s, env_step=1190000, len=25, n/ep=0, n/st=10, player_1/loss=1.470, player_2/loss=1.668, rew=76.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #119: test_reward: 74.900000 ± 6.300000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #120: 10001it [00:33, 302.81it/s, env_step=1200000, len=22, n/ep=0, n/st=10, player_1/loss=1.550, player_2/loss=1.681, rew=36.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #120: test_reward: 8.000000 ± 0.000000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #121: 10001it [00:33, 302.31it/s, env_step=1210000, len=26, n/ep=0, n/st=10, player_1/loss=1.583, player_2/loss=1.590, rew=30.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #121: test_reward: 151.000000 ± 0.000000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #122: 10001it [00:33, 301.89it/s, env_step=1220000, len=20, n/ep=1, n/st=10, player_1/loss=1.528, player_2/loss=1.503, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #122: test_reward: 43.000000 ± 0.000000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #123: 10001it [00:33, 302.30it/s, env_step=1230000, len=36, n/ep=0, n/st=10, player_1/loss=1.486, player_2/loss=1.471, rew=131.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #123: test_reward: 142.000000 ± 0.000000, best_reward: 217.600000 ± 10.229369 in #116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #124: 10001it [00:33, 302.45it/s, env_step=1240000, len=19, n/ep=0, n/st=10, player_1/loss=1.468, player_2/loss=1.656, rew=44.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #124: test_reward: 226.900000 ± 36.300000, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #125: 10001it [00:33, 301.35it/s, env_step=1250000, len=30, n/ep=0, n/st=10, player_1/loss=1.495, player_2/loss=1.591, rew=82.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #125: test_reward: 176.400000 ± 27.251422, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #126: 10001it [00:33, 302.21it/s, env_step=1260000, len=18, n/ep=1, n/st=10, player_1/loss=1.371, player_2/loss=1.550, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #126: test_reward: 125.000000 ± 0.000000, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #127: 10001it [00:33, 302.10it/s, env_step=1270000, len=23, n/ep=0, n/st=10, player_1/loss=1.443, player_2/loss=1.555, rew=37.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #127: test_reward: 78.400000 ± 13.200000, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #128: 10001it [00:33, 301.27it/s, env_step=1280000, len=19, n/ep=0, n/st=10, player_1/loss=1.456, player_2/loss=1.614, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #128: test_reward: 177.200000 ± 15.759442, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #129: 10001it [00:33, 302.24it/s, env_step=1290000, len=28, n/ep=2, n/st=10, player_1/loss=1.456, player_2/loss=1.661, rew=64.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #129: test_reward: 125.800000 ± 18.600000, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #130: 10001it [00:33, 301.64it/s, env_step=1300000, len=29, n/ep=0, n/st=10, player_1/loss=1.462, player_2/loss=1.669, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #130: test_reward: 105.800000 ± 24.305555, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #131: 10001it [00:33, 301.38it/s, env_step=1310000, len=14, n/ep=1, n/st=10, player_1/loss=1.494, player_2/loss=1.680, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #131: test_reward: 58.700000 ± 53.370497, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #132: 10001it [00:33, 302.50it/s, env_step=1320000, len=17, n/ep=0, n/st=10, player_1/loss=1.481, player_2/loss=1.625, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #132: test_reward: 104.200000 ± 34.078732, best_reward: 226.900000 ± 36.300000 in #124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #133: 10001it [00:33, 302.19it/s, env_step=1330000, len=25, n/ep=0, n/st=10, player_1/loss=1.419, player_2/loss=1.609, rew=74.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #133: test_reward: 252.400000 ± 13.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #134: 10001it [00:33, 301.52it/s, env_step=1340000, len=19, n/ep=1, n/st=10, player_1/loss=1.380, player_2/loss=1.598, rew=22.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #134: test_reward: 115.000000 ± 33.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #135: 10001it [00:33, 302.89it/s, env_step=1350000, len=33, n/ep=0, n/st=10, player_1/loss=1.394, player_2/loss=1.654, rew=88.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #135: test_reward: 178.500000 ± 28.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #136: 10001it [00:33, 302.40it/s, env_step=1360000, len=10, n/ep=1, n/st=10, player_1/loss=1.435, player_2/loss=1.576, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #136: test_reward: 48.400000 ± 26.814921, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #137: 10001it [00:33, 302.40it/s, env_step=1370000, len=19, n/ep=1, n/st=10, player_1/loss=1.369, player_2/loss=1.551, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #137: test_reward: 182.600000 ± 22.218011, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #138: 10001it [00:33, 302.46it/s, env_step=1380000, len=8, n/ep=0, n/st=10, player_1/loss=1.494, player_2/loss=1.667, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #138: test_reward: 112.300000 ± 8.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #139: 10001it [00:33, 302.31it/s, env_step=1390000, len=41, n/ep=1, n/st=10, player_1/loss=1.345, player_2/loss=1.659, rew=180.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #139: test_reward: 136.400000 ± 60.228233, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #140: 10001it [00:33, 301.83it/s, env_step=1400000, len=16, n/ep=0, n/st=10, player_1/loss=1.422, player_2/loss=1.656, rew=21.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #140: test_reward: 153.100000 ± 8.700000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #141: 10001it [00:33, 302.49it/s, env_step=1410000, len=10, n/ep=0, n/st=10, player_1/loss=1.460, player_2/loss=1.638, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #141: test_reward: 58.500000 ± 22.258706, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #142: 10001it [00:33, 301.84it/s, env_step=1420000, len=15, n/ep=0, n/st=10, player_1/loss=1.506, player_2/loss=1.585, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #142: test_reward: 132.000000 ± 63.310347, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #143: 10001it [00:33, 301.55it/s, env_step=1430000, len=22, n/ep=1, n/st=10, player_1/loss=1.431, player_2/loss=1.530, rew=20.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #143: test_reward: 220.900000 ± 46.554162, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #144: 10001it [00:33, 302.55it/s, env_step=1440000, len=15, n/ep=2, n/st=10, player_1/loss=1.377, player_2/loss=1.611, rew=17.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #144: test_reward: 57.600000 ± 16.200000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #145: 10001it [00:33, 302.01it/s, env_step=1450000, len=21, n/ep=1, n/st=10, player_1/loss=1.416, player_2/loss=1.619, rew=24.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #145: test_reward: 20.800000 ± 0.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #146: 10001it [00:33, 301.87it/s, env_step=1460000, len=18, n/ep=0, n/st=10, player_1/loss=1.430, player_2/loss=1.594, rew=34.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #146: test_reward: 223.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #147: 10001it [00:33, 301.53it/s, env_step=1470000, len=22, n/ep=1, n/st=10, player_1/loss=1.279, player_2/loss=1.501, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #147: test_reward: 209.100000 ± 44.700000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #148: 10001it [00:33, 302.23it/s, env_step=1480000, len=19, n/ep=0, n/st=10, player_1/loss=1.338, player_2/loss=1.644, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #148: test_reward: 44.600000 ± 1.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #149: 10001it [00:33, 301.88it/s, env_step=1490000, len=21, n/ep=1, n/st=10, player_1/loss=1.302, player_2/loss=1.574, rew=53.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #149: test_reward: 172.200000 ± 44.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #150: 10001it [00:33, 302.21it/s, env_step=1500000, len=18, n/ep=0, n/st=10, player_1/loss=1.284, player_2/loss=1.575, rew=38.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #150: test_reward: 50.700000 ± 29.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #151: 10001it [00:33, 301.81it/s, env_step=1510000, len=9, n/ep=0, n/st=10, player_1/loss=1.347, player_2/loss=1.496, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #151: test_reward: 21.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #152: 10001it [00:33, 300.43it/s, env_step=1520000, len=32, n/ep=0, n/st=10, player_1/loss=1.374, player_2/loss=1.519, rew=70.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #152: test_reward: 144.500000 ± 38.946759, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #153: 10001it [00:33, 300.69it/s, env_step=1530000, len=36, n/ep=0, n/st=10, player_1/loss=1.383, player_2/loss=1.557, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #153: test_reward: 111.100000 ± 17.643412, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #154: 10001it [00:33, 301.37it/s, env_step=1540000, len=25, n/ep=1, n/st=10, player_1/loss=1.382, player_2/loss=1.636, rew=49.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #154: test_reward: 17.400000 ± 7.200000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #155: 10001it [00:33, 301.68it/s, env_step=1550000, len=8, n/ep=0, n/st=10, player_1/loss=1.503, player_2/loss=1.576, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #155: test_reward: 37.900000 ± 14.577037, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #156: 10001it [00:33, 302.42it/s, env_step=1560000, len=18, n/ep=0, n/st=10, player_1/loss=1.501, player_2/loss=1.567, rew=26.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #156: test_reward: 21.000000 ± 0.447214, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #157: 10001it [00:33, 302.15it/s, env_step=1570000, len=16, n/ep=2, n/st=10, player_1/loss=1.497, player_2/loss=1.659, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #157: test_reward: 208.300000 ± 53.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #158: 10001it [00:33, 301.53it/s, env_step=1580000, len=18, n/ep=0, n/st=10, player_1/loss=1.295, player_2/loss=1.664, rew=17.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #158: test_reward: 249.000000 ± 12.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #159: 10001it [00:33, 301.03it/s, env_step=1590000, len=15, n/ep=0, n/st=10, player_1/loss=1.376, player_2/loss=1.577, rew=15.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #159: test_reward: 41.300000 ± 11.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #160: 10001it [00:33, 301.41it/s, env_step=1600000, len=21, n/ep=1, n/st=10, player_1/loss=1.429, player_2/loss=1.629, rew=53.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #160: test_reward: 7.000000 ± 12.296341, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #161: 10001it [00:33, 301.54it/s, env_step=1610000, len=9, n/ep=0, n/st=10, player_1/loss=1.562, player_2/loss=1.710, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #161: test_reward: 53.200000 ± 42.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #162: 10001it [00:33, 300.96it/s, env_step=1620000, len=19, n/ep=1, n/st=10, player_1/loss=1.323, player_2/loss=1.608, rew=33.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #162: test_reward: 136.400000 ± 51.194140, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #163: 10001it [00:33, 301.05it/s, env_step=1630000, len=15, n/ep=0, n/st=10, player_1/loss=1.428, player_2/loss=1.574, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #163: test_reward: 77.100000 ± 34.065965, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #164: 10001it [00:33, 301.66it/s, env_step=1640000, len=12, n/ep=0, n/st=10, player_1/loss=1.548, player_2/loss=1.765, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #164: test_reward: 53.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #165: 10001it [00:33, 300.81it/s, env_step=1650000, len=8, n/ep=0, n/st=10, player_1/loss=1.429, player_2/loss=1.639, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #165: test_reward: 43.400000 ± 7.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #166: 10001it [00:33, 301.05it/s, env_step=1660000, len=17, n/ep=1, n/st=10, player_1/loss=1.478, player_2/loss=1.633, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #166: test_reward: 67.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #167: 10001it [00:33, 302.13it/s, env_step=1670000, len=19, n/ep=1, n/st=10, player_1/loss=1.331, player_2/loss=1.638, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #167: test_reward: 8.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #168: 10001it [00:33, 301.59it/s, env_step=1680000, len=37, n/ep=1, n/st=10, player_1/loss=1.418, player_2/loss=1.641, rew=153.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #168: test_reward: 178.000000 ± 3.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #169: 10001it [00:33, 301.66it/s, env_step=1690000, len=29, n/ep=1, n/st=10, player_1/loss=1.444, player_2/loss=1.606, rew=123.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #169: test_reward: 37.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #170: 10001it [00:33, 301.83it/s, env_step=1700000, len=30, n/ep=1, n/st=10, player_1/loss=1.398, player_2/loss=1.612, rew=28.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #170: test_reward: 37.800000 ± 3.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #171: 10001it [00:33, 302.21it/s, env_step=1710000, len=9, n/ep=0, n/st=10, player_1/loss=1.409, player_2/loss=1.649, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #171: test_reward: 32.400000 ± 10.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #172: 10001it [00:33, 301.95it/s, env_step=1720000, len=12, n/ep=2, n/st=10, player_1/loss=1.398, player_2/loss=1.552, rew=4.50]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #172: test_reward: 85.500000 ± 7.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #173: 10001it [00:33, 302.65it/s, env_step=1730000, len=20, n/ep=0, n/st=10, player_1/loss=1.465, player_2/loss=1.639, rew=51.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #173: test_reward: 122.900000 ± 37.964325, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #174: 10001it [00:33, 302.34it/s, env_step=1740000, len=30, n/ep=1, n/st=10, player_1/loss=1.401, player_2/loss=1.690, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #174: test_reward: 37.600000 ± 1.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #175: 10001it [00:33, 302.07it/s, env_step=1750000, len=10, n/ep=1, n/st=10, player_1/loss=1.324, player_2/loss=1.513, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #175: test_reward: 186.200000 ± 5.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #176: 10001it [00:33, 302.01it/s, env_step=1760000, len=19, n/ep=1, n/st=10, player_1/loss=1.312, player_2/loss=1.503, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #176: test_reward: 77.000000 ± 11.349009, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #177: 10001it [00:33, 301.90it/s, env_step=1770000, len=30, n/ep=0, n/st=10, player_1/loss=1.294, player_2/loss=1.534, rew=87.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #177: test_reward: 18.200000 ± 9.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #178: 10001it [00:33, 302.17it/s, env_step=1780000, len=10, n/ep=1, n/st=10, player_1/loss=1.335, player_2/loss=1.529, rew=3.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #178: test_reward: 141.400000 ± 1.200000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #179: 10001it [00:33, 301.69it/s, env_step=1790000, len=12, n/ep=0, n/st=10, player_1/loss=1.369, player_2/loss=1.574, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #179: test_reward: 8.300000 ± 0.900000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #180: 10001it [00:33, 301.74it/s, env_step=1800000, len=23, n/ep=2, n/st=10, player_1/loss=1.312, player_2/loss=1.556, rew=69.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #180: test_reward: 41.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #181: 10001it [00:33, 302.08it/s, env_step=1810000, len=21, n/ep=1, n/st=10, player_1/loss=1.431, player_2/loss=1.511, rew=32.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #181: test_reward: 201.300000 ± 30.192880, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #182: 10001it [00:33, 302.11it/s, env_step=1820000, len=11, n/ep=1, n/st=10, player_1/loss=1.363, player_2/loss=1.557, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #182: test_reward: 29.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #183: 10001it [00:33, 301.99it/s, env_step=1830000, len=8, n/ep=1, n/st=10, player_1/loss=1.405, player_2/loss=1.653, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #183: test_reward: 54.500000 ± 16.716758, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #184: 10001it [00:33, 302.23it/s, env_step=1840000, len=20, n/ep=0, n/st=10, player_1/loss=1.426, player_2/loss=1.555, rew=43.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #184: test_reward: 12.900000 ± 4.657252, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #185: 10001it [00:33, 301.36it/s, env_step=1850000, len=40, n/ep=0, n/st=10, player_1/loss=1.415, player_2/loss=1.587, rew=163.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #185: test_reward: 54.600000 ± 7.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #186: 10001it [00:33, 301.59it/s, env_step=1860000, len=24, n/ep=0, n/st=10, player_1/loss=1.373, player_2/loss=1.624, rew=60.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #186: test_reward: 90.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #187: 10001it [00:33, 302.16it/s, env_step=1870000, len=8, n/ep=0, n/st=10, player_1/loss=1.426, player_2/loss=1.651, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #187: test_reward: 64.400000 ± 4.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #188: 10001it [00:33, 302.64it/s, env_step=1880000, len=25, n/ep=0, n/st=10, player_1/loss=1.328, player_2/loss=1.635, rew=46.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #188: test_reward: 37.200000 ± 1.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #189: 10001it [00:33, 302.26it/s, env_step=1890000, len=17, n/ep=0, n/st=10, player_1/loss=1.379, player_2/loss=1.615, rew=28.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #189: test_reward: 95.300000 ± 8.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #190: 10001it [00:33, 302.18it/s, env_step=1900000, len=42, n/ep=0, n/st=10, player_1/loss=1.408, player_2/loss=1.573, rew=98.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #190: test_reward: 208.100000 ± 73.157980, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #191: 10001it [00:33, 301.78it/s, env_step=1910000, len=12, n/ep=2, n/st=10, player_1/loss=1.366, player_2/loss=1.644, rew=9.50]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #191: test_reward: 90.500000 ± 28.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #192: 10001it [00:33, 302.18it/s, env_step=1920000, len=8, n/ep=1, n/st=10, player_1/loss=1.414, player_2/loss=1.585, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #192: test_reward: 19.500000 ± 25.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #193: 10001it [00:33, 301.83it/s, env_step=1930000, len=24, n/ep=0, n/st=10, player_1/loss=1.366, player_2/loss=1.540, rew=42.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #193: test_reward: 165.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #194: 10001it [00:33, 301.91it/s, env_step=1940000, len=27, n/ep=0, n/st=10, player_1/loss=1.398, player_2/loss=1.546, rew=48.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #194: test_reward: 70.300000 ± 14.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #195: 10001it [00:33, 301.20it/s, env_step=1950000, len=23, n/ep=3, n/st=10, player_1/loss=1.465, player_2/loss=1.616, rew=42.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #195: test_reward: 73.500000 ± 5.678908, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #196: 10001it [00:33, 301.95it/s, env_step=1960000, len=16, n/ep=1, n/st=10, player_1/loss=1.413, player_2/loss=1.626, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #196: test_reward: 8.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #197: 10001it [00:33, 302.19it/s, env_step=1970000, len=25, n/ep=0, n/st=10, player_1/loss=1.483, player_2/loss=1.552, rew=46.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #197: test_reward: 127.300000 ± 36.254793, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #198: 10001it [00:33, 302.50it/s, env_step=1980000, len=42, n/ep=0, n/st=10, player_1/loss=1.402, player_2/loss=1.598, rew=152.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #198: test_reward: 199.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #199: 10001it [00:33, 301.91it/s, env_step=1990000, len=20, n/ep=0, n/st=10, player_1/loss=1.393, player_2/loss=1.565, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #199: test_reward: 111.900000 ± 36.316525, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #200: 10001it [00:33, 302.15it/s, env_step=2000000, len=11, n/ep=0, n/st=10, player_1/loss=1.408, player_2/loss=1.461, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #200: test_reward: 198.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #201: 10001it [00:33, 302.03it/s, env_step=2010000, len=8, n/ep=1, n/st=10, player_1/loss=1.389, player_2/loss=1.461, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #201: test_reward: 144.400000 ± 35.967207, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #202: 10001it [00:33, 301.71it/s, env_step=2020000, len=24, n/ep=0, n/st=10, player_1/loss=1.407, player_2/loss=1.500, rew=60.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #202: test_reward: 90.100000 ± 8.700000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #203: 10001it [00:33, 301.78it/s, env_step=2030000, len=16, n/ep=0, n/st=10, player_1/loss=1.387, player_2/loss=1.465, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #203: test_reward: 7.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #204: 10001it [00:33, 301.72it/s, env_step=2040000, len=32, n/ep=2, n/st=10, player_1/loss=1.381, player_2/loss=1.422, rew=52.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #204: test_reward: 199.000000 ± 6.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #205: 10001it [00:33, 301.41it/s, env_step=2050000, len=19, n/ep=1, n/st=10, player_1/loss=1.292, player_2/loss=1.462, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #205: test_reward: 227.200000 ± 4.422669, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #206: 10001it [00:33, 301.74it/s, env_step=2060000, len=18, n/ep=0, n/st=10, player_1/loss=1.272, player_2/loss=1.420, rew=17.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #206: test_reward: 109.300000 ± 53.432294, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #207: 10001it [00:33, 302.03it/s, env_step=2070000, len=12, n/ep=2, n/st=10, player_1/loss=1.413, player_2/loss=1.558, rew=7.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #207: test_reward: 110.900000 ± 21.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #208: 10001it [00:33, 302.34it/s, env_step=2080000, len=31, n/ep=0, n/st=10, player_1/loss=1.432, player_2/loss=1.608, rew=74.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #208: test_reward: 67.300000 ± 0.900000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #209: 10001it [00:33, 302.13it/s, env_step=2090000, len=10, n/ep=0, n/st=10, player_1/loss=1.392, player_2/loss=1.633, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #209: test_reward: 111.500000 ± 35.034983, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #210: 10001it [00:33, 302.28it/s, env_step=2100000, len=12, n/ep=0, n/st=10, player_1/loss=1.448, player_2/loss=1.533, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #210: test_reward: 191.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #211: 10001it [00:33, 301.86it/s, env_step=2110000, len=18, n/ep=0, n/st=10, player_1/loss=1.316, player_2/loss=1.543, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #211: test_reward: 193.800000 ± 48.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #212: 10001it [00:33, 301.47it/s, env_step=2120000, len=8, n/ep=0, n/st=10, player_1/loss=1.340, player_2/loss=1.443, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #212: test_reward: 88.200000 ± 6.896376, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #213: 10001it [00:33, 301.69it/s, env_step=2130000, len=32, n/ep=0, n/st=10, player_1/loss=1.379, player_2/loss=1.502, rew=92.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #213: test_reward: 74.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #214: 10001it [00:33, 301.89it/s, env_step=2140000, len=18, n/ep=0, n/st=10, player_1/loss=1.401, player_2/loss=1.474, rew=16.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #214: test_reward: 219.800000 ± 15.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #215: 10001it [00:33, 302.08it/s, env_step=2150000, len=42, n/ep=0, n/st=10, player_1/loss=1.354, player_2/loss=1.491, rew=228.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #215: test_reward: 80.500000 ± 4.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #216: 10001it [00:33, 302.49it/s, env_step=2160000, len=34, n/ep=1, n/st=10, player_1/loss=1.346, player_2/loss=1.563, rew=93.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #216: test_reward: 204.200000 ± 59.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #217: 10001it [00:33, 301.96it/s, env_step=2170000, len=41, n/ep=0, n/st=10, player_1/loss=1.292, player_2/loss=1.553, rew=173.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #217: test_reward: 209.900000 ± 69.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #218: 10001it [00:33, 302.03it/s, env_step=2180000, len=27, n/ep=1, n/st=10, player_1/loss=1.357, player_2/loss=1.478, rew=43.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #218: test_reward: 65.000000 ± 15.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #219: 10001it [00:33, 302.29it/s, env_step=2190000, len=11, n/ep=1, n/st=10, player_1/loss=1.422, player_2/loss=1.479, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #219: test_reward: 100.900000 ± 6.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #220: 10001it [00:33, 301.67it/s, env_step=2200000, len=17, n/ep=0, n/st=10, player_1/loss=1.448, player_2/loss=1.455, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #220: test_reward: 194.100000 ± 18.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #221: 10001it [00:33, 302.39it/s, env_step=2210000, len=13, n/ep=1, n/st=10, player_1/loss=1.352, player_2/loss=1.475, rew=11.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #221: test_reward: 89.000000 ± 27.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #222: 10001it [00:33, 301.44it/s, env_step=2220000, len=31, n/ep=0, n/st=10, player_1/loss=1.400, player_2/loss=1.601, rew=45.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #222: test_reward: 36.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #223: 10001it [00:33, 301.80it/s, env_step=2230000, len=42, n/ep=0, n/st=10, player_1/loss=1.384, player_2/loss=1.420, rew=205.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #223: test_reward: 31.100000 ± 15.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #224: 10001it [00:33, 301.47it/s, env_step=2240000, len=10, n/ep=0, n/st=10, player_1/loss=1.272, player_2/loss=1.509, rew=2.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #224: test_reward: 104.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #225: 10001it [00:33, 301.63it/s, env_step=2250000, len=18, n/ep=0, n/st=10, player_1/loss=1.449, player_2/loss=1.564, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #225: test_reward: 2.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #226: 10001it [00:33, 302.42it/s, env_step=2260000, len=23, n/ep=0, n/st=10, player_1/loss=1.503, player_2/loss=1.643, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #226: test_reward: 126.200000 ± 46.468914, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #227: 10001it [00:33, 301.91it/s, env_step=2270000, len=26, n/ep=0, n/st=10, player_1/loss=1.306, player_2/loss=1.523, rew=54.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #227: test_reward: 50.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #228: 10001it [00:33, 302.56it/s, env_step=2280000, len=14, n/ep=2, n/st=10, player_1/loss=1.277, player_2/loss=1.532, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #228: test_reward: 81.000000 ± 3.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #229: 10001it [00:33, 302.24it/s, env_step=2290000, len=18, n/ep=0, n/st=10, player_1/loss=1.357, player_2/loss=1.597, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #229: test_reward: 58.500000 ± 19.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #230: 10001it [00:33, 302.01it/s, env_step=2300000, len=33, n/ep=1, n/st=10, player_1/loss=1.429, player_2/loss=1.603, rew=74.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #230: test_reward: 109.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #231: 10001it [00:33, 301.46it/s, env_step=2310000, len=42, n/ep=0, n/st=10, player_1/loss=1.414, player_2/loss=1.536, rew=221.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #231: test_reward: 96.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #232: 10001it [00:33, 302.11it/s, env_step=2320000, len=7, n/ep=1, n/st=10, player_1/loss=1.409, player_2/loss=1.584, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #232: test_reward: 44.600000 ± 15.460918, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #233: 10001it [00:33, 302.01it/s, env_step=2330000, len=27, n/ep=0, n/st=10, player_1/loss=1.375, player_2/loss=1.539, rew=73.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #233: test_reward: 58.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #234: 10001it [00:33, 301.68it/s, env_step=2340000, len=11, n/ep=0, n/st=10, player_1/loss=1.373, player_2/loss=1.529, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #234: test_reward: 95.900000 ± 31.988904, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #235: 10001it [00:33, 301.87it/s, env_step=2350000, len=17, n/ep=0, n/st=10, player_1/loss=1.374, player_2/loss=1.397, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #235: test_reward: 79.300000 ± 6.900000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #236: 10001it [00:33, 301.72it/s, env_step=2360000, len=20, n/ep=0, n/st=10, player_1/loss=1.315, player_2/loss=1.475, rew=43.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #236: test_reward: 188.800000 ± 8.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #237: 10001it [00:33, 301.90it/s, env_step=2370000, len=11, n/ep=0, n/st=10, player_1/loss=1.308, player_2/loss=1.430, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #237: test_reward: 185.800000 ± 57.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #238: 10001it [00:33, 301.40it/s, env_step=2380000, len=25, n/ep=0, n/st=10, player_1/loss=1.270, player_2/loss=1.410, rew=42.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #238: test_reward: 122.200000 ± 0.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #239: 10001it [00:33, 300.98it/s, env_step=2390000, len=29, n/ep=1, n/st=10, player_1/loss=1.256, player_2/loss=1.464, rew=86.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #239: test_reward: 189.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #240: 10001it [00:33, 301.27it/s, env_step=2400000, len=18, n/ep=2, n/st=10, player_1/loss=1.221, player_2/loss=1.450, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #240: test_reward: 121.200000 ± 45.759808, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #241: 10001it [00:33, 302.16it/s, env_step=2410000, len=19, n/ep=0, n/st=10, player_1/loss=1.201, player_2/loss=1.415, rew=35.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #241: test_reward: 66.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #242: 10001it [00:33, 301.87it/s, env_step=2420000, len=31, n/ep=1, n/st=10, player_1/loss=1.307, player_2/loss=1.564, rew=86.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #242: test_reward: 83.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #243: 10001it [00:33, 301.32it/s, env_step=2430000, len=22, n/ep=0, n/st=10, player_1/loss=1.307, player_2/loss=1.484, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #243: test_reward: 162.400000 ± 44.292663, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #244: 10001it [00:33, 301.67it/s, env_step=2440000, len=17, n/ep=1, n/st=10, player_1/loss=1.340, player_2/loss=1.482, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #244: test_reward: 104.800000 ± 16.743954, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #245: 10001it [00:33, 301.59it/s, env_step=2450000, len=36, n/ep=0, n/st=10, player_1/loss=1.374, player_2/loss=1.354, rew=109.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #245: test_reward: 132.800000 ± 42.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #246: 10001it [00:33, 301.49it/s, env_step=2460000, len=23, n/ep=1, n/st=10, player_1/loss=1.398, player_2/loss=1.404, rew=34.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #246: test_reward: 190.200000 ± 64.703632, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #247: 10001it [00:33, 300.90it/s, env_step=2470000, len=8, n/ep=0, n/st=10, player_1/loss=1.318, player_2/loss=1.443, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #247: test_reward: 137.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #248: 10001it [00:33, 301.44it/s, env_step=2480000, len=11, n/ep=1, n/st=10, player_1/loss=1.339, player_2/loss=1.453, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #248: test_reward: 145.300000 ± 11.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #249: 10001it [00:33, 301.44it/s, env_step=2490000, len=8, n/ep=1, n/st=10, player_1/loss=1.308, player_2/loss=1.452, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #249: test_reward: 170.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #250: 10001it [00:33, 301.26it/s, env_step=2500000, len=8, n/ep=0, n/st=10, player_1/loss=1.230, player_2/loss=1.392, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #250: test_reward: 144.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #251: 10001it [00:33, 301.50it/s, env_step=2510000, len=10, n/ep=0, n/st=10, player_1/loss=1.347, player_2/loss=1.366, rew=2.50]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #251: test_reward: 164.500000 ± 25.993268, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #252: 10001it [00:33, 301.79it/s, env_step=2520000, len=8, n/ep=1, n/st=10, player_1/loss=1.345, player_2/loss=1.378, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #252: test_reward: 161.900000 ± 49.178146, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #253: 10001it [00:33, 301.89it/s, env_step=2530000, len=19, n/ep=0, n/st=10, player_1/loss=1.376, player_2/loss=1.401, rew=16.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #253: test_reward: 201.900000 ± 6.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #254: 10001it [00:33, 301.76it/s, env_step=2540000, len=24, n/ep=0, n/st=10, player_1/loss=1.378, player_2/loss=1.385, rew=133.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #254: test_reward: 195.800000 ± 64.623216, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #255: 10001it [00:33, 301.73it/s, env_step=2550000, len=14, n/ep=1, n/st=10, player_1/loss=1.398, player_2/loss=1.324, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #255: test_reward: 213.400000 ± 4.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #256: 10001it [00:33, 301.46it/s, env_step=2560000, len=28, n/ep=0, n/st=10, player_1/loss=1.457, player_2/loss=1.450, rew=47.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #256: test_reward: 96.300000 ± 47.518523, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #257: 10001it [00:33, 301.59it/s, env_step=2570000, len=16, n/ep=1, n/st=10, player_1/loss=1.479, player_2/loss=1.544, rew=16.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #257: test_reward: 70.800000 ± 0.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #258: 10001it [00:33, 301.29it/s, env_step=2580000, len=20, n/ep=2, n/st=10, player_1/loss=1.380, player_2/loss=1.509, rew=42.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #258: test_reward: 192.300000 ± 58.537253, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #259: 10001it [00:33, 301.22it/s, env_step=2590000, len=27, n/ep=2, n/st=10, player_1/loss=1.403, player_2/loss=1.365, rew=44.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #259: test_reward: 154.900000 ± 6.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #260: 10001it [00:33, 300.11it/s, env_step=2600000, len=25, n/ep=0, n/st=10, player_1/loss=1.461, player_2/loss=1.446, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #260: test_reward: 107.100000 ± 32.700000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #261: 10001it [00:33, 301.37it/s, env_step=2610000, len=27, n/ep=2, n/st=10, player_1/loss=1.343, player_2/loss=1.293, rew=82.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #261: test_reward: 121.200000 ± 8.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #262: 10001it [00:33, 300.88it/s, env_step=2620000, len=9, n/ep=0, n/st=10, player_1/loss=1.306, player_2/loss=1.350, rew=2.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #262: test_reward: 129.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #263: 10001it [00:33, 301.50it/s, env_step=2630000, len=9, n/ep=0, n/st=10, player_1/loss=1.369, player_2/loss=1.444, rew=4.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #263: test_reward: 120.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #264: 10001it [00:33, 300.41it/s, env_step=2640000, len=25, n/ep=1, n/st=10, player_1/loss=1.386, player_2/loss=1.460, rew=17.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #264: test_reward: 107.500000 ± 5.783597, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #265: 10001it [00:33, 299.21it/s, env_step=2650000, len=13, n/ep=1, n/st=10, player_1/loss=1.359, player_2/loss=1.483, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #265: test_reward: 194.700000 ± 63.236145, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #266: 10001it [00:33, 300.26it/s, env_step=2660000, len=13, n/ep=1, n/st=10, player_1/loss=1.358, player_2/loss=1.471, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #266: test_reward: 182.700000 ± 59.786370, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #267: 10001it [00:33, 300.93it/s, env_step=2670000, len=29, n/ep=1, n/st=10, player_1/loss=1.490, player_2/loss=1.570, rew=88.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #267: test_reward: 34.500000 ± 8.381527, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #268: 10001it [00:33, 301.43it/s, env_step=2680000, len=16, n/ep=0, n/st=10, player_1/loss=1.473, player_2/loss=1.559, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #268: test_reward: 205.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #269: 10001it [00:33, 300.90it/s, env_step=2690000, len=30, n/ep=0, n/st=10, player_1/loss=1.397, player_2/loss=1.431, rew=59.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #269: test_reward: 139.900000 ± 3.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #270: 10001it [00:33, 301.58it/s, env_step=2700000, len=34, n/ep=0, n/st=10, player_1/loss=1.401, player_2/loss=1.412, rew=49.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #270: test_reward: 184.400000 ± 7.255343, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #271: 10001it [00:33, 301.78it/s, env_step=2710000, len=36, n/ep=2, n/st=10, player_1/loss=1.331, player_2/loss=1.389, rew=97.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #271: test_reward: 153.100000 ± 20.612860, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #272: 10001it [00:33, 301.57it/s, env_step=2720000, len=26, n/ep=0, n/st=10, player_1/loss=1.333, player_2/loss=1.410, rew=55.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #272: test_reward: 179.900000 ± 56.946378, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #273: 10001it [00:33, 301.59it/s, env_step=2730000, len=15, n/ep=1, n/st=10, player_1/loss=1.275, player_2/loss=1.405, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #273: test_reward: 197.400000 ± 42.379712, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #274: 10001it [00:33, 301.69it/s, env_step=2740000, len=8, n/ep=1, n/st=10, player_1/loss=1.254, player_2/loss=1.370, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #274: test_reward: 189.500000 ± 25.500000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #275: 10001it [00:33, 301.69it/s, env_step=2750000, len=17, n/ep=0, n/st=10, player_1/loss=1.322, player_2/loss=1.340, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #275: test_reward: 166.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #276: 10001it [00:33, 300.30it/s, env_step=2760000, len=42, n/ep=1, n/st=10, player_1/loss=1.299, player_2/loss=1.424, rew=230.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #276: test_reward: 223.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #277: 10001it [00:33, 301.59it/s, env_step=2770000, len=24, n/ep=0, n/st=10, player_1/loss=1.330, player_2/loss=1.429, rew=53.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #277: test_reward: 222.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #278: 10001it [00:33, 301.18it/s, env_step=2780000, len=17, n/ep=0, n/st=10, player_1/loss=1.240, player_2/loss=1.250, rew=20.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #278: test_reward: 208.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #279: 10001it [00:33, 301.17it/s, env_step=2790000, len=17, n/ep=0, n/st=10, player_1/loss=1.366, player_2/loss=1.392, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #279: test_reward: 134.400000 ± 1.800000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #280: 10001it [00:33, 301.11it/s, env_step=2800000, len=14, n/ep=0, n/st=10, player_1/loss=1.372, player_2/loss=1.424, rew=16.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #280: test_reward: 148.600000 ± 10.200000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #281: 10001it [00:33, 301.89it/s, env_step=2810000, len=39, n/ep=0, n/st=10, player_1/loss=1.359, player_2/loss=1.476, rew=89.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #281: test_reward: 204.200000 ± 8.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #282: 10001it [00:33, 301.94it/s, env_step=2820000, len=36, n/ep=0, n/st=10, player_1/loss=1.400, player_2/loss=1.651, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #282: test_reward: 124.800000 ± 35.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #283: 10001it [00:33, 301.60it/s, env_step=2830000, len=22, n/ep=1, n/st=10, player_1/loss=1.361, player_2/loss=1.523, rew=20.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #283: test_reward: 80.000000 ± 30.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #284: 10001it [00:33, 301.56it/s, env_step=2840000, len=25, n/ep=1, n/st=10, player_1/loss=1.375, player_2/loss=1.571, rew=66.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #284: test_reward: 170.500000 ± 76.931463, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #285: 10001it [00:33, 296.78it/s, env_step=2850000, len=8, n/ep=1, n/st=10, player_1/loss=1.440, player_2/loss=1.661, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #285: test_reward: 99.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #286: 10001it [00:33, 301.01it/s, env_step=2860000, len=8, n/ep=1, n/st=10, player_1/loss=1.395, player_2/loss=1.578, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #286: test_reward: 81.000000 ± 21.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #287: 10001it [00:33, 301.50it/s, env_step=2870000, len=38, n/ep=0, n/st=10, player_1/loss=1.375, player_2/loss=1.460, rew=71.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #287: test_reward: 166.200000 ± 53.906957, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #288: 10001it [00:33, 301.46it/s, env_step=2880000, len=28, n/ep=0, n/st=10, player_1/loss=1.317, player_2/loss=1.504, rew=95.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #288: test_reward: 176.100000 ± 14.003214, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #289: 10001it [00:33, 300.27it/s, env_step=2890000, len=11, n/ep=1, n/st=10, player_1/loss=1.391, player_2/loss=1.571, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #289: test_reward: 100.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #290: 10001it [00:33, 301.37it/s, env_step=2900000, len=13, n/ep=1, n/st=10, player_1/loss=1.363, player_2/loss=1.536, rew=7.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #290: test_reward: 209.600000 ± 43.200000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #291: 10001it [00:33, 301.02it/s, env_step=2910000, len=22, n/ep=0, n/st=10, player_1/loss=1.323, player_2/loss=1.402, rew=35.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #291: test_reward: 102.700000 ± 30.285475, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #292: 10001it [00:33, 301.17it/s, env_step=2920000, len=33, n/ep=0, n/st=10, player_1/loss=1.304, player_2/loss=1.284, rew=103.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #292: test_reward: 136.200000 ± 2.400000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #293: 10001it [00:33, 301.09it/s, env_step=2930000, len=21, n/ep=0, n/st=10, player_1/loss=1.391, player_2/loss=1.411, rew=40.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #293: test_reward: 101.300000 ± 28.607866, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #294: 10001it [00:33, 299.79it/s, env_step=2940000, len=31, n/ep=2, n/st=10, player_1/loss=1.407, player_2/loss=1.452, rew=113.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #294: test_reward: 72.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #295: 10001it [00:33, 302.07it/s, env_step=2950000, len=8, n/ep=0, n/st=10, player_1/loss=1.452, player_2/loss=1.514, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #295: test_reward: 225.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #296: 10001it [00:33, 301.37it/s, env_step=2960000, len=33, n/ep=0, n/st=10, player_1/loss=1.424, player_2/loss=1.662, rew=151.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #296: test_reward: 241.000000 ± 15.159156, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #297: 10001it [00:33, 301.34it/s, env_step=2970000, len=42, n/ep=0, n/st=10, player_1/loss=1.349, player_2/loss=1.470, rew=243.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #297: test_reward: 156.600000 ± 46.169687, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #298: 10001it [00:33, 301.53it/s, env_step=2980000, len=30, n/ep=1, n/st=10, player_1/loss=1.335, player_2/loss=1.656, rew=61.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #298: test_reward: 96.200000 ± 3.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #299: 10001it [00:33, 301.32it/s, env_step=2990000, len=20, n/ep=1, n/st=10, player_1/loss=1.302, player_2/loss=1.649, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #299: test_reward: 151.700000 ± 23.100000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #300: 10001it [00:33, 301.30it/s, env_step=3000000, len=15, n/ep=0, n/st=10, player_1/loss=1.353, player_2/loss=1.487, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #300: test_reward: 164.700000 ± 51.969318, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #301: 10001it [00:33, 300.11it/s, env_step=3010000, len=15, n/ep=1, n/st=10, player_1/loss=1.323, player_2/loss=1.462, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #301: test_reward: 93.600000 ± 32.009998, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #302: 10001it [00:33, 300.83it/s, env_step=3020000, len=28, n/ep=0, n/st=10, player_1/loss=1.302, player_2/loss=1.519, rew=84.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #302: test_reward: 18.100000 ± 3.300000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #303: 10001it [00:33, 299.30it/s, env_step=3030000, len=19, n/ep=0, n/st=10, player_1/loss=1.292, player_2/loss=1.599, rew=24.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #303: test_reward: 197.400000 ± 65.126339, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #304: 10001it [00:33, 300.00it/s, env_step=3040000, len=13, n/ep=0, n/st=10, player_1/loss=1.337, player_2/loss=1.540, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #304: test_reward: 114.000000 ± 6.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #305: 10001it [00:33, 301.13it/s, env_step=3050000, len=9, n/ep=0, n/st=10, player_1/loss=1.308, player_2/loss=1.494, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #305: test_reward: 102.000000 ± 0.000000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #306: 10001it [00:33, 300.50it/s, env_step=3060000, len=11, n/ep=0, n/st=10, player_1/loss=1.387, player_2/loss=1.582, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #306: test_reward: 100.200000 ± 3.600000, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #307: 10001it [00:33, 301.13it/s, env_step=3070000, len=17, n/ep=0, n/st=10, player_1/loss=1.427, player_2/loss=1.590, rew=24.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #307: test_reward: 82.300000 ± 8.832327, best_reward: 252.400000 ± 13.800000 in #133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #308: 10001it [00:33, 299.59it/s, env_step=3080000, len=7, n/ep=1, n/st=10, player_1/loss=1.355, player_2/loss=1.544, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #308: test_reward: 258.200000 ± 26.400000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #309: 10001it [00:33, 297.24it/s, env_step=3090000, len=21, n/ep=1, n/st=10, player_1/loss=1.377, player_2/loss=1.571, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #309: test_reward: 40.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #310: 10001it [00:33, 297.52it/s, env_step=3100000, len=19, n/ep=1, n/st=10, player_1/loss=1.366, player_2/loss=1.446, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #310: test_reward: 237.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #311: 10001it [00:33, 300.21it/s, env_step=3110000, len=32, n/ep=1, n/st=10, player_1/loss=1.438, player_2/loss=1.581, rew=56.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #311: test_reward: 165.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #312: 10001it [00:33, 298.77it/s, env_step=3120000, len=24, n/ep=0, n/st=10, player_1/loss=1.355, player_2/loss=1.460, rew=97.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #312: test_reward: 172.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #313: 10001it [00:33, 299.01it/s, env_step=3130000, len=24, n/ep=0, n/st=10, player_1/loss=1.356, player_2/loss=1.490, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #313: test_reward: 257.600000 ± 1.959592, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #314: 10001it [00:33, 299.94it/s, env_step=3140000, len=37, n/ep=0, n/st=10, player_1/loss=1.296, player_2/loss=1.432, rew=99.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #314: test_reward: 120.900000 ± 34.288336, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #315: 10001it [00:33, 298.98it/s, env_step=3150000, len=28, n/ep=0, n/st=10, player_1/loss=1.336, player_2/loss=1.520, rew=75.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #315: test_reward: 36.400000 ± 4.200000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #316: 10001it [00:33, 299.49it/s, env_step=3160000, len=25, n/ep=0, n/st=10, player_1/loss=1.407, player_2/loss=1.579, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #316: test_reward: 114.300000 ± 12.198770, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #317: 10001it [00:33, 300.02it/s, env_step=3170000, len=9, n/ep=2, n/st=10, player_1/loss=1.350, player_2/loss=1.569, rew=2.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #317: test_reward: 10.500000 ± 10.500000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #318: 10001it [00:33, 299.79it/s, env_step=3180000, len=15, n/ep=0, n/st=10, player_1/loss=1.260, player_2/loss=1.464, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #318: test_reward: 161.700000 ± 38.564362, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #319: 10001it [00:33, 299.56it/s, env_step=3190000, len=23, n/ep=0, n/st=10, player_1/loss=1.330, player_2/loss=1.492, rew=50.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #319: test_reward: 7.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #320: 10001it [00:33, 298.71it/s, env_step=3200000, len=40, n/ep=1, n/st=10, player_1/loss=1.344, player_2/loss=1.548, rew=115.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #320: test_reward: 170.700000 ± 45.607127, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #321: 10001it [00:33, 301.06it/s, env_step=3210000, len=11, n/ep=1, n/st=10, player_1/loss=1.324, player_2/loss=1.518, rew=7.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #321: test_reward: 7.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #322: 10001it [00:33, 301.85it/s, env_step=3220000, len=21, n/ep=0, n/st=10, player_1/loss=1.325, player_2/loss=1.557, rew=15.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #322: test_reward: 112.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #323: 10001it [00:33, 301.20it/s, env_step=3230000, len=20, n/ep=1, n/st=10, player_1/loss=1.276, player_2/loss=1.499, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #323: test_reward: 250.000000 ± 0.000000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #324: 10001it [00:33, 301.44it/s, env_step=3240000, len=31, n/ep=2, n/st=10, player_1/loss=1.284, player_2/loss=1.536, rew=119.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #324: test_reward: 125.800000 ± 45.134909, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #325: 10001it [00:33, 301.60it/s, env_step=3250000, len=13, n/ep=1, n/st=10, player_1/loss=1.290, player_2/loss=1.564, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #325: test_reward: 28.500000 ± 1.500000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #326: 10001it [00:33, 301.05it/s, env_step=3260000, len=22, n/ep=1, n/st=10, player_1/loss=1.395, player_2/loss=1.550, rew=41.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #326: test_reward: 37.300000 ± 0.900000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #327: 10001it [00:33, 300.63it/s, env_step=3270000, len=20, n/ep=1, n/st=10, player_1/loss=1.294, player_2/loss=1.509, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #327: test_reward: 214.000000 ± 9.685040, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #328: 10001it [00:33, 300.56it/s, env_step=3280000, len=21, n/ep=0, n/st=10, player_1/loss=1.227, player_2/loss=1.578, rew=42.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #328: test_reward: 171.800000 ± 8.400000, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #329: 10001it [00:33, 300.75it/s, env_step=3290000, len=11, n/ep=0, n/st=10, player_1/loss=1.296, player_2/loss=1.554, rew=7.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #329: test_reward: 69.800000 ± 23.705696, best_reward: 258.200000 ± 26.400000 in #308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #330: 10001it [00:33, 301.03it/s, env_step=3300000, len=8, n/ep=1, n/st=10, player_1/loss=1.311, player_2/loss=1.550, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #330: test_reward: 287.200000 ± 2.088061, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #331: 10001it [00:33, 300.99it/s, env_step=3310000, len=27, n/ep=1, n/st=10, player_1/loss=1.276, player_2/loss=1.527, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #331: test_reward: 9.600000 ± 7.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #332: 10001it [00:33, 301.12it/s, env_step=3320000, len=8, n/ep=0, n/st=10, player_1/loss=1.325, player_2/loss=1.476, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #332: test_reward: 13.900000 ± 20.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #333: 10001it [00:33, 301.09it/s, env_step=3330000, len=19, n/ep=0, n/st=10, player_1/loss=1.382, player_2/loss=1.530, rew=30.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #333: test_reward: 7.600000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #334: 10001it [00:33, 301.49it/s, env_step=3340000, len=8, n/ep=1, n/st=10, player_1/loss=1.318, player_2/loss=1.618, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #334: test_reward: 56.600000 ± 34.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #335: 10001it [00:33, 300.73it/s, env_step=3350000, len=24, n/ep=2, n/st=10, player_1/loss=1.315, player_2/loss=1.679, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #335: test_reward: 147.400000 ± 43.347895, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #336: 10001it [00:33, 301.12it/s, env_step=3360000, len=16, n/ep=0, n/st=10, player_1/loss=1.311, player_2/loss=1.581, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #336: test_reward: 119.700000 ± 39.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #337: 10001it [00:33, 300.77it/s, env_step=3370000, len=18, n/ep=0, n/st=10, player_1/loss=1.336, player_2/loss=1.567, rew=18.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #337: test_reward: 15.200000 ± 24.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #338: 10001it [00:33, 300.57it/s, env_step=3380000, len=7, n/ep=0, n/st=10, player_1/loss=1.237, player_2/loss=1.568, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #338: test_reward: 50.200000 ± 2.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #339: 10001it [00:33, 300.83it/s, env_step=3390000, len=22, n/ep=2, n/st=10, player_1/loss=1.236, player_2/loss=1.483, rew=54.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #339: test_reward: 162.000000 ± 40.696437, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #340: 10001it [00:33, 301.04it/s, env_step=3400000, len=25, n/ep=0, n/st=10, player_1/loss=1.346, player_2/loss=1.608, rew=53.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #340: test_reward: 18.900000 ± 6.300000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #341: 10001it [00:33, 300.42it/s, env_step=3410000, len=36, n/ep=1, n/st=10, player_1/loss=1.332, player_2/loss=1.582, rew=118.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #341: test_reward: 66.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #342: 10001it [00:33, 301.16it/s, env_step=3420000, len=19, n/ep=1, n/st=10, player_1/loss=1.256, player_2/loss=1.599, rew=20.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #342: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #343: 10001it [00:33, 301.25it/s, env_step=3430000, len=7, n/ep=0, n/st=10, player_1/loss=1.298, player_2/loss=1.557, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #343: test_reward: 93.200000 ± 17.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #344: 10001it [00:33, 301.55it/s, env_step=3440000, len=19, n/ep=0, n/st=10, player_1/loss=1.331, player_2/loss=1.519, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #344: test_reward: 143.300000 ± 24.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #345: 10001it [00:33, 300.90it/s, env_step=3450000, len=24, n/ep=1, n/st=10, player_1/loss=1.266, player_2/loss=1.517, rew=49.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #345: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #346: 10001it [00:33, 301.16it/s, env_step=3460000, len=20, n/ep=1, n/st=10, player_1/loss=1.326, player_2/loss=1.534, rew=37.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #346: test_reward: 15.200000 ± 27.014070, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #347: 10001it [00:33, 300.45it/s, env_step=3470000, len=20, n/ep=2, n/st=10, player_1/loss=1.306, player_2/loss=1.536, rew=29.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #347: test_reward: 70.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #348: 10001it [00:33, 301.41it/s, env_step=3480000, len=14, n/ep=0, n/st=10, player_1/loss=1.362, player_2/loss=1.608, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #348: test_reward: 83.000000 ± 3.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #349: 10001it [00:33, 300.99it/s, env_step=3490000, len=24, n/ep=0, n/st=10, player_1/loss=1.231, player_2/loss=1.504, rew=38.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #349: test_reward: 160.700000 ± 18.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #350: 10001it [00:33, 301.22it/s, env_step=3500000, len=21, n/ep=0, n/st=10, player_1/loss=1.363, player_2/loss=1.566, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #350: test_reward: 10.600000 ± 10.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #351: 10001it [00:33, 301.14it/s, env_step=3510000, len=8, n/ep=0, n/st=10, player_1/loss=1.345, player_2/loss=1.551, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #351: test_reward: 110.200000 ± 20.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #352: 10001it [00:33, 300.55it/s, env_step=3520000, len=14, n/ep=0, n/st=10, player_1/loss=1.353, player_2/loss=1.472, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #352: test_reward: 161.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #353: 10001it [00:33, 301.25it/s, env_step=3530000, len=42, n/ep=1, n/st=10, player_1/loss=1.259, player_2/loss=1.337, rew=199.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #353: test_reward: 150.800000 ± 14.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #354: 10001it [00:33, 300.96it/s, env_step=3540000, len=28, n/ep=0, n/st=10, player_1/loss=1.278, player_2/loss=1.307, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #354: test_reward: 45.600000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #355: 10001it [00:33, 300.48it/s, env_step=3550000, len=28, n/ep=1, n/st=10, player_1/loss=1.369, player_2/loss=1.436, rew=38.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #355: test_reward: 148.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #356: 10001it [00:33, 300.34it/s, env_step=3560000, len=23, n/ep=0, n/st=10, player_1/loss=1.346, player_2/loss=1.419, rew=46.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #356: test_reward: 218.400000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #357: 10001it [00:33, 300.92it/s, env_step=3570000, len=26, n/ep=2, n/st=10, player_1/loss=1.365, player_2/loss=1.494, rew=58.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #357: test_reward: 118.800000 ± 39.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #358: 10001it [00:33, 301.30it/s, env_step=3580000, len=16, n/ep=1, n/st=10, player_1/loss=1.281, player_2/loss=1.450, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #358: test_reward: 177.500000 ± 56.482298, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #359: 10001it [00:33, 301.05it/s, env_step=3590000, len=8, n/ep=0, n/st=10, player_1/loss=1.237, player_2/loss=1.500, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #359: test_reward: 37.700000 ± 37.704244, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #360: 10001it [00:33, 301.07it/s, env_step=3600000, len=14, n/ep=0, n/st=10, player_1/loss=1.265, player_2/loss=1.593, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #360: test_reward: 148.700000 ± 29.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #361: 10001it [00:33, 300.81it/s, env_step=3610000, len=17, n/ep=1, n/st=10, player_1/loss=1.248, player_2/loss=1.547, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #361: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #362: 10001it [00:33, 301.03it/s, env_step=3620000, len=29, n/ep=0, n/st=10, player_1/loss=1.297, player_2/loss=1.474, rew=88.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #362: test_reward: 192.800000 ± 11.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #363: 10001it [00:33, 301.24it/s, env_step=3630000, len=16, n/ep=2, n/st=10, player_1/loss=1.341, player_2/loss=1.489, rew=22.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #363: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #364: 10001it [00:33, 301.02it/s, env_step=3640000, len=24, n/ep=1, n/st=10, player_1/loss=1.271, player_2/loss=1.528, rew=54.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #364: test_reward: 9.200000 ± 6.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #365: 10001it [00:33, 300.61it/s, env_step=3650000, len=15, n/ep=1, n/st=10, player_1/loss=1.326, player_2/loss=1.575, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #365: test_reward: 171.300000 ± 11.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #366: 10001it [00:33, 300.21it/s, env_step=3660000, len=26, n/ep=1, n/st=10, player_1/loss=1.318, player_2/loss=1.612, rew=66.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #366: test_reward: 80.000000 ± 6.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #367: 10001it [00:33, 300.58it/s, env_step=3670000, len=15, n/ep=0, n/st=10, player_1/loss=1.288, player_2/loss=1.529, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #367: test_reward: 85.300000 ± 26.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #368: 10001it [00:33, 300.68it/s, env_step=3680000, len=38, n/ep=1, n/st=10, player_1/loss=1.326, player_2/loss=1.561, rew=208.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #368: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #369: 10001it [00:33, 301.31it/s, env_step=3690000, len=14, n/ep=1, n/st=10, player_1/loss=1.309, player_2/loss=1.454, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #369: test_reward: 176.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #370: 10001it [00:33, 300.83it/s, env_step=3700000, len=8, n/ep=0, n/st=10, player_1/loss=1.193, player_2/loss=1.437, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #370: test_reward: 219.900000 ± 2.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #371: 10001it [00:33, 301.31it/s, env_step=3710000, len=31, n/ep=1, n/st=10, player_1/loss=1.230, player_2/loss=1.465, rew=108.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #371: test_reward: 46.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #372: 10001it [00:33, 300.85it/s, env_step=3720000, len=23, n/ep=0, n/st=10, player_1/loss=1.143, player_2/loss=1.426, rew=73.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #372: test_reward: 193.600000 ± 41.466131, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #373: 10001it [00:33, 300.33it/s, env_step=3730000, len=25, n/ep=0, n/st=10, player_1/loss=1.125, player_2/loss=1.452, rew=77.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #373: test_reward: 20.300000 ± 6.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #374: 10001it [00:33, 300.28it/s, env_step=3740000, len=34, n/ep=0, n/st=10, player_1/loss=1.170, player_2/loss=1.421, rew=102.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #374: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #375: 10001it [00:33, 300.43it/s, env_step=3750000, len=19, n/ep=1, n/st=10, player_1/loss=1.228, player_2/loss=1.355, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #375: test_reward: 83.200000 ± 14.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #376: 10001it [00:33, 301.06it/s, env_step=3760000, len=12, n/ep=0, n/st=10, player_1/loss=1.217, player_2/loss=1.376, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #376: test_reward: 131.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #377: 10001it [00:33, 301.31it/s, env_step=3770000, len=20, n/ep=0, n/st=10, player_1/loss=1.285, player_2/loss=1.520, rew=35.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #377: test_reward: 97.300000 ± 72.371334, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #378: 10001it [00:33, 301.34it/s, env_step=3780000, len=17, n/ep=2, n/st=10, player_1/loss=1.291, player_2/loss=1.423, rew=24.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #378: test_reward: 131.400000 ± 15.232859, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #379: 10001it [00:33, 300.86it/s, env_step=3790000, len=41, n/ep=1, n/st=10, player_1/loss=1.235, player_2/loss=1.399, rew=170.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #379: test_reward: 128.200000 ± 10.998182, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #380: 10001it [00:33, 300.67it/s, env_step=3800000, len=20, n/ep=0, n/st=10, player_1/loss=1.221, player_2/loss=1.537, rew=27.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #380: test_reward: 50.800000 ± 17.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #381: 10001it [00:33, 300.41it/s, env_step=3810000, len=25, n/ep=0, n/st=10, player_1/loss=1.223, player_2/loss=1.500, rew=99.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #381: test_reward: 186.000000 ± 48.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #382: 10001it [00:33, 300.36it/s, env_step=3820000, len=13, n/ep=1, n/st=10, player_1/loss=1.237, player_2/loss=1.415, rew=10.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #382: test_reward: 86.400000 ± 42.389150, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #383: 10001it [00:33, 300.41it/s, env_step=3830000, len=16, n/ep=0, n/st=10, player_1/loss=1.159, player_2/loss=1.382, rew=23.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #383: test_reward: 219.400000 ± 19.386593, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #384: 10001it [00:33, 300.53it/s, env_step=3840000, len=15, n/ep=0, n/st=10, player_1/loss=1.155, player_2/loss=1.379, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #384: test_reward: 172.100000 ± 54.369937, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #385: 10001it [00:33, 301.03it/s, env_step=3850000, len=13, n/ep=0, n/st=10, player_1/loss=1.161, player_2/loss=1.384, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #385: test_reward: 215.800000 ± 46.012607, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #386: 10001it [00:33, 301.24it/s, env_step=3860000, len=11, n/ep=0, n/st=10, player_1/loss=1.270, player_2/loss=1.403, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #386: test_reward: 188.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #387: 10001it [00:33, 300.86it/s, env_step=3870000, len=17, n/ep=0, n/st=10, player_1/loss=1.132, player_2/loss=1.403, rew=33.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #387: test_reward: 184.800000 ± 18.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #388: 10001it [00:33, 300.06it/s, env_step=3880000, len=37, n/ep=1, n/st=10, player_1/loss=1.199, player_2/loss=1.427, rew=85.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #388: test_reward: 114.300000 ± 12.759702, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #389: 10001it [00:33, 301.13it/s, env_step=3890000, len=41, n/ep=0, n/st=10, player_1/loss=1.205, player_2/loss=1.474, rew=216.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #389: test_reward: 150.800000 ± 64.703632, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #390: 10001it [00:33, 300.68it/s, env_step=3900000, len=15, n/ep=0, n/st=10, player_1/loss=1.203, player_2/loss=1.370, rew=12.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #390: test_reward: 21.200000 ± 3.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #391: 10001it [00:33, 300.51it/s, env_step=3910000, len=16, n/ep=0, n/st=10, player_1/loss=1.245, player_2/loss=1.450, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #391: test_reward: 216.600000 ± 22.200000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #392: 10001it [00:33, 300.39it/s, env_step=3920000, len=13, n/ep=1, n/st=10, player_1/loss=1.133, player_2/loss=1.381, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #392: test_reward: 16.200000 ± 5.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #393: 10001it [00:33, 300.82it/s, env_step=3930000, len=15, n/ep=0, n/st=10, player_1/loss=1.169, player_2/loss=1.428, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #393: test_reward: 54.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #394: 10001it [00:33, 300.70it/s, env_step=3940000, len=24, n/ep=0, n/st=10, player_1/loss=1.217, player_2/loss=1.428, rew=42.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #394: test_reward: 143.200000 ± 18.230743, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #395: 10001it [00:33, 300.68it/s, env_step=3950000, len=29, n/ep=0, n/st=10, player_1/loss=1.193, player_2/loss=1.535, rew=65.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #395: test_reward: 2.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #396: 10001it [00:33, 300.94it/s, env_step=3960000, len=27, n/ep=0, n/st=10, player_1/loss=1.129, player_2/loss=1.344, rew=79.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #396: test_reward: 112.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #397: 10001it [00:33, 300.54it/s, env_step=3970000, len=42, n/ep=1, n/st=10, player_1/loss=1.188, player_2/loss=1.385, rew=148.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #397: test_reward: 162.700000 ± 20.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #398: 10001it [00:33, 300.43it/s, env_step=3980000, len=12, n/ep=1, n/st=10, player_1/loss=1.223, player_2/loss=1.447, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #398: test_reward: 149.300000 ± 41.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #399: 10001it [00:33, 300.93it/s, env_step=3990000, len=17, n/ep=0, n/st=10, player_1/loss=1.206, player_2/loss=1.395, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #399: test_reward: 20.000000 ± 4.816638, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #400: 10001it [00:33, 300.98it/s, env_step=4000000, len=41, n/ep=0, n/st=10, player_1/loss=1.225, player_2/loss=1.457, rew=204.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #400: test_reward: 41.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #401: 10001it [00:33, 299.81it/s, env_step=4010000, len=11, n/ep=1, n/st=10, player_1/loss=1.172, player_2/loss=1.441, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #401: test_reward: 79.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #402: 10001it [00:33, 300.61it/s, env_step=4020000, len=18, n/ep=0, n/st=10, player_1/loss=1.156, player_2/loss=1.416, rew=15.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #402: test_reward: 112.200000 ± 35.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #403: 10001it [00:33, 300.59it/s, env_step=4030000, len=8, n/ep=1, n/st=10, player_1/loss=1.214, player_2/loss=1.493, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #403: test_reward: 102.800000 ± 28.272955, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #404: 10001it [00:33, 300.84it/s, env_step=4040000, len=7, n/ep=0, n/st=10, player_1/loss=1.198, player_2/loss=1.496, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #404: test_reward: 86.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #405: 10001it [00:33, 301.00it/s, env_step=4050000, len=11, n/ep=0, n/st=10, player_1/loss=1.219, player_2/loss=1.516, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #405: test_reward: 131.700000 ± 8.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #406: 10001it [00:33, 300.31it/s, env_step=4060000, len=8, n/ep=0, n/st=10, player_1/loss=1.216, player_2/loss=1.469, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #406: test_reward: 109.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #407: 10001it [00:33, 300.73it/s, env_step=4070000, len=42, n/ep=0, n/st=10, player_1/loss=1.215, player_2/loss=1.462, rew=190.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #407: test_reward: 143.100000 ± 68.358540, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #408: 10001it [00:33, 300.83it/s, env_step=4080000, len=9, n/ep=2, n/st=10, player_1/loss=1.258, player_2/loss=1.505, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #408: test_reward: 169.800000 ± 21.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #409: 10001it [00:33, 300.27it/s, env_step=4090000, len=12, n/ep=1, n/st=10, player_1/loss=1.191, player_2/loss=1.503, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #409: test_reward: 217.200000 ± 33.730698, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #410: 10001it [00:33, 299.02it/s, env_step=4100000, len=38, n/ep=1, n/st=10, player_1/loss=1.178, player_2/loss=1.372, rew=134.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #410: test_reward: 18.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #411: 10001it [00:33, 299.89it/s, env_step=4110000, len=18, n/ep=0, n/st=10, player_1/loss=1.236, player_2/loss=1.506, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #411: test_reward: 175.000000 ± 24.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #412: 10001it [00:33, 300.79it/s, env_step=4120000, len=14, n/ep=0, n/st=10, player_1/loss=1.148, player_2/loss=1.473, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #412: test_reward: 212.100000 ± 39.740282, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #413: 10001it [00:33, 300.27it/s, env_step=4130000, len=8, n/ep=0, n/st=10, player_1/loss=1.242, player_2/loss=1.416, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #413: test_reward: 151.600000 ± 18.821265, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #414: 10001it [00:33, 300.03it/s, env_step=4140000, len=25, n/ep=1, n/st=10, player_1/loss=1.418, player_2/loss=1.474, rew=34.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #414: test_reward: 8.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #415: 10001it [00:33, 300.31it/s, env_step=4150000, len=10, n/ep=1, n/st=10, player_1/loss=1.358, player_2/loss=1.477, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #415: test_reward: 89.200000 ± 54.101386, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #416: 10001it [00:33, 300.45it/s, env_step=4160000, len=7, n/ep=1, n/st=10, player_1/loss=1.274, player_2/loss=1.544, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #416: test_reward: 26.900000 ± 26.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #417: 10001it [00:33, 300.95it/s, env_step=4170000, len=8, n/ep=0, n/st=10, player_1/loss=1.258, player_2/loss=1.486, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #417: test_reward: 85.900000 ± 27.800899, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #418: 10001it [00:33, 300.54it/s, env_step=4180000, len=14, n/ep=0, n/st=10, player_1/loss=1.242, player_2/loss=1.401, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #418: test_reward: 202.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #419: 10001it [00:33, 300.39it/s, env_step=4190000, len=16, n/ep=1, n/st=10, player_1/loss=1.223, player_2/loss=1.342, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #419: test_reward: 271.900000 ± 0.300000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #420: 10001it [00:33, 300.44it/s, env_step=4200000, len=20, n/ep=1, n/st=10, player_1/loss=1.236, player_2/loss=1.349, rew=22.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #420: test_reward: 87.700000 ± 5.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #421: 10001it [00:33, 300.77it/s, env_step=4210000, len=33, n/ep=0, n/st=10, player_1/loss=1.278, player_2/loss=1.496, rew=93.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #421: test_reward: 111.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #422: 10001it [00:33, 300.04it/s, env_step=4220000, len=16, n/ep=0, n/st=10, player_1/loss=1.238, player_2/loss=1.429, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #422: test_reward: 42.900000 ± 29.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #423: 10001it [00:33, 300.56it/s, env_step=4230000, len=34, n/ep=1, n/st=10, player_1/loss=1.293, player_2/loss=1.375, rew=131.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #423: test_reward: 199.700000 ± 52.623284, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #424: 10001it [00:33, 300.59it/s, env_step=4240000, len=8, n/ep=0, n/st=10, player_1/loss=1.201, player_2/loss=1.384, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #424: test_reward: 161.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #425: 10001it [00:33, 300.36it/s, env_step=4250000, len=12, n/ep=0, n/st=10, player_1/loss=1.185, player_2/loss=1.305, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #425: test_reward: 226.600000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #426: 10001it [00:33, 300.87it/s, env_step=4260000, len=8, n/ep=0, n/st=10, player_1/loss=1.183, player_2/loss=1.391, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #426: test_reward: 22.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #427: 10001it [00:33, 300.70it/s, env_step=4270000, len=18, n/ep=0, n/st=10, player_1/loss=1.276, player_2/loss=1.412, rew=21.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #427: test_reward: 92.900000 ± 2.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #428: 10001it [00:33, 299.44it/s, env_step=4280000, len=40, n/ep=0, n/st=10, player_1/loss=1.246, player_2/loss=1.372, rew=178.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #428: test_reward: 28.800000 ± 38.773187, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #429: 10001it [00:33, 300.06it/s, env_step=4290000, len=26, n/ep=1, n/st=10, player_1/loss=1.223, player_2/loss=1.399, rew=61.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #429: test_reward: 144.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #430: 10001it [00:33, 300.83it/s, env_step=4300000, len=8, n/ep=1, n/st=10, player_1/loss=1.143, player_2/loss=1.326, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #430: test_reward: 154.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #431: 10001it [00:33, 300.21it/s, env_step=4310000, len=13, n/ep=0, n/st=10, player_1/loss=1.205, player_2/loss=1.330, rew=7.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #431: test_reward: 99.900000 ± 30.300000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #432: 10001it [00:33, 300.49it/s, env_step=4320000, len=19, n/ep=0, n/st=10, player_1/loss=1.227, player_2/loss=1.446, rew=30.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #432: test_reward: 7.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #433: 10001it [00:33, 300.28it/s, env_step=4330000, len=8, n/ep=0, n/st=10, player_1/loss=1.264, player_2/loss=1.444, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #433: test_reward: 27.700000 ± 17.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #434: 10001it [00:33, 299.77it/s, env_step=4340000, len=27, n/ep=1, n/st=10, player_1/loss=1.182, player_2/loss=1.381, rew=91.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #434: test_reward: 243.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #435: 10001it [00:33, 300.16it/s, env_step=4350000, len=13, n/ep=1, n/st=10, player_1/loss=1.141, player_2/loss=1.388, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #435: test_reward: 151.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #436: 10001it [00:33, 298.83it/s, env_step=4360000, len=10, n/ep=0, n/st=10, player_1/loss=1.183, player_2/loss=1.422, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #436: test_reward: 105.100000 ± 32.589722, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #437: 10001it [00:33, 299.23it/s, env_step=4370000, len=18, n/ep=0, n/st=10, player_1/loss=1.140, player_2/loss=1.352, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #437: test_reward: 58.700000 ± 5.330103, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #438: 10001it [00:33, 300.14it/s, env_step=4380000, len=27, n/ep=0, n/st=10, player_1/loss=1.142, player_2/loss=1.397, rew=99.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #438: test_reward: 151.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #439: 10001it [00:33, 299.14it/s, env_step=4390000, len=42, n/ep=0, n/st=10, player_1/loss=1.124, player_2/loss=1.384, rew=201.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #439: test_reward: 18.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #440: 10001it [00:33, 299.41it/s, env_step=4400000, len=27, n/ep=0, n/st=10, player_1/loss=1.105, player_2/loss=1.372, rew=93.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #440: test_reward: 221.800000 ± 3.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #441: 10001it [00:33, 299.52it/s, env_step=4410000, len=8, n/ep=1, n/st=10, player_1/loss=1.110, player_2/loss=1.303, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #441: test_reward: 121.200000 ± 3.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #442: 10001it [00:33, 297.86it/s, env_step=4420000, len=28, n/ep=0, n/st=10, player_1/loss=1.155, player_2/loss=1.360, rew=75.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #442: test_reward: 214.300000 ± 25.440322, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #443: 10001it [00:33, 298.66it/s, env_step=4430000, len=26, n/ep=0, n/st=10, player_1/loss=1.105, player_2/loss=1.440, rew=48.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #443: test_reward: 196.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #444: 10001it [00:33, 300.29it/s, env_step=4440000, len=18, n/ep=0, n/st=10, player_1/loss=1.122, player_2/loss=1.489, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #444: test_reward: 213.400000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #445: 10001it [00:33, 299.84it/s, env_step=4450000, len=12, n/ep=0, n/st=10, player_1/loss=1.147, player_2/loss=1.446, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #445: test_reward: 183.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #446: 10001it [00:33, 299.54it/s, env_step=4460000, len=12, n/ep=0, n/st=10, player_1/loss=1.174, player_2/loss=1.335, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #446: test_reward: 39.300000 ± 30.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #447: 10001it [00:33, 299.65it/s, env_step=4470000, len=18, n/ep=1, n/st=10, player_1/loss=1.124, player_2/loss=1.378, rew=27.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #447: test_reward: 120.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #448: 10001it [00:33, 300.52it/s, env_step=4480000, len=35, n/ep=1, n/st=10, player_1/loss=1.162, player_2/loss=1.324, rew=112.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #448: test_reward: 120.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #449: 10001it [00:33, 299.89it/s, env_step=4490000, len=8, n/ep=0, n/st=10, player_1/loss=1.254, player_2/loss=1.414, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #449: test_reward: 37.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #450: 10001it [00:33, 300.16it/s, env_step=4500000, len=12, n/ep=0, n/st=10, player_1/loss=1.129, player_2/loss=1.407, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #450: test_reward: 126.400000 ± 1.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #451: 10001it [00:33, 300.19it/s, env_step=4510000, len=16, n/ep=0, n/st=10, player_1/loss=1.246, player_2/loss=1.381, rew=24.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #451: test_reward: 127.300000 ± 6.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #452: 10001it [00:33, 300.08it/s, env_step=4520000, len=13, n/ep=0, n/st=10, player_1/loss=1.230, player_2/loss=1.361, rew=16.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #452: test_reward: 34.400000 ± 49.200000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #453: 10001it [00:33, 299.88it/s, env_step=4530000, len=22, n/ep=0, n/st=10, player_1/loss=1.187, player_2/loss=1.441, rew=36.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #453: test_reward: 31.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #454: 10001it [00:33, 299.56it/s, env_step=4540000, len=7, n/ep=0, n/st=10, player_1/loss=1.171, player_2/loss=1.416, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #454: test_reward: 134.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #455: 10001it [00:33, 298.33it/s, env_step=4550000, len=17, n/ep=1, n/st=10, player_1/loss=1.159, player_2/loss=1.388, rew=20.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #455: test_reward: 208.400000 ± 70.118756, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #456: 10001it [00:33, 299.64it/s, env_step=4560000, len=16, n/ep=0, n/st=10, player_1/loss=1.130, player_2/loss=1.330, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #456: test_reward: 200.400000 ± 13.146863, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #457: 10001it [00:33, 300.02it/s, env_step=4570000, len=16, n/ep=0, n/st=10, player_1/loss=1.158, player_2/loss=1.364, rew=11.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #457: test_reward: 208.000000 ± 2.792848, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #458: 10001it [00:33, 300.92it/s, env_step=4580000, len=8, n/ep=0, n/st=10, player_1/loss=1.267, player_2/loss=1.511, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #458: test_reward: 48.400000 ± 61.036383, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #459: 10001it [00:33, 299.93it/s, env_step=4590000, len=22, n/ep=2, n/st=10, player_1/loss=1.189, player_2/loss=1.478, rew=50.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #459: test_reward: 9.400000 ± 28.200000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #460: 10001it [00:33, 299.32it/s, env_step=4600000, len=23, n/ep=0, n/st=10, player_1/loss=1.179, player_2/loss=1.501, rew=48.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #460: test_reward: 46.100000 ± 19.081143, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #461: 10001it [00:33, 299.81it/s, env_step=4610000, len=28, n/ep=0, n/st=10, player_1/loss=1.170, player_2/loss=1.477, rew=112.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #461: test_reward: 227.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #462: 10001it [00:33, 298.44it/s, env_step=4620000, len=22, n/ep=1, n/st=10, player_1/loss=1.071, player_2/loss=1.325, rew=39.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #462: test_reward: 145.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #463: 10001it [00:33, 296.89it/s, env_step=4630000, len=10, n/ep=1, n/st=10, player_1/loss=1.142, player_2/loss=1.310, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #463: test_reward: 120.900000 ± 23.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #464: 10001it [00:33, 297.57it/s, env_step=4640000, len=23, n/ep=0, n/st=10, player_1/loss=1.180, player_2/loss=1.306, rew=63.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #464: test_reward: 194.900000 ± 0.300000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #465: 10001it [00:33, 296.59it/s, env_step=4650000, len=22, n/ep=0, n/st=10, player_1/loss=1.201, player_2/loss=1.347, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #465: test_reward: 116.900000 ± 37.998553, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #466: 10001it [00:33, 295.01it/s, env_step=4660000, len=13, n/ep=2, n/st=10, player_1/loss=1.176, player_2/loss=1.370, rew=10.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #466: test_reward: 22.700000 ± 20.100000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #467: 10001it [00:33, 296.31it/s, env_step=4670000, len=7, n/ep=1, n/st=10, player_1/loss=1.171, player_2/loss=1.447, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #467: test_reward: 197.000000 ± 23.668545, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #468: 10001it [00:33, 298.22it/s, env_step=4680000, len=17, n/ep=1, n/st=10, player_1/loss=1.239, player_2/loss=1.318, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #468: test_reward: 186.600000 ± 46.200000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #469: 10001it [00:33, 297.46it/s, env_step=4690000, len=13, n/ep=1, n/st=10, player_1/loss=1.260, player_2/loss=1.368, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #469: test_reward: 123.900000 ± 36.300000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #470: 10001it [00:33, 299.17it/s, env_step=4700000, len=8, n/ep=2, n/st=10, player_1/loss=1.230, player_2/loss=1.297, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #470: test_reward: 149.500000 ± 34.848960, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #471: 10001it [00:33, 299.07it/s, env_step=4710000, len=23, n/ep=2, n/st=10, player_1/loss=1.146, player_2/loss=1.290, rew=47.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #471: test_reward: 160.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #472: 10001it [00:33, 299.13it/s, env_step=4720000, len=33, n/ep=0, n/st=10, player_1/loss=1.322, player_2/loss=1.520, rew=74.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #472: test_reward: 66.600000 ± 14.664242, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #473: 10001it [00:33, 298.44it/s, env_step=4730000, len=31, n/ep=0, n/st=10, player_1/loss=1.372, player_2/loss=1.559, rew=100.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #473: test_reward: 111.600000 ± 42.802336, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #474: 10001it [00:33, 297.90it/s, env_step=4740000, len=20, n/ep=0, n/st=10, player_1/loss=1.239, player_2/loss=1.302, rew=32.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #474: test_reward: 184.400000 ± 4.800000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #475: 10001it [00:33, 297.81it/s, env_step=4750000, len=15, n/ep=0, n/st=10, player_1/loss=1.250, player_2/loss=1.266, rew=21.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #475: test_reward: 120.400000 ± 34.940521, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #476: 10001it [00:33, 298.30it/s, env_step=4760000, len=11, n/ep=0, n/st=10, player_1/loss=1.138, player_2/loss=1.272, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #476: test_reward: 204.700000 ± 0.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #477: 10001it [00:33, 298.67it/s, env_step=4770000, len=7, n/ep=0, n/st=10, player_1/loss=1.189, player_2/loss=1.274, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #477: test_reward: 132.000000 ± 36.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #478: 10001it [00:33, 298.83it/s, env_step=4780000, len=42, n/ep=1, n/st=10, player_1/loss=1.173, player_2/loss=1.272, rew=245.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #478: test_reward: 112.500000 ± 22.500000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #479: 10001it [00:33, 297.62it/s, env_step=4790000, len=34, n/ep=1, n/st=10, player_1/loss=1.122, player_2/loss=1.279, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #479: test_reward: 223.500000 ± 1.500000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #480: 10001it [00:33, 296.70it/s, env_step=4800000, len=20, n/ep=0, n/st=10, player_1/loss=1.285, player_2/loss=1.402, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #480: test_reward: 142.200000 ± 45.185838, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #481: 10001it [00:33, 295.53it/s, env_step=4810000, len=11, n/ep=1, n/st=10, player_1/loss=1.164, player_2/loss=1.328, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #481: test_reward: 137.500000 ± 45.657968, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #482: 10001it [00:33, 295.44it/s, env_step=4820000, len=27, n/ep=0, n/st=10, player_1/loss=1.163, player_2/loss=1.437, rew=54.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #482: test_reward: 86.100000 ± 8.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #483: 10001it [00:33, 296.30it/s, env_step=4830000, len=14, n/ep=0, n/st=10, player_1/loss=1.268, player_2/loss=1.425, rew=11.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #483: test_reward: 148.900000 ± 30.497377, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #484: 10001it [00:33, 296.36it/s, env_step=4840000, len=21, n/ep=0, n/st=10, player_1/loss=1.350, player_2/loss=1.581, rew=48.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #484: test_reward: 2.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #485: 10001it [00:33, 299.57it/s, env_step=4850000, len=26, n/ep=1, n/st=10, player_1/loss=1.261, player_2/loss=1.443, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #485: test_reward: 131.900000 ± 5.700000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #486: 10001it [00:33, 298.99it/s, env_step=4860000, len=30, n/ep=1, n/st=10, player_1/loss=1.189, player_2/loss=1.343, rew=60.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #486: test_reward: 154.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #487: 10001it [00:33, 299.24it/s, env_step=4870000, len=11, n/ep=0, n/st=10, player_1/loss=1.167, player_2/loss=1.347, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #487: test_reward: 74.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #488: 10001it [00:33, 296.98it/s, env_step=4880000, len=12, n/ep=0, n/st=10, player_1/loss=1.145, player_2/loss=1.340, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #488: test_reward: 28.800000 ± 32.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #489: 10001it [00:33, 298.59it/s, env_step=4890000, len=20, n/ep=1, n/st=10, player_1/loss=1.127, player_2/loss=1.380, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #489: test_reward: 136.800000 ± 12.600000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #490: 10001it [00:33, 297.82it/s, env_step=4900000, len=23, n/ep=0, n/st=10, player_1/loss=1.213, player_2/loss=1.382, rew=47.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #490: test_reward: 187.400000 ± 54.829189, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #491: 10001it [00:33, 298.90it/s, env_step=4910000, len=42, n/ep=0, n/st=10, player_1/loss=1.130, player_2/loss=1.355, rew=219.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #491: test_reward: 143.200000 ± 49.247944, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #492: 10001it [00:33, 296.83it/s, env_step=4920000, len=24, n/ep=0, n/st=10, player_1/loss=1.189, player_2/loss=1.342, rew=76.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #492: test_reward: 44.700000 ± 9.900000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #493: 10001it [00:33, 297.38it/s, env_step=4930000, len=18, n/ep=0, n/st=10, player_1/loss=1.230, player_2/loss=1.355, rew=49.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #493: test_reward: 115.800000 ± 38.765449, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #494: 10001it [00:33, 298.98it/s, env_step=4940000, len=18, n/ep=0, n/st=10, player_1/loss=1.122, player_2/loss=1.309, rew=23.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #494: test_reward: 208.200000 ± 44.823654, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #495: 10001it [00:33, 297.88it/s, env_step=4950000, len=30, n/ep=0, n/st=10, player_1/loss=1.157, player_2/loss=1.269, rew=100.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #495: test_reward: 165.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #496: 10001it [00:33, 299.35it/s, env_step=4960000, len=9, n/ep=0, n/st=10, player_1/loss=1.246, player_2/loss=1.400, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #496: test_reward: 22.000000 ± 0.000000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #497: 10001it [00:33, 299.01it/s, env_step=4970000, len=24, n/ep=0, n/st=10, player_1/loss=1.235, player_2/loss=1.461, rew=36.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #497: test_reward: 201.200000 ± 11.400000, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #498: 10001it [00:33, 298.94it/s, env_step=4980000, len=32, n/ep=0, n/st=10, player_1/loss=1.177, player_2/loss=1.426, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #498: test_reward: 189.200000 ± 5.827521, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #499: 10001it [00:33, 297.97it/s, env_step=4990000, len=16, n/ep=1, n/st=10, player_1/loss=1.176, player_2/loss=1.365, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #499: test_reward: 149.500000 ± 15.844557, best_reward: 287.200000 ± 2.088061 in #330\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: TRAINING AGENTS\n",
    "####################################################\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure the agents\n",
    "agent1 = rainbow_policy(state_shape= state_shape,\n",
    "                        action_shape= action_shape,\n",
    "                        learning_rate=  0.0001, # Increased from 0000625\n",
    "                        gamma= 0.8, # Decreased from 0.9\n",
    "                        n_step= 3, # Number of steps to look ahead\n",
    "                        num_atoms= 51,\n",
    "                        is_noisy= True,\n",
    "                        noisy_std= 0.1,\n",
    "                        is_dueling= True)\n",
    "\n",
    "\n",
    "agent2 = rainbow_policy(state_shape= state_shape,\n",
    "                        action_shape= action_shape,\n",
    "                        learning_rate=  0.0001, # Increased from 0000625\n",
    "                        gamma= 0.8, # Decreased from 0.9\n",
    "                        n_step= 3, # Number of steps to look ahead\n",
    "                        num_atoms= 51,\n",
    "                        is_noisy= True,\n",
    "                        noisy_std= 0.1,\n",
    "                        is_dueling= True)\n",
    "\n",
    "# Train the agent\n",
    "off_policy_traininer_results, final_agent_player1, final_agent_player2 = train_agent(filename= \"rainbow_vs_rainbow_blocking_reward_complex_cnn\",\n",
    "                                                                                     epochs= 500, # Default 50\n",
    "                                                                                     agent_player1= agent1,\n",
    "                                                                                     agent_player2= agent2,\n",
    "                                                                                     training_env_num= 10,\n",
    "                                                                                     testing_env_num= 10,\n",
    "                                                                                     buffer_size= 10000, # Default 100000\n",
    "                                                                                     batch_size= 64, # Default 32\n",
    "                                                                                     step_per_epoch= 10000, # Default 100000\n",
    "                                                                                     step_per_collect= 10,\n",
    "                                                                                     update_per_step= 0.1,\n",
    "                                                                                     testing_eps= 0.005,\n",
    "                                                                                     training_eps_init= 1,\n",
    "                                                                                     training_eps_final= 0.2) # Default 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c8f3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  42.0\n",
      "Final mean reward agent 1: 140.33333333333334, std: 1.8856180831641267\n",
      "Final mean reward agent 2: 152.0, std: 4.242640687119285\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE BEST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure the best agent\n",
    "best_agent1 = rainbow_policy(state_shape= state_shape,\n",
    "                             action_shape= action_shape)\n",
    "best_agent1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_complex_cnn/best_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "\n",
    "best_agent2 = rainbow_policy(state_shape= state_shape,\n",
    "                             action_shape= action_shape)\n",
    "best_agent2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_complex_cnn/best_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= best_agent1,\n",
    "      agent_player2= best_agent2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c704acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  35.0\n",
      "Final mean reward agent 1: 90.0, std: 0.0\n",
      "Final mean reward agent 2: 65.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE LAST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Configure the final agent\n",
    "final_agent_player1 = rainbow_policy(state_shape= state_shape,\n",
    "                                     action_shape= action_shape)\n",
    "final_agent_player1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_complex_cnn/final_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "final_agent_player2 = rainbow_policy(state_shape= state_shape,\n",
    "                                     action_shape= action_shape)\n",
    "final_agent_player2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_complex_cnn/final_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= final_agent_player1,\n",
    "      agent_player2= final_agent_player2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84478519",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "1. When a reward for making moves is given, the agents learn to play together rather then against each other. Just as was the case for DQN. This can be seen by looking at the gameplay of the best reward agents where a tie is reached.\n",
    "> Best reward: 594.700000 ± 344.331541 in epoch 64\n",
    "\n",
    "2. Afterwards we did an experiment with the \"default\" parameters, which does ten times as many iterations per epoch. The found results for the model using a reward for each move is a perfect synced play between agents of getting ties. Thus, this would have been identical as just doing more epochs.\n",
    "> Best reward: 932.000000 ± 0.000000 in epoch 37\n",
    "\n",
    "3. Since the agent optimizes to the rewards, it is more logical to give it a reward when blocking a winning move rather then just for any move made.\n",
    "This will incentive defensive behaviour which is what we want indeed. \n",
    "Since testing only happens on epochs and thus saving the model only happens after an epoch, we beleive it might be better to do shorter epochs but more epochs. For the default iteration and epoch count we got:\n",
    "> Best reward: 233.000000 ± 0.000000 in epoch 25\n",
    "\n",
    "4. After this we used rewards for blocking moves but using 10 times as many epochs for 10 times fewer iterations per epoch. The batch size was also increased to 64 and the learning rate was increased to 0,0001. The gamma was decreased to 0.8. All of this was done to combat the harder network to train and to have more checkpoints for testing for the best model. The reward was also changed so a blocking move gets 1, a win gets 5 (instead of 25) and a draw gets 3(instead of 15). As a result, we got:\n",
    "> Best reward: 280.000000 ± 0.000000 in epoch 380\n",
    "\n",
    "5. From the previous experiments, the fourth was most promising as it had results that were human-like. However, it seems to diverge from a defending strategy to a combination play strategy which causes it to perform worse again. We think a league based testing strategy would be better, which will be tested in the next notebook. Just to test our feature extraction capabilities, we do the same experiment but with a more complex CNN, namely one that outputs 64 filters instead of 16. We also keep the final epsilon higher, from 0.05 to 0.2 in an attempt to reduce the overfitting that seems to happen after a while (when the epsilon has fully decayed). This had de following results (best policy = attemtped ties):\n",
    "> Best reward: 287.200000 ± 2.088061 in epoch 330\n",
    "\n",
    "It is noted that comparing results is difficult since the reward strategy is different between the experiments.\n",
    "After manual inspection by playing against the bot and watching the bots play against each other, the most promosing setup was: the best policy from experiment 5, agent 1. It is noted that the agent playing as player 1 is significantly better then the agent playing as agent 2 in human play.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d9110be",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CLEAN VARIABLES\n",
    "####################################################\n",
    "\n",
    "del action_shape\n",
    "del agent1\n",
    "del agent2\n",
    "del best_agent1\n",
    "del best_agent2\n",
    "del env\n",
    "del final_agent_player1\n",
    "del final_agent_player2\n",
    "del observation_space\n",
    "del off_policy_traininer_results\n",
    "del state_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d3da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b88c88564fefe7444548986d165ad8d7f764d0079ffa923785a3f5a89d52c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
