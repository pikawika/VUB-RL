{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Using the Rainbow algorithm to learn connect four\n",
    "\n",
    "The previous notebooks all used Deep Q-Networks (DQN) to learn to play connect four and no real desired behaviour was obtained.\n",
    "Since rainbow by [Hessel et al](https://doi.org/10.48550/arXiv.1710.02298) is known to outperform DQN in both sample efficiency and overall performance for Atari games, we explore its performance on the connect four game as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Contact information\n",
    "- Checking requirements\n",
    "  - Correct Anaconda environment\n",
    "  - Correct module access\n",
    "  - Correct CUDA access\n",
    "- Training two Rainbow agents on connect four Gym\n",
    "  - Building the environment\n",
    "  - Implementing the Rainbow policy\n",
    "  - Building agents\n",
    "  - Function for letting agents learn\n",
    "  - Function for watching learned agent\n",
    "  - Doing the experiment\n",
    "- Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Contact information\n",
    "\n",
    "| Name             | Student ID | VUB mail                                                  | Personal mail                                               |\n",
    "| ---------------- | ---------- | --------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| Lennert Bontinck | 0568702    | [lennert.bontinck@vub.be](mailto:lennert.bontinck@vub.be) | [info@lennertbontinck.com](mailto:info@lennertbontinck.com) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a405d24",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements\n",
    "\n",
    "### Correct Anaconda environment\n",
    "\n",
    "The `rl-project` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the RL course project and homeworks](https://github.com/pikawika/vub-rl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: rl-project\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'rl-project'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following code block will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version (3.5.1 recommended): 3.5.1\n",
      "Pygame version (2.1.2 recommended): 2.1.2\n",
      "Gym version (0.21.0 recommended): 0.21.0\n",
      "Tianshou version (0.4.8 recommended): 0.4.8\n",
      "Torch version (1.12.0 recommended): 1.12.0.dev20220520+cu116\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Allow reloading of libraries\n",
    "import importlib\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Argparser\n",
    "import argparse\n",
    "\n",
    "# More data types\n",
    "import typing\n",
    "import numpy as np\n",
    "\n",
    "# Pygame\n",
    "import pygame; print(f\"Pygame version (2.1.2 recommended): {pygame.__version__}\")\n",
    "\n",
    "# Gym environment\n",
    "import gym; print(f\"Gym version (0.21.0 recommended): {gym.__version__}\")\n",
    "\n",
    "# Tianshou for RL algorithms\n",
    "import tianshou as ts; print(f\"Tianshou version (0.4.8 recommended): {ts.__version__}\")\n",
    "\n",
    "# Torch is a popular DL framework\n",
    "import torch; print(f\"Torch version (1.12.0 recommended): {torch.__version__}\")\n",
    "\n",
    "# PPrint is a pretty print for variables\n",
    "from pprint import pprint\n",
    "\n",
    "# Our custom connect four gym environment\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import gym_connect4_pygame.envs.ConnectFourPygameEnvV2 as cfgym\n",
    "importlib.invalidate_caches()\n",
    "importlib.reload(cfgym)\n",
    "\n",
    "# Time for allowing \"freezes\" in execution\n",
    "import time;\n",
    "\n",
    "# Allow for copying objects in a non reference manner\n",
    "import copy\n",
    "\n",
    "# Used for updating notebook display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617a21",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct CUDA access\n",
    "\n",
    "The installation instructions specify how to install PyTorch with CUDA 11.6.\n",
    "The following code block tests if this was done successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9f5ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "\n",
      "Amount of connected devices supporting CUDA: 1\n",
      "\n",
      "Current CUDA device: 0\n",
      "Cuda device 0 name: NVIDIA GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CUDA VALIDATION\n",
    "####################################################\n",
    "\n",
    "# Check cuda available\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Show cuda devices\n",
    "print(f\"\\nAmount of connected devices supporting CUDA: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Show current cuda device\n",
    "print(f\"\\nCurrent CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "# Show cuda device name\n",
    "print(f\"Cuda device 0 name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826657c4",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Training two Rainbow agents on connect four Gym\n",
    "\n",
    "Our connect four gym setup requires two agents, one for each player.\n",
    "To reduce complexity, agents will always play as the same player, e.g. always as player 1.\n",
    "It is important to note that connect four is a *solved game*.\n",
    "According to [The Washington Post](https://www.washingtonpost.com/news/wonk/wp/2015/05/08/how-to-win-any-popular-game-according-to-data-scientists/):\n",
    "\n",
    "> Connect Four is what mathematicians call a \"solved game,\" meaning you can play it perfectly every time, no matter what your opponent does. You will need to get the first move, but as long as you do so, you can always win within 41 moves.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### Building the environment\n",
    "\n",
    "This code is taken from previous notebooks.\n",
    "We don't allow invalid moves to make the problem easier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2b47a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Dict(action_mask:Box([0 0 0 0 0 0 0], [1 1 1 1 1 1 1], (7,), int8), observation:Box([[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]], [[2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]\n",
      " [2 2 2 2 2 2 2]], (6, 7), int8))\n",
      "\n",
      "Action space: Discrete(7)\n",
      "\n",
      " Initial player id:\n",
      "player_1\n",
      "\n",
      " Initial observation:\n",
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " Initial mask:\n",
      "[True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CONNECT FOUR V2 ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "def get_env():\n",
    "    \"\"\"\n",
    "    Returns the connect four gym environment V2 altered for Tianshou and Petting Zoo compatibility.\n",
    "    Already wrapped with a ts.env.PettingZooEnv wrapper.\n",
    "    \"\"\"\n",
    "    return ts.env.PettingZooEnv(cfgym.env(reward_move= 0, # Set to 1 for reward to make moves (incentivise longer games)\n",
    "                                          reward_blocking= 1, # Set to 1 for reward to make blocking moves (incentivise defensive games)\n",
    "                                          reward_invalid= -3,\n",
    "                                          reward_draw= 3,\n",
    "                                          reward_win= 5,\n",
    "                                          reward_loss= -5,\n",
    "                                          allow_invalid_move= False))\n",
    "    \n",
    "    \n",
    "# Test the environment\n",
    "env = get_env()\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"\\nAction space: {env.action_space}\")\n",
    "\n",
    "# Reset the environment to start from a clean state, returns the initial observation\n",
    "observation = env.reset()\n",
    "\n",
    "print(\"\\n Initial player id:\")\n",
    "print(observation[\"agent_id\"])\n",
    "\n",
    "print(\"\\n Initial observation:\")\n",
    "print(observation[\"obs\"])\n",
    "\n",
    "print(\"\\n Initial mask:\")\n",
    "print(observation[\"mask\"])\n",
    "\n",
    "# Clean unused variables\n",
    "del observation\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2e15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "Blocking move made by player 1: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# BLOCKING MOVE CHECK\n",
    "####################################################\n",
    "\n",
    "# Check if a reward is received for playing a blocking move\n",
    "\n",
    "env = get_env()\n",
    "env.reset()\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 0)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(env.rewards)\n",
    "env.step(action= 1)\n",
    "print(f\"Blocking move made by player 1: {env.rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7e7da",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Implementing the Rainbow policy\n",
    "\n",
    "The Rainbow policy for the agent is configured and set up below.\n",
    "This is based on the Atari rainbow example by the [Tianshou doc](https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py).\n",
    "Tianshou uses a DQN as base class for Rainbow, so we will do this to but adopt both classes to better represent our previous DQN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2f43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# DQN ARCHITECTURE\n",
    "####################################################\n",
    "\n",
    "class CNNForRainbow(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom CNN to be used as baseclass for the Rainbow algorithm.\n",
    "    Extracts \"feautures\" for the Rainbow algorithm by doing a 4x4 cnn kernel pass and providing 16 filters.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 state_shape: typing.Sequence[int],\n",
    "                 device: typing.Union[str, int, torch.device] = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        \n",
    "        # Torch init\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store device to be used\n",
    "        self.device = device\n",
    "        \n",
    "        # The input layer is singular -> we have 1 board vector\n",
    "        input_channels_cnn = 1\n",
    "        \n",
    "        # We output 16 filters per kernel \n",
    "        output_channels_cnn = 64 # Updated from previous 16\n",
    "        \n",
    "        # We store the output dimension of the CNN \"feature\" layer\n",
    "        self.output_dim = (state_shape[0] - 3) * (state_shape[1] - 3) * output_channels_cnn\n",
    "        \n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels= input_channels_cnn, out_channels= output_channels_cnn, kernel_size= 4, stride= 1), torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                obs: typing.Union[np.ndarray, torch.Tensor],\n",
    "                state: typing.Optional[typing.Any] = None,\n",
    "                info: typing.Dict[str, typing.Any] = {}):\n",
    "        # Make a torch instance (from regular vector of board)\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float, device=self.device)\n",
    "            \n",
    "        # Tianshou bugs the batch output, reshape to work properly with our torch version\n",
    "        if (len(np.shape(obs)) != 4):\n",
    "            obs = obs[:, None, :, :]\n",
    "        \n",
    "        # Return what is needed (network output & state)\n",
    "        return self.net(obs), state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b137ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RAINBOW ARCHITECTURE\n",
    "####################################################\n",
    "\n",
    "class Rainbow(CNNForRainbow):\n",
    "    \"\"\"\n",
    "    Implementation of the Rainbow algorithm making using of the CNNForRainbow baseclass.\n",
    "    Default parameters adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 state_shape: typing.Sequence[int],\n",
    "                 action_shape: typing.Sequence[int],\n",
    "                 device: typing.Union[str, int, torch.device] = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                 num_atoms: int = 51,\n",
    "                 is_noisy: bool = True,\n",
    "                 noisy_std: float = 0.1,\n",
    "                 is_dueling: bool = True):\n",
    "        \n",
    "        # Init CNN feature extraction parent class\n",
    "        super().__init__(state_shape= state_shape, device= device)\n",
    "        \n",
    "        # the amount of actions we have is just the action shape\n",
    "        self.action_num = np.prod(action_shape)\n",
    "        \n",
    "        # Store class specific info\n",
    "        self.num_atoms = num_atoms\n",
    "        self._is_dueling = is_dueling\n",
    "\n",
    "        # Our linear layer depends on wether or not we want to use a noisy environment\n",
    "        # Noisy implementation based on https://arxiv.org/abs/1706.10295\n",
    "        def linear(x, y):\n",
    "            if is_noisy:\n",
    "                return ts.utils.net.discrete.NoisyLinear(x, y, noisy_std)\n",
    "            else:\n",
    "                return torch.nn.Linear(x, y)\n",
    "            \n",
    "        # Specify Q and V based on wether or not agent is dueling\n",
    "        # Setting agent on dueling mode should help generalisation according to rainbow paper\n",
    "        # NOTE: this uses the output dim from the feature extraction CNN\n",
    "        self.Q = torch.nn.Sequential(\n",
    "            linear(self.output_dim, 512), torch.nn.ReLU(inplace=True),\n",
    "            linear(512, self.action_num * self.num_atoms))\n",
    "        \n",
    "        if self._is_dueling:\n",
    "            self.V = torch.nn.Sequential(\n",
    "                linear(self.output_dim, 512), torch.nn.ReLU(inplace=True),\n",
    "                linear(512, self.num_atoms))\n",
    "            \n",
    "        # New output dim for this rainbow network\n",
    "        self.output_dim = self.action_num * self.num_atoms\n",
    "        \n",
    "\n",
    "    def forward(self,\n",
    "                obs: typing.Union[np.ndarray, torch.Tensor],\n",
    "                state: typing.Optional[typing.Any] = None,\n",
    "                info: typing.Dict[str, typing.Any] = {}):\n",
    "        \n",
    "        # Use our parent CNN based network to get \"features\"\n",
    "        obs, state = super().forward(obs)\n",
    "        \n",
    "        # Get our Rainbow specific values\n",
    "        q = self.Q(obs)\n",
    "        q = q.view(-1, self.action_num, self.num_atoms)\n",
    "        \n",
    "        if self._is_dueling:\n",
    "            v = self.V(obs)\n",
    "            v = v.view(-1, 1, self.num_atoms)\n",
    "            logits = q - q.mean(dim=1, keepdim=True) + v\n",
    "        else:\n",
    "            logits = q\n",
    "        \n",
    "        # We need to go from our logits to an accepted dimension of probability outputs\n",
    "        probs = logits.softmax(dim=2)\n",
    "        \n",
    "        return probs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539b56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RAINBOW POLICY\n",
    "####################################################\n",
    "\n",
    "def rainbow_policy(state_shape: tuple,\n",
    "                   action_shape: tuple,\n",
    "                   optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                   learning_rate: float =  0.0000625,\n",
    "                   gamma: float = 0.9,\n",
    "                   n_step: int = 3, # Number of steps to look ahead\n",
    "                   num_atoms: int = 51,\n",
    "                   is_noisy: bool = True,\n",
    "                   noisy_std: float = 0.1,\n",
    "                   is_dueling: bool = True,\n",
    "                   target_update_freq: int = 500):\n",
    "    \"\"\"\n",
    "    Implementation of the Rainbow policy.\n",
    "    Default parameters adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use cuda device if possible\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Rainbow network to be used by policy\n",
    "    net = Rainbow(state_shape= state_shape,\n",
    "                  action_shape= action_shape,\n",
    "                  device= device,\n",
    "                  num_atoms= num_atoms,\n",
    "                  is_noisy= is_noisy,\n",
    "                  noisy_std= noisy_std,\n",
    "                  is_dueling= is_dueling).to(device)\n",
    "    \n",
    "    # Default optimizer is an adam optimizer with the argparser learning rate\n",
    "    if optim is None:\n",
    "        optim = torch.optim.Adam(net.parameters(), lr= learning_rate)\n",
    "        \n",
    "    # Our agents Rainbow policy\n",
    "    return ts.policy.RainbowPolicy(model= net,\n",
    "                                   optim= optim,\n",
    "                                   discount_factor= gamma,\n",
    "                                   num_atoms= num_atoms,\n",
    "                                   estimation_step= n_step,\n",
    "                                   target_update_freq= target_update_freq).to(device)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd411318",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Building agents\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a06d25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT CREATION\n",
    "####################################################\n",
    "\n",
    "def get_agent_manager(agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                      agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                      optim: typing.Optional[torch.optim.Optimizer] = None):\n",
    "    \"\"\"\n",
    "    Gets a multi agent policy manager, optimizer and player ids for the connect four V2 gym environment.\n",
    "    Per default this returns \n",
    "        - Multi agent manager for 2 agents using Rainbow\n",
    "        - Adam optimizer\n",
    "        - ['player_1', 'player_2'] from the connect four environment\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the environment to play in (Connect four gym V2)\n",
    "    env = get_env()\n",
    "    \n",
    "    # Get the observation space from the environment, depending on typo of space (ternary operator)\n",
    "    observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "    \n",
    "    # Set the arguments\n",
    "    state_shape = observation_space.shape or observation_space.n\n",
    "    action_shape = env.action_space.shape or env.action_space.n\n",
    "    \n",
    "    # Configure agent player 1 to be a Rainbow if no policy is passed.\n",
    "    if agent_player1 is None:\n",
    "        # Our agent1 uses a Rainbow policy\n",
    "        agent_player1 = rainbow_policy(state_shape= state_shape,\n",
    "                                       action_shape= action_shape,\n",
    "                                       optim= optim)\n",
    "    \n",
    "    # Configure agent player 2 to be a Rainbow if no policy is passed.\n",
    "    if agent_player2 is None:\n",
    "        # Our agent1 uses a Rainbow policy\n",
    "        agent_player2 = rainbow_policy(state_shape= state_shape,\n",
    "                                       action_shape= action_shape,\n",
    "                                       optim= optim)\n",
    "\n",
    "    # Default order of the agents\n",
    "    agents = [agent_player1, agent_player2]\n",
    "        \n",
    "    # Create the multi agent policy\n",
    "    policy = ts.policy.MultiAgentPolicyManager(agents, env)\n",
    "    \n",
    "    # Return our policy, optimizer and the available agents in the environment\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using Rainbow\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    \n",
    "    return policy, optim, env.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8f3a6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for letting agents learn\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d364383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# AGENT TRAINING\n",
    "####################################################\n",
    "\n",
    "def train_agent(filename: str = \"rainbow_vs_rainbow\",\n",
    "                agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "                optim: typing.Optional[torch.optim.Optimizer] = None,\n",
    "                training_env_num: int = 10,\n",
    "                testing_env_num: int = 10,\n",
    "                buffer_size: int = 100000,\n",
    "                batch_size: int = 32, \n",
    "                epochs: int = 50,\n",
    "                step_per_epoch: int = 100000,\n",
    "                step_per_collect: int = 10, # Should be multiple of the test/training envs\n",
    "                update_per_step: float = 0.1,\n",
    "                testing_eps: float = 0.005,\n",
    "                training_eps_init: float = 1,\n",
    "                training_eps_final: float = 0.05):\n",
    "    \"\"\"\n",
    "    Trains two agents in the connect four V2 environment and saves their best model and logs.\n",
    "    Returns:\n",
    "        - result from offpolicy_trainer\n",
    "        - final version of agent 1\n",
    "        - final version of agent 2\n",
    "    Defaults adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "    \"\"\"\n",
    "\n",
    "    # ======== notebook specific =========\n",
    "    notebook_version = '9' # Used for foldering logs and models\n",
    "\n",
    "    # ======== environment setup =========\n",
    "    train_envs = ts.env.DummyVectorEnv([get_env for _ in range(training_env_num)])\n",
    "    test_envs = ts.env.DummyVectorEnv([get_env for _ in range(testing_env_num)])\n",
    "    \n",
    "    # set the seed for reproducibility\n",
    "    np.random.seed(1998)\n",
    "    torch.manual_seed(1998)\n",
    "    train_envs.seed(1998)\n",
    "    test_envs.seed(1998)\n",
    "\n",
    "    # ======== agent setup =========\n",
    "    # Gets our agents from the previously made function\n",
    "    # Per default: \n",
    "    #   - Multi agent manager for 2 agents using Rainbow\n",
    "    #   - Adam optimizer\n",
    "    #   - ['player_1', 'player_2'] from the connect four environment\n",
    "    policy, optim, agents = get_agent_manager(agent_player1=agent_player1,\n",
    "                                              agent_player2=agent_player2,\n",
    "                                              optim=optim)\n",
    "\n",
    "    # ======== collector setup =========\n",
    "    # Make a collector for the training environments\n",
    "    buffer= ts.data.VectorReplayBuffer(total_size= buffer_size,\n",
    "                                       buffer_num=len(train_envs))\n",
    "    \n",
    "    train_collector = ts.data.Collector(policy= policy,\n",
    "                                        env= train_envs,\n",
    "                                        buffer= buffer,\n",
    "                                        exploration_noise= True)\n",
    "    \n",
    "    # Make a collector for the testing environments\n",
    "    test_collector = ts.data.Collector(policy= policy,\n",
    "                                       env= test_envs,\n",
    "                                       exploration_noise= True)\n",
    "    \n",
    "    # ======== ensure folders exist =========\n",
    "    if not os.path.exists(os.path.join('./logs', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./logs', 'paper_notebooks', notebook_version, filename))\n",
    "    if not os.path.exists(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename)):\n",
    "        os.makedirs(os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename))\n",
    "\n",
    "    # ======== tensorboard logging setup =========\n",
    "    # Allows to save the training progress to tensorboard compatable logs\n",
    "    log_path = os.path.join('./logs', 'paper_notebooks', notebook_version, filename)\n",
    "    writer = torch.utils.tensorboard.SummaryWriter(log_path)\n",
    "    logger = ts.utils.TensorboardLogger(writer)\n",
    "\n",
    "    # ======== callback functions used during training =========\n",
    "    # We want to save our best policy\n",
    "    def save_best_fn(policy):\n",
    "        \"\"\"\n",
    "        Callback to save the best model\n",
    "        \"\"\"\n",
    "        # Save best agent 1\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent1.pth')\n",
    "        torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save best agent 2\n",
    "        model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'best_policy_agent2.pth')\n",
    "        torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "        \n",
    "        # Save agent2\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        \"\"\"\n",
    "        Callback to stop training when we've reached the win rate\n",
    "        \"\"\"\n",
    "        return False # Not implemented\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback before training, sets the training epsilon in a decaying manner.\n",
    "        Adopted from: https://github.com/thu-ml/tianshou/blob/master/examples/atari/atari_rainbow.py\n",
    "        \"\"\"        \n",
    "        # Nature DQN setting to have a \"linear decaying epsilon\" for the first one million iterations\n",
    "        if env_step <= 1000000:\n",
    "            training_eps = training_eps_init - env_step / 1000000 * (training_eps_init - training_eps_final)\n",
    "        else:\n",
    "            training_eps = training_eps_final\n",
    "            \n",
    "            \n",
    "        # Set epsilon\n",
    "        policy.policies[agents[0]].set_eps(training_eps)\n",
    "        policy.policies[agents[1]].set_eps(training_eps)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        \"\"\"\n",
    "        Callback beore testing, sets the testing epsilon.\n",
    "        \"\"\"        \n",
    "        # Before testing we want to configure the epsilon for the agents\n",
    "        # In general more greedy than the train case but not\n",
    "        #   to avoid getting stuck on invalid moves\n",
    "        policy.policies[agents[0]].set_eps(testing_eps)\n",
    "        policy.policies[agents[1]].set_eps(testing_eps)\n",
    "\n",
    "    def reward_metric(rews):\n",
    "        \"\"\"\n",
    "        Callback for reward collection.\n",
    "        Currently the reward is the sum of both agents.\n",
    "        \"\"\"        \n",
    "        # We are interested in having a high total total reward,\n",
    "        #   as this would mean equally good agents.\n",
    "        return rews[:, 0] + rews[:, 1]\n",
    "\n",
    "    # ======== Training =========\n",
    "    # off policy training\n",
    "    result = ts.trainer.offpolicy_trainer(policy= policy,\n",
    "                                          train_collector= train_collector,\n",
    "                                          test_collector= test_collector,\n",
    "                                          max_epoch= epochs,\n",
    "                                          step_per_epoch= step_per_epoch,\n",
    "                                          step_per_collect= step_per_collect,\n",
    "                                          episode_per_test= testing_env_num,\n",
    "                                          batch_size= batch_size,\n",
    "                                          train_fn= train_fn,\n",
    "                                          test_fn= test_fn,\n",
    "                                          stop_fn= stop_fn,\n",
    "                                          save_best_fn= save_best_fn,\n",
    "                                          update_per_step= update_per_step,\n",
    "                                          logger= logger,\n",
    "                                          test_in_train= False,\n",
    "                                          reward_metric= reward_metric)\n",
    "    \n",
    "    # Save final agent 1\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent1.pth')\n",
    "    torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "\n",
    "    # Save final agent 2\n",
    "    model_save_path = os.path.join('./saved_variables', 'paper_notebooks', notebook_version, filename, 'final_policy_agent2.pth')\n",
    "    torch.save(policy.policies[agents[1]].state_dict(), model_save_path)\n",
    "\n",
    "    return result, policy.policies[agents[0]], policy.policies[agents[1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161cc0f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Function for watching learned agent\n",
    "\n",
    "Identical to the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b526e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# WATCHING THE LEARNED POLICY IN ACTION\n",
    "####################################################\n",
    "\n",
    "def watch(numer_of_games: int = 3,\n",
    "          agent_player1: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          agent_player2: typing.Optional[ts.policy.BasePolicy] = None,\n",
    "          test_epsilon: float = 0.005, # For the watching we act completely greedy but low random for not getting stuck on invalid move\n",
    "          render_speed: float = 0.15, # Amount of seconds to update frame/ do a step\n",
    "          ) -> None:\n",
    "    \n",
    "    # Get the connect four V2 environment (must be a list)\n",
    "    env= ts.env.DummyVectorEnv([get_env])\n",
    "    \n",
    "    # Get the agents from the trained agents\n",
    "    policy, optim, agents = get_agent_manager(agent_player1= agent_player1,\n",
    "                                              agent_player2= agent_player2)\n",
    "    \n",
    "    # Evaluate the policy\n",
    "    policy.eval()\n",
    "    \n",
    "    # Set the testing policy epsilon for our agents\n",
    "    policy.policies[agents[0]].set_eps(test_epsilon)\n",
    "    policy.policies[agents[1]].set_eps(test_epsilon)\n",
    "    \n",
    "    # Collect the test data\n",
    "    collector = ts.data.Collector(policy= policy,\n",
    "                                  env= env,\n",
    "                                  exploration_noise= True)\n",
    "    \n",
    "    # Render games in human mode to see how it plays\n",
    "    result = collector.collect(n_episode= numer_of_games, render= render_speed)\n",
    "    \n",
    "    # Close the environment aftering collecting the results\n",
    "    # This closes the pygame window after completion\n",
    "    env.close()\n",
    "    \n",
    "    # Get the rewards and length from the test trials\n",
    "    rewards, length = result[\"rews\"], result[\"lens\"]\n",
    "    \n",
    "    # Print the final reward for the first agent\n",
    "    print(f\"Average steps of game:  {length.mean()}\")\n",
    "    print(f\"Final mean reward agent 1: {rewards[:, 0].mean()}, std: {rewards[:, 0].std()}\")\n",
    "    print(f\"Final mean reward agent 2: {rewards[:, 1].mean()}, std: {rewards[:, 1].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31784e9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Doing the experiment\n",
    "\n",
    "We now do the experiment with using our previously created functions.\n",
    "We update some parameter settings to find if we can improve our DQN agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925f85a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 10001it [00:33, 297.46it/s, env_step=10000, len=18, n/ep=0, n/st=10, player_1/loss=2.964, player_2/loss=2.957, rew=6.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 10001it [00:33, 294.67it/s, env_step=20000, len=22, n/ep=0, n/st=10, player_1/loss=2.487, player_2/loss=2.562, rew=5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 10001it [00:34, 290.71it/s, env_step=30000, len=19, n/ep=1, n/st=10, player_1/loss=2.252, player_2/loss=2.364, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 10001it [00:32, 303.15it/s, env_step=40000, len=7, n/ep=0, n/st=10, player_1/loss=2.064, player_2/loss=2.341, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 10001it [00:33, 302.38it/s, env_step=50000, len=31, n/ep=0, n/st=10, player_1/loss=2.073, player_2/loss=2.368, rew=37.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 10001it [00:33, 296.87it/s, env_step=60000, len=16, n/ep=0, n/st=10, player_1/loss=2.081, player_2/loss=2.330, rew=6.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 10001it [00:33, 297.38it/s, env_step=70000, len=19, n/ep=1, n/st=10, player_1/loss=2.074, player_2/loss=2.352, rew=17.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 0.000000 ± 0.000000, best_reward: 0.000000 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 10001it [00:33, 298.89it/s, env_step=80000, len=25, n/ep=0, n/st=10, player_1/loss=2.034, player_2/loss=2.340, rew=5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 5.600000 ± 4.800000, best_reward: 5.600000 ± 4.800000 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 10001it [00:33, 295.41it/s, env_step=90000, len=22, n/ep=1, n/st=10, player_1/loss=1.989, player_2/loss=2.303, rew=17.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 25.100000 ± 11.819052, best_reward: 25.100000 ± 11.819052 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 10001it [00:34, 294.12it/s, env_step=100000, len=10, n/ep=0, n/st=10, player_1/loss=2.031, player_2/loss=2.349, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 0.800000 ± 1.600000, best_reward: 25.100000 ± 11.819052 in #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 10001it [00:34, 290.02it/s, env_step=110000, len=19, n/ep=0, n/st=10, player_1/loss=2.047, player_2/loss=2.360, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 28.400000 ± 4.800000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 10001it [00:33, 301.30it/s, env_step=120000, len=10, n/ep=0, n/st=10, player_1/loss=2.098, player_2/loss=2.365, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 0.600000 ± 1.800000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 10001it [00:33, 299.69it/s, env_step=130000, len=14, n/ep=0, n/st=10, player_1/loss=2.068, player_2/loss=2.330, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 18.000000 ± 0.000000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 10001it [00:33, 299.41it/s, env_step=140000, len=9, n/ep=1, n/st=10, player_1/loss=2.049, player_2/loss=2.321, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 25.500000 ± 8.686196, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 10001it [00:32, 303.63it/s, env_step=150000, len=19, n/ep=0, n/st=10, player_1/loss=2.019, player_2/loss=2.376, rew=7.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 16.300000 ± 14.940214, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 10001it [00:32, 303.53it/s, env_step=160000, len=18, n/ep=0, n/st=10, player_1/loss=2.036, player_2/loss=2.338, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 18.900000 ± 6.300000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 10001it [00:32, 303.57it/s, env_step=170000, len=9, n/ep=1, n/st=10, player_1/loss=2.077, player_2/loss=2.373, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 3.100000 ± 1.577973, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 10001it [00:32, 303.32it/s, env_step=180000, len=14, n/ep=0, n/st=10, player_1/loss=2.086, player_2/loss=2.391, rew=6.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 3.000000 ± 0.000000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 10001it [00:32, 303.55it/s, env_step=190000, len=27, n/ep=0, n/st=10, player_1/loss=2.078, player_2/loss=2.376, rew=32.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 7.000000 ± 0.000000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 10001it [00:32, 303.88it/s, env_step=200000, len=14, n/ep=1, n/st=10, player_1/loss=2.124, player_2/loss=2.365, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 0.000000 ± 0.000000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #21: 10001it [00:33, 301.36it/s, env_step=210000, len=17, n/ep=0, n/st=10, player_1/loss=2.106, player_2/loss=2.402, rew=7.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #21: test_reward: 0.000000 ± 0.000000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #22: 10001it [00:32, 304.15it/s, env_step=220000, len=30, n/ep=1, n/st=10, player_1/loss=2.095, player_2/loss=2.387, rew=42.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #22: test_reward: 1.800000 ± 0.600000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #23: 10001it [00:32, 303.21it/s, env_step=230000, len=25, n/ep=1, n/st=10, player_1/loss=2.060, player_2/loss=2.393, rew=17.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #23: test_reward: 2.100000 ± 6.300000, best_reward: 28.400000 ± 4.800000 in #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #24: 10001it [00:32, 303.99it/s, env_step=240000, len=20, n/ep=1, n/st=10, player_1/loss=2.071, player_2/loss=2.360, rew=4.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #24: test_reward: 39.400000 ± 2.154066, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #25: 10001it [00:32, 303.40it/s, env_step=250000, len=15, n/ep=0, n/st=10, player_1/loss=2.137, player_2/loss=2.357, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #25: test_reward: 29.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #26: 10001it [00:32, 303.80it/s, env_step=260000, len=18, n/ep=0, n/st=10, player_1/loss=2.221, player_2/loss=2.428, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #26: test_reward: 17.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #27: 10001it [00:32, 304.06it/s, env_step=270000, len=20, n/ep=1, n/st=10, player_1/loss=2.102, player_2/loss=2.367, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #27: test_reward: 6.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #28: 10001it [00:32, 304.26it/s, env_step=280000, len=17, n/ep=0, n/st=10, player_1/loss=2.088, player_2/loss=2.355, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #28: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #29: 10001it [00:32, 303.11it/s, env_step=290000, len=20, n/ep=0, n/st=10, player_1/loss=2.100, player_2/loss=2.387, rew=11.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #29: test_reward: 23.400000 ± 7.800000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #30: 10001it [00:32, 303.36it/s, env_step=300000, len=30, n/ep=2, n/st=10, player_1/loss=2.091, player_2/loss=2.424, rew=61.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #30: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #31: 10001it [00:32, 304.19it/s, env_step=310000, len=7, n/ep=0, n/st=10, player_1/loss=2.091, player_2/loss=2.380, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #31: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #32: 10001it [00:32, 303.18it/s, env_step=320000, len=24, n/ep=1, n/st=10, player_1/loss=2.111, player_2/loss=2.427, rew=3.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #32: test_reward: 6.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #33: 10001it [00:32, 303.75it/s, env_step=330000, len=20, n/ep=1, n/st=10, player_1/loss=2.101, player_2/loss=2.442, rew=12.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #33: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #34: 10001it [00:32, 303.81it/s, env_step=340000, len=16, n/ep=0, n/st=10, player_1/loss=2.090, player_2/loss=2.398, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #34: test_reward: 32.500000 ± 1.500000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #35: 10001it [00:32, 303.62it/s, env_step=350000, len=21, n/ep=0, n/st=10, player_1/loss=2.080, player_2/loss=2.385, rew=15.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #36: 10001it [00:33, 302.96it/s, env_step=360000, len=23, n/ep=0, n/st=10, player_1/loss=2.064, player_2/loss=2.431, rew=13.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #36: test_reward: 25.400000 ± 14.800000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #37: 10001it [00:33, 303.01it/s, env_step=370000, len=18, n/ep=0, n/st=10, player_1/loss=2.074, player_2/loss=2.422, rew=17.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #37: test_reward: 1.800000 ± 0.600000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #38: 10001it [00:33, 302.75it/s, env_step=380000, len=22, n/ep=2, n/st=10, player_1/loss=2.076, player_2/loss=2.400, rew=23.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #38: test_reward: 9.800000 ± 0.600000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #39: 10001it [00:32, 303.21it/s, env_step=390000, len=26, n/ep=0, n/st=10, player_1/loss=2.063, player_2/loss=2.396, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #39: test_reward: 4.800000 ± 0.600000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #40: 10001it [00:33, 302.48it/s, env_step=400000, len=26, n/ep=0, n/st=10, player_1/loss=2.082, player_2/loss=2.413, rew=11.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40: test_reward: 17.000000 ± 6.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #41: 10001it [00:32, 303.14it/s, env_step=410000, len=21, n/ep=0, n/st=10, player_1/loss=2.064, player_2/loss=2.407, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #41: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #42: 10001it [00:32, 303.21it/s, env_step=420000, len=23, n/ep=1, n/st=10, player_1/loss=2.022, player_2/loss=2.373, rew=18.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #42: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #43: 10001it [00:32, 303.36it/s, env_step=430000, len=8, n/ep=0, n/st=10, player_1/loss=2.073, player_2/loss=2.360, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #43: test_reward: 4.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #44: 10001it [00:32, 303.37it/s, env_step=440000, len=20, n/ep=0, n/st=10, player_1/loss=2.089, player_2/loss=2.449, rew=33.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #44: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #45: 10001it [00:32, 303.62it/s, env_step=450000, len=21, n/ep=0, n/st=10, player_1/loss=2.132, player_2/loss=2.457, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #45: test_reward: 0.000000 ± 0.000000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #46: 10001it [00:33, 302.79it/s, env_step=460000, len=36, n/ep=0, n/st=10, player_1/loss=2.094, player_2/loss=2.423, rew=53.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #46: test_reward: 21.600000 ± 7.200000, best_reward: 39.400000 ± 2.154066 in #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #47: 10001it [00:33, 302.29it/s, env_step=470000, len=19, n/ep=0, n/st=10, player_1/loss=2.039, player_2/loss=2.397, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #47: test_reward: 72.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #48: 10001it [00:33, 302.10it/s, env_step=480000, len=19, n/ep=0, n/st=10, player_1/loss=2.077, player_2/loss=2.477, rew=6.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #48: test_reward: 27.400000 ± 7.200000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #49: 10001it [00:32, 303.90it/s, env_step=490000, len=16, n/ep=1, n/st=10, player_1/loss=1.976, player_2/loss=2.407, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #49: test_reward: 1.800000 ± 0.600000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #50: 10001it [00:32, 303.25it/s, env_step=500000, len=17, n/ep=1, n/st=10, player_1/loss=2.008, player_2/loss=2.420, rew=10.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50: test_reward: 10.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #51: 10001it [00:32, 303.89it/s, env_step=510000, len=27, n/ep=1, n/st=10, player_1/loss=1.961, player_2/loss=2.426, rew=3.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #51: test_reward: 0.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #52: 10001it [00:32, 303.40it/s, env_step=520000, len=9, n/ep=1, n/st=10, player_1/loss=1.959, player_2/loss=2.392, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #52: test_reward: 19.900000 ± 4.346263, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #53: 10001it [00:32, 303.73it/s, env_step=530000, len=7, n/ep=0, n/st=10, player_1/loss=1.995, player_2/loss=2.412, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #53: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #54: 10001it [00:32, 303.44it/s, env_step=540000, len=15, n/ep=0, n/st=10, player_1/loss=1.987, player_2/loss=2.378, rew=8.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #54: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #55: 10001it [00:32, 304.06it/s, env_step=550000, len=27, n/ep=0, n/st=10, player_1/loss=1.954, player_2/loss=2.411, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #55: test_reward: 42.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #56: 10001it [00:32, 303.78it/s, env_step=560000, len=17, n/ep=0, n/st=10, player_1/loss=1.912, player_2/loss=2.403, rew=8.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #56: test_reward: 45.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #57: 10001it [00:33, 302.64it/s, env_step=570000, len=17, n/ep=0, n/st=10, player_1/loss=1.940, player_2/loss=2.435, rew=8.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #57: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #58: 10001it [00:33, 302.75it/s, env_step=580000, len=15, n/ep=0, n/st=10, player_1/loss=1.968, player_2/loss=2.437, rew=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #58: test_reward: 41.700000 ± 6.034070, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #59: 10001it [00:33, 302.72it/s, env_step=590000, len=10, n/ep=1, n/st=10, player_1/loss=1.919, player_2/loss=2.406, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #59: test_reward: 31.400000 ± 2.800000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #60: 10001it [00:33, 302.34it/s, env_step=600000, len=23, n/ep=0, n/st=10, player_1/loss=1.871, player_2/loss=2.363, rew=12.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #60: test_reward: 16.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #61: 10001it [00:33, 302.25it/s, env_step=610000, len=26, n/ep=0, n/st=10, player_1/loss=1.829, player_2/loss=2.395, rew=20.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #61: test_reward: 33.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #62: 10001it [00:33, 302.17it/s, env_step=620000, len=9, n/ep=0, n/st=10, player_1/loss=1.862, player_2/loss=2.385, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #62: test_reward: 18.200000 ± 5.400000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #63: 10001it [00:33, 301.36it/s, env_step=630000, len=7, n/ep=2, n/st=10, player_1/loss=1.823, player_2/loss=2.377, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #63: test_reward: 2.400000 ± 1.200000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #64: 10001it [00:33, 302.34it/s, env_step=640000, len=33, n/ep=1, n/st=10, player_1/loss=1.877, player_2/loss=2.361, rew=80.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #64: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #65: 10001it [00:33, 300.48it/s, env_step=650000, len=19, n/ep=1, n/st=10, player_1/loss=1.910, player_2/loss=2.340, rew=16.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #65: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #66: 10001it [00:33, 300.90it/s, env_step=660000, len=12, n/ep=0, n/st=10, player_1/loss=1.885, player_2/loss=2.328, rew=5.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #66: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #67: 10001it [00:33, 300.80it/s, env_step=670000, len=19, n/ep=0, n/st=10, player_1/loss=1.812, player_2/loss=2.323, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #67: test_reward: 33.500000 ± 10.500000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #68: 10001it [00:33, 296.75it/s, env_step=680000, len=15, n/ep=0, n/st=10, player_1/loss=1.839, player_2/loss=2.328, rew=12.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #68: test_reward: 2.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #69: 10001it [00:34, 290.38it/s, env_step=690000, len=16, n/ep=0, n/st=10, player_1/loss=1.877, player_2/loss=2.276, rew=7.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #69: test_reward: 32.700000 ± 10.507616, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #70: 10001it [00:33, 296.85it/s, env_step=700000, len=13, n/ep=0, n/st=10, player_1/loss=1.842, player_2/loss=2.281, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #70: test_reward: 45.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #71: 10001it [00:33, 298.94it/s, env_step=710000, len=9, n/ep=1, n/st=10, player_1/loss=1.784, player_2/loss=2.304, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #71: test_reward: 37.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #72: 10001it [00:33, 299.88it/s, env_step=720000, len=19, n/ep=0, n/st=10, player_1/loss=1.828, player_2/loss=2.308, rew=28.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #72: test_reward: 25.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #73: 10001it [00:34, 287.36it/s, env_step=730000, len=7, n/ep=0, n/st=10, player_1/loss=1.859, player_2/loss=2.232, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #73: test_reward: 33.300000 ± 11.100000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #74: 10001it [00:33, 301.87it/s, env_step=740000, len=28, n/ep=0, n/st=10, player_1/loss=1.842, player_2/loss=2.287, rew=3.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #74: test_reward: 32.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #75: 10001it [00:33, 294.81it/s, env_step=750000, len=16, n/ep=0, n/st=10, player_1/loss=1.863, player_2/loss=2.200, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #75: test_reward: 30.600000 ± 1.800000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #76: 10001it [00:33, 299.10it/s, env_step=760000, len=24, n/ep=1, n/st=10, player_1/loss=1.816, player_2/loss=2.181, rew=19.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #76: test_reward: 1.800000 ± 0.600000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #77: 10001it [00:33, 299.94it/s, env_step=770000, len=18, n/ep=0, n/st=10, player_1/loss=1.810, player_2/loss=2.212, rew=17.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #77: test_reward: 33.700000 ± 11.296460, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #78: 10001it [00:33, 299.87it/s, env_step=780000, len=7, n/ep=1, n/st=10, player_1/loss=1.763, player_2/loss=2.184, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #78: test_reward: 31.500000 ± 11.791946, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #79: 10001it [00:33, 300.61it/s, env_step=790000, len=23, n/ep=0, n/st=10, player_1/loss=1.708, player_2/loss=2.189, rew=42.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #79: test_reward: 19.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #80: 10001it [00:33, 299.07it/s, env_step=800000, len=23, n/ep=1, n/st=10, player_1/loss=1.696, player_2/loss=2.088, rew=35.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #80: test_reward: 28.500000 ± 1.500000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #81: 10001it [00:33, 300.59it/s, env_step=810000, len=7, n/ep=0, n/st=10, player_1/loss=1.707, player_2/loss=2.124, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #81: test_reward: 31.200000 ± 6.600000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #82: 10001it [00:33, 299.55it/s, env_step=820000, len=17, n/ep=0, n/st=10, player_1/loss=1.736, player_2/loss=2.117, rew=22.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #82: test_reward: 43.600000 ± 9.340236, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #83: 10001it [00:33, 299.85it/s, env_step=830000, len=19, n/ep=0, n/st=10, player_1/loss=1.749, player_2/loss=2.026, rew=15.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #83: test_reward: 13.000000 ± 0.000000, best_reward: 72.000000 ± 0.000000 in #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #84: 10001it [00:33, 295.88it/s, env_step=840000, len=7, n/ep=1, n/st=10, player_1/loss=1.664, player_2/loss=2.004, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #84: test_reward: 77.000000 ± 0.000000, best_reward: 77.000000 ± 0.000000 in #84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #85: 10001it [00:33, 298.37it/s, env_step=850000, len=17, n/ep=1, n/st=10, player_1/loss=1.705, player_2/loss=1.965, rew=12.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #85: test_reward: 24.200000 ± 0.600000, best_reward: 77.000000 ± 0.000000 in #84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #86: 10001it [00:33, 299.04it/s, env_step=860000, len=25, n/ep=1, n/st=10, player_1/loss=1.693, player_2/loss=1.992, rew=53.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #86: test_reward: 109.100000 ± 20.873189, best_reward: 109.100000 ± 20.873189 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #87: 10001it [00:33, 299.06it/s, env_step=870000, len=23, n/ep=0, n/st=10, player_1/loss=1.676, player_2/loss=2.011, rew=43.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #87: test_reward: 2.000000 ± 0.000000, best_reward: 109.100000 ± 20.873189 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #88: 10001it [00:33, 299.72it/s, env_step=880000, len=27, n/ep=0, n/st=10, player_1/loss=1.645, player_2/loss=1.897, rew=73.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #88: test_reward: 36.100000 ± 12.397177, best_reward: 109.100000 ± 20.873189 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #89: 10001it [00:33, 301.12it/s, env_step=890000, len=21, n/ep=0, n/st=10, player_1/loss=1.665, player_2/loss=1.699, rew=34.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #89: test_reward: 21.800000 ± 6.600000, best_reward: 109.100000 ± 20.873189 in #86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #90: 10001it [00:32, 305.03it/s, env_step=900000, len=32, n/ep=1, n/st=10, player_1/loss=1.581, player_2/loss=1.710, rew=148.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #90: test_reward: 129.200000 ± 31.412736, best_reward: 129.200000 ± 31.412736 in #90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #91: 10001it [00:33, 301.67it/s, env_step=910000, len=13, n/ep=0, n/st=10, player_1/loss=1.533, player_2/loss=1.823, rew=8.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #91: test_reward: 2.000000 ± 0.000000, best_reward: 129.200000 ± 31.412736 in #90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #92: 10001it [00:33, 301.79it/s, env_step=920000, len=19, n/ep=2, n/st=10, player_1/loss=1.551, player_2/loss=1.850, rew=33.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #92: test_reward: 42.000000 ± 0.000000, best_reward: 129.200000 ± 31.412736 in #90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #93: 10001it [00:34, 287.08it/s, env_step=930000, len=19, n/ep=1, n/st=10, player_1/loss=1.495, player_2/loss=1.495, rew=35.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #93: test_reward: 198.500000 ± 49.500000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #94: 10001it [00:33, 297.80it/s, env_step=940000, len=7, n/ep=0, n/st=10, player_1/loss=1.421, player_2/loss=1.295, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #94: test_reward: 129.700000 ± 6.900000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #95: 10001it [00:35, 283.44it/s, env_step=950000, len=13, n/ep=0, n/st=10, player_1/loss=1.394, player_2/loss=1.188, rew=18.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #95: test_reward: 196.400000 ± 55.800000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #96: 10001it [00:40, 249.72it/s, env_step=960000, len=25, n/ep=0, n/st=10, player_1/loss=1.269, player_2/loss=1.168, rew=100.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #96: test_reward: 189.300000 ± 50.100000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #97: 10001it [00:51, 192.39it/s, env_step=970000, len=18, n/ep=0, n/st=10, player_1/loss=1.182, player_2/loss=1.167, rew=36.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #97: test_reward: 2.000000 ± 0.000000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #98: 10001it [00:51, 194.06it/s, env_step=980000, len=16, n/ep=2, n/st=10, player_1/loss=1.165, player_2/loss=1.175, rew=11.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #98: test_reward: 11.000000 ± 27.000000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #99: 10001it [00:50, 199.64it/s, env_step=990000, len=7, n/ep=1, n/st=10, player_1/loss=1.146, player_2/loss=1.555, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #99: test_reward: 2.000000 ± 0.000000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #100: 10001it [00:52, 191.49it/s, env_step=1000000, len=9, n/ep=0, n/st=10, player_1/loss=1.466, player_2/loss=1.597, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #100: test_reward: 35.000000 ± 0.000000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #101: 10001it [00:55, 180.26it/s, env_step=1010000, len=39, n/ep=0, n/st=10, player_1/loss=1.031, player_2/loss=0.876, rew=236.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #101: test_reward: 179.000000 ± 0.000000, best_reward: 198.500000 ± 49.500000 in #93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #102: 10001it [00:53, 187.19it/s, env_step=1020000, len=24, n/ep=0, n/st=10, player_1/loss=0.975, player_2/loss=0.883, rew=90.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #102: test_reward: 202.000000 ± 0.000000, best_reward: 202.000000 ± 0.000000 in #102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #103: 10001it [00:48, 207.97it/s, env_step=1030000, len=27, n/ep=0, n/st=10, player_1/loss=1.088, player_2/loss=1.250, rew=117.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #103: test_reward: 179.800000 ± 0.600000, best_reward: 202.000000 ± 0.000000 in #102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #104: 10001it [00:45, 221.93it/s, env_step=1040000, len=35, n/ep=0, n/st=10, player_1/loss=0.993, player_2/loss=0.830, rew=209.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #104: test_reward: 210.900000 ± 12.300000, best_reward: 210.900000 ± 12.300000 in #104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #105: 10001it [00:50, 196.62it/s, env_step=1050000, len=37, n/ep=0, n/st=10, player_1/loss=0.976, player_2/loss=0.719, rew=245.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #105: test_reward: 53.000000 ± 0.000000, best_reward: 210.900000 ± 12.300000 in #104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #106: 10001it [00:47, 209.77it/s, env_step=1060000, len=7, n/ep=1, n/st=10, player_1/loss=0.964, player_2/loss=1.038, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #106: test_reward: 127.600000 ± 57.353640, best_reward: 210.900000 ± 12.300000 in #104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #107: 10001it [00:48, 204.30it/s, env_step=1070000, len=33, n/ep=0, n/st=10, player_1/loss=1.028, player_2/loss=0.986, rew=182.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #107: test_reward: 225.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #108: 10001it [00:51, 192.33it/s, env_step=1080000, len=13, n/ep=0, n/st=10, player_1/loss=0.963, player_2/loss=0.884, rew=8.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #108: test_reward: 177.300000 ± 56.444752, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #109: 10001it [00:50, 196.71it/s, env_step=1090000, len=34, n/ep=0, n/st=10, player_1/loss=1.027, player_2/loss=0.852, rew=169.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #109: test_reward: 210.100000 ± 33.137441, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #110: 10001it [00:50, 198.51it/s, env_step=1100000, len=13, n/ep=1, n/st=10, player_1/loss=0.992, player_2/loss=0.767, rew=7.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #110: test_reward: 7.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #111: 10001it [00:52, 188.85it/s, env_step=1110000, len=19, n/ep=0, n/st=10, player_1/loss=1.063, player_2/loss=0.775, rew=37.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #111: test_reward: 154.900000 ± 75.764702, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #112: 10001it [00:50, 198.78it/s, env_step=1120000, len=17, n/ep=0, n/st=10, player_1/loss=0.943, player_2/loss=0.771, rew=31.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #112: test_reward: 221.300000 ± 5.100000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #113: 10001it [00:47, 210.69it/s, env_step=1130000, len=18, n/ep=0, n/st=10, player_1/loss=1.239, player_2/loss=1.186, rew=19.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #113: test_reward: 201.900000 ± 63.300000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #114: 10001it [00:51, 195.95it/s, env_step=1140000, len=8, n/ep=0, n/st=10, player_1/loss=1.244, player_2/loss=0.976, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #114: test_reward: 109.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #115: 10001it [00:52, 190.94it/s, env_step=1150000, len=7, n/ep=1, n/st=10, player_1/loss=1.252, player_2/loss=0.947, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #115: test_reward: 189.800000 ± 0.600000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #116: 10001it [00:47, 211.53it/s, env_step=1160000, len=21, n/ep=0, n/st=10, player_1/loss=1.228, player_2/loss=0.918, rew=51.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #116: test_reward: 178.400000 ± 67.201488, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #117: 10001it [00:55, 179.30it/s, env_step=1170000, len=35, n/ep=0, n/st=10, player_1/loss=1.053, player_2/loss=0.948, rew=162.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #117: test_reward: 215.100000 ± 17.700000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #118: 10001it [00:49, 202.29it/s, env_step=1180000, len=24, n/ep=0, n/st=10, player_1/loss=0.984, player_2/loss=0.818, rew=89.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #118: test_reward: 145.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #119: 10001it [01:03, 156.67it/s, env_step=1190000, len=19, n/ep=0, n/st=10, player_1/loss=1.219, player_2/loss=1.087, rew=37.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #119: test_reward: 42.400000 ± 1.800000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #120: 10001it [00:50, 196.13it/s, env_step=1200000, len=27, n/ep=0, n/st=10, player_1/loss=1.258, player_2/loss=0.976, rew=88.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #120: test_reward: 105.000000 ± 44.335088, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #121: 10001it [00:51, 194.96it/s, env_step=1210000, len=29, n/ep=1, n/st=10, player_1/loss=1.183, player_2/loss=0.990, rew=111.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #121: test_reward: 141.800000 ± 69.423051, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #122: 10001it [00:40, 244.55it/s, env_step=1220000, len=39, n/ep=0, n/st=10, player_1/loss=1.355, player_2/loss=1.248, rew=227.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #122: test_reward: 128.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #123: 10001it [00:35, 281.88it/s, env_step=1230000, len=7, n/ep=0, n/st=10, player_1/loss=1.125, player_2/loss=0.896, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #123: test_reward: 189.400000 ± 62.678864, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #124: 10001it [00:35, 280.47it/s, env_step=1240000, len=19, n/ep=1, n/st=10, player_1/loss=1.113, player_2/loss=0.845, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #124: test_reward: 163.000000 ± 9.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #125: 10001it [00:35, 281.68it/s, env_step=1250000, len=26, n/ep=0, n/st=10, player_1/loss=1.200, player_2/loss=0.943, rew=95.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #125: test_reward: 142.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #126: 10001it [00:35, 283.85it/s, env_step=1260000, len=36, n/ep=0, n/st=10, player_1/loss=1.265, player_2/loss=1.306, rew=127.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #126: test_reward: 134.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #127: 10001it [00:35, 285.13it/s, env_step=1270000, len=24, n/ep=0, n/st=10, player_1/loss=1.089, player_2/loss=0.873, rew=83.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #127: test_reward: 15.400000 ± 10.200000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #128: 10001it [00:35, 285.64it/s, env_step=1280000, len=13, n/ep=0, n/st=10, player_1/loss=0.988, player_2/loss=0.888, rew=7.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #128: test_reward: 46.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #129: 10001it [00:35, 278.10it/s, env_step=1290000, len=7, n/ep=1, n/st=10, player_1/loss=1.078, player_2/loss=1.078, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #129: test_reward: 33.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #130: 10001it [00:34, 287.02it/s, env_step=1300000, len=36, n/ep=0, n/st=10, player_1/loss=1.057, player_2/loss=1.052, rew=198.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #130: test_reward: 173.900000 ± 24.283534, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #131: 10001it [00:35, 283.90it/s, env_step=1310000, len=17, n/ep=1, n/st=10, player_1/loss=1.112, player_2/loss=1.180, rew=31.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #131: test_reward: 185.300000 ± 41.100000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #132: 10001it [00:35, 282.77it/s, env_step=1320000, len=14, n/ep=0, n/st=10, player_1/loss=1.064, player_2/loss=1.025, rew=18.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #132: test_reward: 31.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #133: 10001it [00:34, 287.36it/s, env_step=1330000, len=33, n/ep=0, n/st=10, player_1/loss=1.203, player_2/loss=0.876, rew=184.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #133: test_reward: 33.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #134: 10001it [00:34, 286.55it/s, env_step=1340000, len=27, n/ep=0, n/st=10, player_1/loss=1.210, player_2/loss=0.976, rew=88.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #134: test_reward: 1.500000 ± 4.500000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #135: 10001it [00:35, 285.51it/s, env_step=1350000, len=21, n/ep=0, n/st=10, player_1/loss=1.124, player_2/loss=0.920, rew=58.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #135: test_reward: 173.600000 ± 34.699280, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #136: 10001it [00:34, 286.25it/s, env_step=1360000, len=39, n/ep=1, n/st=10, player_1/loss=1.021, player_2/loss=0.866, rew=206.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #136: test_reward: 192.000000 ± 36.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #137: 10001it [00:35, 284.89it/s, env_step=1370000, len=19, n/ep=0, n/st=10, player_1/loss=1.005, player_2/loss=0.815, rew=15.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #137: test_reward: 206.200000 ± 17.400000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #138: 10001it [00:35, 285.47it/s, env_step=1380000, len=29, n/ep=0, n/st=10, player_1/loss=1.003, player_2/loss=0.936, rew=83.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #138: test_reward: 40.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #139: 10001it [00:35, 283.53it/s, env_step=1390000, len=33, n/ep=0, n/st=10, player_1/loss=1.065, player_2/loss=0.939, rew=131.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #139: test_reward: 125.000000 ± 32.619013, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #140: 10001it [00:35, 284.54it/s, env_step=1400000, len=7, n/ep=1, n/st=10, player_1/loss=1.053, player_2/loss=0.809, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #140: test_reward: 135.300000 ± 65.915173, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #141: 10001it [00:36, 275.86it/s, env_step=1410000, len=37, n/ep=0, n/st=10, player_1/loss=1.050, player_2/loss=0.927, rew=179.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #141: test_reward: 0.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #142: 10001it [00:35, 284.23it/s, env_step=1420000, len=21, n/ep=1, n/st=10, player_1/loss=1.041, player_2/loss=0.862, rew=29.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #142: test_reward: 166.700000 ± 74.964058, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #143: 10001it [00:35, 284.21it/s, env_step=1430000, len=25, n/ep=0, n/st=10, player_1/loss=1.251, player_2/loss=1.215, rew=49.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #143: test_reward: 10.000000 ± 0.000000, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #144: 10001it [00:35, 283.95it/s, env_step=1440000, len=39, n/ep=1, n/st=10, player_1/loss=1.164, player_2/loss=0.972, rew=188.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #144: test_reward: 193.600000 ± 5.969925, best_reward: 225.000000 ± 0.000000 in #107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #145: 10001it [00:35, 279.09it/s, env_step=1450000, len=19, n/ep=1, n/st=10, player_1/loss=0.964, player_2/loss=0.709, rew=43.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #145: test_reward: 241.300000 ± 11.100000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #146: 10001it [00:35, 282.49it/s, env_step=1460000, len=39, n/ep=0, n/st=10, player_1/loss=0.918, player_2/loss=0.738, rew=245.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #146: test_reward: 222.800000 ± 66.600000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #147: 10001it [00:33, 302.36it/s, env_step=1470000, len=31, n/ep=0, n/st=10, player_1/loss=0.899, player_2/loss=0.691, rew=114.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #147: test_reward: 185.800000 ± 61.775076, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #148: 10001it [00:33, 301.98it/s, env_step=1480000, len=37, n/ep=0, n/st=10, player_1/loss=1.006, player_2/loss=0.736, rew=179.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #148: test_reward: 217.500000 ± 7.003571, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #149: 10001it [00:35, 278.76it/s, env_step=1490000, len=27, n/ep=0, n/st=10, player_1/loss=1.482, player_2/loss=1.414, rew=82.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #149: test_reward: 185.900000 ± 65.235650, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #150: 10001it [00:34, 290.56it/s, env_step=1500000, len=18, n/ep=0, n/st=10, player_1/loss=1.337, player_2/loss=1.295, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #150: test_reward: 12.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #151: 10001it [00:35, 282.53it/s, env_step=1510000, len=35, n/ep=1, n/st=10, player_1/loss=1.071, player_2/loss=0.802, rew=182.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #151: test_reward: 168.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #152: 10001it [00:35, 279.84it/s, env_step=1520000, len=15, n/ep=0, n/st=10, player_1/loss=1.089, player_2/loss=0.930, rew=8.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #152: test_reward: 164.000000 ± 63.255039, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #153: 10001it [00:35, 281.57it/s, env_step=1530000, len=7, n/ep=0, n/st=10, player_1/loss=1.133, player_2/loss=1.479, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #153: test_reward: 21.700000 ± 59.100000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #154: 10001it [00:35, 284.00it/s, env_step=1540000, len=30, n/ep=1, n/st=10, player_1/loss=1.434, player_2/loss=1.634, rew=99.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #154: test_reward: 18.900000 ± 6.300000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #155: 10001it [00:35, 285.09it/s, env_step=1550000, len=7, n/ep=0, n/st=10, player_1/loss=1.133, player_2/loss=0.964, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #155: test_reward: 232.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #156: 10001it [00:37, 263.25it/s, env_step=1560000, len=29, n/ep=0, n/st=10, player_1/loss=0.911, player_2/loss=0.711, rew=55.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #156: test_reward: 202.400000 ± 7.200000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #157: 10001it [00:39, 253.09it/s, env_step=1570000, len=21, n/ep=1, n/st=10, player_1/loss=0.920, player_2/loss=0.735, rew=42.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #157: test_reward: 76.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #158: 10001it [00:40, 247.04it/s, env_step=1580000, len=35, n/ep=0, n/st=10, player_1/loss=1.105, player_2/loss=0.919, rew=141.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #158: test_reward: 207.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #159: 10001it [00:41, 239.50it/s, env_step=1590000, len=24, n/ep=0, n/st=10, player_1/loss=1.007, player_2/loss=0.962, rew=18.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #159: test_reward: 217.400000 ± 19.386593, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #160: 10001it [00:40, 248.80it/s, env_step=1600000, len=39, n/ep=0, n/st=10, player_1/loss=0.928, player_2/loss=0.761, rew=257.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #160: test_reward: 225.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #161: 10001it [00:41, 242.16it/s, env_step=1610000, len=23, n/ep=0, n/st=10, player_1/loss=1.107, player_2/loss=0.937, rew=58.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #161: test_reward: 7.900000 ± 23.700000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #162: 10001it [00:41, 240.40it/s, env_step=1620000, len=7, n/ep=1, n/st=10, player_1/loss=1.070, player_2/loss=1.030, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #162: test_reward: 2.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #163: 10001it [00:41, 243.87it/s, env_step=1630000, len=28, n/ep=0, n/st=10, player_1/loss=0.982, player_2/loss=0.933, rew=99.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #163: test_reward: 2.000000 ± 0.000000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #164: 10001it [00:37, 269.48it/s, env_step=1640000, len=17, n/ep=0, n/st=10, player_1/loss=1.428, player_2/loss=1.542, rew=22.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #164: test_reward: 20.900000 ± 4.392038, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #165: 10001it [00:38, 261.46it/s, env_step=1650000, len=31, n/ep=0, n/st=10, player_1/loss=1.401, player_2/loss=1.415, rew=133.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #165: test_reward: 154.200000 ± 36.600000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #166: 10001it [00:37, 264.80it/s, env_step=1660000, len=37, n/ep=0, n/st=10, player_1/loss=1.074, player_2/loss=1.010, rew=196.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #166: test_reward: 180.500000 ± 7.500000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #167: 10001it [00:37, 269.51it/s, env_step=1670000, len=25, n/ep=1, n/st=10, player_1/loss=1.106, player_2/loss=0.895, rew=64.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #167: test_reward: 115.100000 ± 29.183728, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #168: 10001it [00:40, 246.75it/s, env_step=1680000, len=17, n/ep=0, n/st=10, player_1/loss=1.082, player_2/loss=0.900, rew=21.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #168: test_reward: 166.500000 ± 55.500000, best_reward: 241.300000 ± 11.100000 in #145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #169: 10001it [00:47, 211.64it/s, env_step=1690000, len=39, n/ep=0, n/st=10, player_1/loss=1.170, player_2/loss=1.058, rew=189.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #169: test_reward: 259.000000 ± 0.000000, best_reward: 259.000000 ± 0.000000 in #169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #170: 10001it [00:47, 210.65it/s, env_step=1700000, len=19, n/ep=1, n/st=10, player_1/loss=1.097, player_2/loss=1.054, rew=37.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #170: test_reward: 31.000000 ± 0.000000, best_reward: 259.000000 ± 0.000000 in #169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #171: 10001it [00:46, 213.87it/s, env_step=1710000, len=35, n/ep=0, n/st=10, player_1/loss=0.940, player_2/loss=0.935, rew=176.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #171: test_reward: 267.700000 ± 15.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #172: 10001it [00:47, 211.73it/s, env_step=1720000, len=21, n/ep=0, n/st=10, player_1/loss=1.086, player_2/loss=0.883, rew=21.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #172: test_reward: 242.100000 ± 9.679359, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #173: 10001it [00:47, 211.58it/s, env_step=1730000, len=12, n/ep=2, n/st=10, player_1/loss=1.191, player_2/loss=1.141, rew=14.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #173: test_reward: 40.400000 ± 28.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #174: 10001it [00:45, 217.95it/s, env_step=1740000, len=7, n/ep=0, n/st=10, player_1/loss=1.260, player_2/loss=1.269, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #174: test_reward: 38.000000 ± 27.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #175: 10001it [00:46, 216.05it/s, env_step=1750000, len=9, n/ep=1, n/st=10, player_1/loss=1.228, player_2/loss=1.076, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #175: test_reward: 4.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #176: 10001it [00:46, 214.92it/s, env_step=1760000, len=7, n/ep=1, n/st=10, player_1/loss=1.303, player_2/loss=1.407, rew=2.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #176: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #177: 10001it [00:47, 211.95it/s, env_step=1770000, len=7, n/ep=0, n/st=10, player_1/loss=1.117, player_2/loss=1.423, rew=0.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #177: test_reward: 13.800000 ± 12.014991, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #178: 10001it [00:49, 203.34it/s, env_step=1780000, len=25, n/ep=0, n/st=10, player_1/loss=1.214, player_2/loss=1.332, rew=45.50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #178: test_reward: 100.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #179: 10001it [00:49, 203.14it/s, env_step=1790000, len=21, n/ep=0, n/st=10, player_1/loss=1.343, player_2/loss=1.102, rew=44.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #179: test_reward: 172.000000 ± 57.382924, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #180: 10001it [00:49, 202.78it/s, env_step=1800000, len=39, n/ep=0, n/st=10, player_1/loss=1.182, player_2/loss=0.895, rew=197.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #180: test_reward: 124.200000 ± 32.204969, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #181: 10001it [00:48, 205.21it/s, env_step=1810000, len=29, n/ep=0, n/st=10, player_1/loss=1.388, player_2/loss=1.068, rew=114.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #181: test_reward: 151.300000 ± 44.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #182: 10001it [00:47, 210.07it/s, env_step=1820000, len=35, n/ep=0, n/st=10, player_1/loss=1.424, player_2/loss=1.088, rew=146.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #182: test_reward: 162.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #183: 10001it [00:48, 205.16it/s, env_step=1830000, len=19, n/ep=0, n/st=10, player_1/loss=1.334, player_2/loss=0.978, rew=31.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #183: test_reward: 197.000000 ± 59.866518, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #184: 10001it [00:48, 205.89it/s, env_step=1840000, len=19, n/ep=0, n/st=10, player_1/loss=1.380, player_2/loss=1.037, rew=25.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #184: test_reward: 84.800000 ± 36.498767, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #185: 10001it [00:50, 198.83it/s, env_step=1850000, len=29, n/ep=1, n/st=10, player_1/loss=1.321, player_2/loss=1.141, rew=79.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #185: test_reward: 182.200000 ± 64.717540, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #186: 10001it [00:39, 255.51it/s, env_step=1860000, len=25, n/ep=2, n/st=10, player_1/loss=1.268, player_2/loss=1.173, rew=50.00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #186: test_reward: 8.700000 ± 13.928747, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #187: 10001it [00:37, 264.44it/s, env_step=1870000, len=17, n/ep=1, n/st=10, player_1/loss=1.401, player_2/loss=1.215, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #187: test_reward: 124.900000 ± 38.606865, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #188: 10001it [00:36, 271.98it/s, env_step=1880000, len=21, n/ep=1, n/st=10, player_1/loss=1.207, player_2/loss=1.025, rew=33.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #188: test_reward: 30.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #189: 10001it [00:35, 284.88it/s, env_step=1890000, len=33, n/ep=1, n/st=10, player_1/loss=1.018, player_2/loss=0.810, rew=139.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #189: test_reward: 229.700000 ± 0.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #190: 10001it [00:34, 288.40it/s, env_step=1900000, len=39, n/ep=0, n/st=10, player_1/loss=1.058, player_2/loss=0.893, rew=195.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #190: test_reward: 230.100000 ± 32.700000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #191: 10001it [00:34, 288.63it/s, env_step=1910000, len=17, n/ep=1, n/st=10, player_1/loss=1.018, player_2/loss=0.861, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #191: test_reward: 174.800000 ± 72.968212, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #192: 10001it [00:34, 288.51it/s, env_step=1920000, len=39, n/ep=0, n/st=10, player_1/loss=1.040, player_2/loss=0.946, rew=211.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #192: test_reward: 203.800000 ± 46.948482, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #193: 10001it [00:35, 283.20it/s, env_step=1930000, len=39, n/ep=0, n/st=10, player_1/loss=1.152, player_2/loss=1.092, rew=175.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #193: test_reward: 179.100000 ± 10.866922, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #194: 10001it [00:34, 289.31it/s, env_step=1940000, len=23, n/ep=0, n/st=10, player_1/loss=1.289, player_2/loss=1.058, rew=32.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #194: test_reward: 20.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #195: 10001it [00:34, 289.18it/s, env_step=1950000, len=42, n/ep=1, n/st=10, player_1/loss=1.446, player_2/loss=1.136, rew=247.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #195: test_reward: 18.200000 ± 5.400000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #196: 10001it [00:34, 289.25it/s, env_step=1960000, len=38, n/ep=1, n/st=10, player_1/loss=1.284, player_2/loss=1.109, rew=250.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #196: test_reward: 50.300000 ± 42.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #197: 10001it [00:34, 289.32it/s, env_step=1970000, len=29, n/ep=0, n/st=10, player_1/loss=1.512, player_2/loss=1.141, rew=101.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #197: test_reward: 41.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #198: 10001it [00:34, 289.14it/s, env_step=1980000, len=36, n/ep=0, n/st=10, player_1/loss=1.214, player_2/loss=0.787, rew=212.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #198: test_reward: 83.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #199: 10001it [00:34, 289.29it/s, env_step=1990000, len=33, n/ep=0, n/st=10, player_1/loss=1.298, player_2/loss=0.933, rew=106.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #199: test_reward: 39.600000 ± 52.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #200: 10001it [00:34, 289.11it/s, env_step=2000000, len=39, n/ep=0, n/st=10, player_1/loss=1.271, player_2/loss=0.941, rew=159.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #200: test_reward: 214.500000 ± 20.723175, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #201: 10001it [00:34, 289.08it/s, env_step=2010000, len=31, n/ep=0, n/st=10, player_1/loss=1.348, player_2/loss=0.848, rew=115.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #201: test_reward: 139.700000 ± 39.935072, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #202: 10001it [00:34, 289.13it/s, env_step=2020000, len=9, n/ep=1, n/st=10, player_1/loss=1.318, player_2/loss=0.748, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #202: test_reward: 178.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #203: 10001it [00:34, 288.71it/s, env_step=2030000, len=7, n/ep=0, n/st=10, player_1/loss=1.279, player_2/loss=0.884, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #203: test_reward: 183.800000 ± 0.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #204: 10001it [00:34, 289.45it/s, env_step=2040000, len=37, n/ep=1, n/st=10, player_1/loss=1.141, player_2/loss=0.696, rew=181.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #204: test_reward: 122.400000 ± 22.821919, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #205: 10001it [00:34, 288.83it/s, env_step=2050000, len=17, n/ep=0, n/st=10, player_1/loss=1.093, player_2/loss=0.661, rew=23.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #205: test_reward: 169.100000 ± 27.420613, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #206: 10001it [00:34, 289.14it/s, env_step=2060000, len=39, n/ep=1, n/st=10, player_1/loss=1.037, player_2/loss=0.644, rew=156.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #206: test_reward: 22.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #207: 10001it [00:34, 288.18it/s, env_step=2070000, len=39, n/ep=1, n/st=10, player_1/loss=0.898, player_2/loss=0.693, rew=213.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #207: test_reward: 233.500000 ± 5.239275, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #208: 10001it [00:34, 289.49it/s, env_step=2080000, len=39, n/ep=1, n/st=10, player_1/loss=0.998, player_2/loss=0.655, rew=174.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #208: test_reward: 52.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #209: 10001it [00:34, 288.92it/s, env_step=2090000, len=33, n/ep=1, n/st=10, player_1/loss=1.016, player_2/loss=0.765, rew=147.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #209: test_reward: 211.600000 ± 7.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #210: 10001it [00:34, 289.27it/s, env_step=2100000, len=26, n/ep=0, n/st=10, player_1/loss=0.898, player_2/loss=0.723, rew=87.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #210: test_reward: 7.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #211: 10001it [00:34, 289.35it/s, env_step=2110000, len=15, n/ep=1, n/st=10, player_1/loss=1.103, player_2/loss=1.020, rew=10.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #211: test_reward: 44.100000 ± 14.700000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #212: 10001it [00:34, 288.89it/s, env_step=2120000, len=19, n/ep=1, n/st=10, player_1/loss=1.213, player_2/loss=1.089, rew=39.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #212: test_reward: 27.800000 ± 3.124100, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #213: 10001it [00:34, 289.09it/s, env_step=2130000, len=15, n/ep=0, n/st=10, player_1/loss=1.194, player_2/loss=1.013, rew=21.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #213: test_reward: 26.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #214: 10001it [00:34, 289.46it/s, env_step=2140000, len=13, n/ep=3, n/st=10, player_1/loss=1.210, player_2/loss=1.094, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #214: test_reward: 1.600000 ± 0.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #215: 10001it [00:34, 289.49it/s, env_step=2150000, len=8, n/ep=1, n/st=10, player_1/loss=1.355, player_2/loss=1.210, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #215: test_reward: 55.200000 ± 3.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #216: 10001it [00:34, 290.10it/s, env_step=2160000, len=19, n/ep=0, n/st=10, player_1/loss=1.271, player_2/loss=1.079, rew=39.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #216: test_reward: 48.600000 ± 47.623944, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #217: 10001it [00:34, 289.88it/s, env_step=2170000, len=18, n/ep=0, n/st=10, player_1/loss=1.226, player_2/loss=1.093, rew=36.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #217: test_reward: 60.000000 ± 58.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #218: 10001it [00:34, 289.00it/s, env_step=2180000, len=23, n/ep=0, n/st=10, player_1/loss=1.221, player_2/loss=1.144, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #218: test_reward: 31.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #219: 10001it [00:34, 288.74it/s, env_step=2190000, len=7, n/ep=1, n/st=10, player_1/loss=1.394, player_2/loss=1.558, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #219: test_reward: 14.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #220: 10001it [00:34, 288.55it/s, env_step=2200000, len=19, n/ep=0, n/st=10, player_1/loss=1.115, player_2/loss=1.463, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #220: test_reward: 127.100000 ± 21.828651, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #221: 10001it [00:34, 289.04it/s, env_step=2210000, len=14, n/ep=1, n/st=10, player_1/loss=1.306, player_2/loss=1.035, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #221: test_reward: 233.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #222: 10001it [00:34, 289.18it/s, env_step=2220000, len=40, n/ep=1, n/st=10, player_1/loss=1.213, player_2/loss=0.986, rew=243.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #222: test_reward: 116.200000 ± 50.344414, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #223: 10001it [00:34, 289.00it/s, env_step=2230000, len=22, n/ep=0, n/st=10, player_1/loss=1.024, player_2/loss=0.784, rew=60.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #223: test_reward: 161.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #224: 10001it [00:34, 289.57it/s, env_step=2240000, len=19, n/ep=1, n/st=10, player_1/loss=1.245, player_2/loss=1.245, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #224: test_reward: 162.900000 ± 45.300000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #225: 10001it [00:34, 289.16it/s, env_step=2250000, len=14, n/ep=0, n/st=10, player_1/loss=1.421, player_2/loss=1.339, rew=12.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #225: test_reward: 231.500000 ± 52.500000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #226: 10001it [00:34, 289.70it/s, env_step=2260000, len=31, n/ep=0, n/st=10, player_1/loss=1.478, player_2/loss=1.292, rew=102.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #226: test_reward: 14.400000 ± 4.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #227: 10001it [00:34, 288.95it/s, env_step=2270000, len=23, n/ep=1, n/st=10, player_1/loss=1.654, player_2/loss=1.442, rew=47.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #227: test_reward: 10.400000 ± 1.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #228: 10001it [00:34, 289.09it/s, env_step=2280000, len=13, n/ep=0, n/st=10, player_1/loss=1.259, player_2/loss=1.181, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #228: test_reward: 7.700000 ± 5.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #229: 10001it [00:34, 288.88it/s, env_step=2290000, len=21, n/ep=1, n/st=10, player_1/loss=1.312, player_2/loss=1.443, rew=41.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #229: test_reward: 25.800000 ± 1.833030, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #230: 10001it [00:34, 289.32it/s, env_step=2300000, len=37, n/ep=1, n/st=10, player_1/loss=1.310, player_2/loss=1.268, rew=163.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #230: test_reward: 206.000000 ± 47.726303, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #231: 10001it [00:34, 289.02it/s, env_step=2310000, len=19, n/ep=0, n/st=10, player_1/loss=1.137, player_2/loss=0.871, rew=27.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #231: test_reward: 190.400000 ± 55.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #232: 10001it [00:34, 289.44it/s, env_step=2320000, len=37, n/ep=0, n/st=10, player_1/loss=1.563, player_2/loss=1.170, rew=175.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #232: test_reward: 22.800000 ± 3.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #233: 10001it [00:34, 288.91it/s, env_step=2330000, len=23, n/ep=0, n/st=10, player_1/loss=1.541, player_2/loss=1.516, rew=20.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #233: test_reward: 49.200000 ± 6.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #234: 10001it [00:34, 288.62it/s, env_step=2340000, len=39, n/ep=0, n/st=10, player_1/loss=1.206, player_2/loss=1.214, rew=213.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #234: test_reward: 29.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #235: 10001it [00:34, 289.26it/s, env_step=2350000, len=31, n/ep=0, n/st=10, player_1/loss=1.433, player_2/loss=1.504, rew=86.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #235: test_reward: 40.700000 ± 53.516446, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #236: 10001it [00:34, 288.92it/s, env_step=2360000, len=39, n/ep=0, n/st=10, player_1/loss=1.662, player_2/loss=1.441, rew=219.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #236: test_reward: 100.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #237: 10001it [00:34, 288.73it/s, env_step=2370000, len=39, n/ep=1, n/st=10, player_1/loss=1.410, player_2/loss=1.351, rew=228.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #237: test_reward: 20.300000 ± 6.870953, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #238: 10001it [00:34, 289.03it/s, env_step=2380000, len=35, n/ep=0, n/st=10, player_1/loss=1.280, player_2/loss=1.166, rew=173.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #238: test_reward: 200.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #239: 10001it [00:34, 287.58it/s, env_step=2390000, len=19, n/ep=0, n/st=10, player_1/loss=1.139, player_2/loss=0.897, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #239: test_reward: 162.000000 ± 15.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #240: 10001it [00:34, 289.79it/s, env_step=2400000, len=17, n/ep=1, n/st=10, player_1/loss=1.409, player_2/loss=0.976, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #240: test_reward: 30.600000 ± 41.511926, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #241: 10001it [00:34, 289.44it/s, env_step=2410000, len=27, n/ep=0, n/st=10, player_1/loss=1.266, player_2/loss=0.986, rew=30.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #241: test_reward: 228.900000 ± 5.107837, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #242: 10001it [00:34, 289.17it/s, env_step=2420000, len=39, n/ep=0, n/st=10, player_1/loss=1.065, player_2/loss=0.770, rew=223.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #242: test_reward: 166.300000 ± 55.749529, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #243: 10001it [00:34, 289.37it/s, env_step=2430000, len=32, n/ep=2, n/st=10, player_1/loss=0.870, player_2/loss=0.649, rew=167.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #243: test_reward: 237.600000 ± 28.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #244: 10001it [00:34, 288.83it/s, env_step=2440000, len=33, n/ep=0, n/st=10, player_1/loss=0.923, player_2/loss=0.649, rew=100.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #244: test_reward: 10.800000 ± 3.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #245: 10001it [00:34, 288.19it/s, env_step=2450000, len=24, n/ep=0, n/st=10, player_1/loss=1.136, player_2/loss=0.829, rew=70.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #245: test_reward: 176.800000 ± 0.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #246: 10001it [00:34, 289.05it/s, env_step=2460000, len=7, n/ep=1, n/st=10, player_1/loss=1.235, player_2/loss=1.465, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #246: test_reward: 4.600000 ± 7.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #247: 10001it [00:34, 289.09it/s, env_step=2470000, len=27, n/ep=0, n/st=10, player_1/loss=1.011, player_2/loss=0.910, rew=102.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #247: test_reward: 84.400000 ± 4.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #248: 10001it [00:34, 289.16it/s, env_step=2480000, len=7, n/ep=0, n/st=10, player_1/loss=1.160, player_2/loss=1.368, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #248: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #249: 10001it [00:34, 288.94it/s, env_step=2490000, len=17, n/ep=1, n/st=10, player_1/loss=1.108, player_2/loss=1.003, rew=29.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #249: test_reward: 231.100000 ± 8.700000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #250: 10001it [00:34, 288.68it/s, env_step=2500000, len=39, n/ep=0, n/st=10, player_1/loss=0.843, player_2/loss=0.633, rew=174.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #250: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #251: 10001it [00:34, 289.53it/s, env_step=2510000, len=39, n/ep=1, n/st=10, player_1/loss=0.809, player_2/loss=0.660, rew=233.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #251: test_reward: 245.300000 ± 2.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #252: 10001it [00:34, 288.69it/s, env_step=2520000, len=8, n/ep=2, n/st=10, player_1/loss=0.864, player_2/loss=0.672, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #252: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #253: 10001it [00:34, 289.01it/s, env_step=2530000, len=31, n/ep=1, n/st=10, player_1/loss=0.898, player_2/loss=0.760, rew=138.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #253: test_reward: 109.000000 ± 35.791060, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #254: 10001it [00:34, 289.15it/s, env_step=2540000, len=24, n/ep=1, n/st=10, player_1/loss=0.902, player_2/loss=0.646, rew=60.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #254: test_reward: 196.500000 ± 45.640443, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #255: 10001it [00:34, 288.28it/s, env_step=2550000, len=31, n/ep=0, n/st=10, player_1/loss=0.841, player_2/loss=0.621, rew=117.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #255: test_reward: 231.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #256: 10001it [00:34, 289.50it/s, env_step=2560000, len=33, n/ep=0, n/st=10, player_1/loss=0.986, player_2/loss=0.738, rew=143.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #256: test_reward: 100.500000 ± 1.500000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #257: 10001it [00:34, 289.08it/s, env_step=2570000, len=7, n/ep=0, n/st=10, player_1/loss=1.066, player_2/loss=1.136, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #257: test_reward: 5.700000 ± 11.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #258: 10001it [00:34, 288.98it/s, env_step=2580000, len=19, n/ep=0, n/st=10, player_1/loss=1.454, player_2/loss=1.593, rew=44.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #258: test_reward: 225.600000 ± 67.396142, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #259: 10001it [00:34, 289.29it/s, env_step=2590000, len=20, n/ep=1, n/st=10, player_1/loss=1.252, player_2/loss=1.337, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #259: test_reward: 32.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #260: 10001it [00:34, 289.32it/s, env_step=2600000, len=19, n/ep=1, n/st=10, player_1/loss=1.405, player_2/loss=1.600, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #260: test_reward: 35.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #261: 10001it [00:34, 289.23it/s, env_step=2610000, len=7, n/ep=0, n/st=10, player_1/loss=1.339, player_2/loss=1.399, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #261: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #262: 10001it [00:34, 289.74it/s, env_step=2620000, len=39, n/ep=1, n/st=10, player_1/loss=1.183, player_2/loss=1.078, rew=170.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #262: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #263: 10001it [00:34, 288.45it/s, env_step=2630000, len=19, n/ep=1, n/st=10, player_1/loss=1.052, player_2/loss=0.955, rew=46.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #263: test_reward: 166.500000 ± 94.339016, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #264: 10001it [00:34, 288.58it/s, env_step=2640000, len=32, n/ep=0, n/st=10, player_1/loss=0.982, player_2/loss=0.678, rew=153.33]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #264: test_reward: 263.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #265: 10001it [00:34, 288.46it/s, env_step=2650000, len=21, n/ep=0, n/st=10, player_1/loss=0.908, player_2/loss=0.648, rew=45.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #265: test_reward: 39.800000 ± 3.124100, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #266: 10001it [00:34, 288.55it/s, env_step=2660000, len=25, n/ep=3, n/st=10, player_1/loss=0.868, player_2/loss=0.671, rew=94.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #266: test_reward: 27.900000 ± 9.300000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #267: 10001it [00:36, 275.13it/s, env_step=2670000, len=39, n/ep=1, n/st=10, player_1/loss=0.897, player_2/loss=0.613, rew=252.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #267: test_reward: 134.700000 ± 21.587265, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #268: 10001it [00:34, 287.50it/s, env_step=2680000, len=26, n/ep=3, n/st=10, player_1/loss=0.903, player_2/loss=1.003, rew=107.67]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #268: test_reward: 4.400000 ± 7.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #269: 10001it [00:34, 290.17it/s, env_step=2690000, len=7, n/ep=1, n/st=10, player_1/loss=0.910, player_2/loss=1.196, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #269: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #270: 10001it [00:34, 289.44it/s, env_step=2700000, len=21, n/ep=1, n/st=10, player_1/loss=1.072, player_2/loss=1.014, rew=41.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #270: test_reward: 27.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #271: 10001it [00:34, 289.26it/s, env_step=2710000, len=11, n/ep=0, n/st=10, player_1/loss=1.316, player_2/loss=1.122, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #271: test_reward: 10.500000 ± 4.500000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #272: 10001it [00:34, 288.62it/s, env_step=2720000, len=27, n/ep=2, n/st=10, player_1/loss=1.142, player_2/loss=0.867, rew=112.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #272: test_reward: 147.600000 ± 10.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #273: 10001it [00:34, 289.40it/s, env_step=2730000, len=21, n/ep=1, n/st=10, player_1/loss=1.139, player_2/loss=0.929, rew=47.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #273: test_reward: 113.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #274: 10001it [00:34, 289.87it/s, env_step=2740000, len=39, n/ep=1, n/st=10, player_1/loss=1.340, player_2/loss=1.035, rew=167.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #274: test_reward: 55.700000 ± 4.473254, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #275: 10001it [00:34, 289.20it/s, env_step=2750000, len=39, n/ep=1, n/st=10, player_1/loss=1.426, player_2/loss=0.920, rew=189.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #275: test_reward: 77.500000 ± 39.837796, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #276: 10001it [00:34, 288.82it/s, env_step=2760000, len=19, n/ep=0, n/st=10, player_1/loss=1.046, player_2/loss=0.697, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #276: test_reward: 26.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #277: 10001it [00:34, 289.74it/s, env_step=2770000, len=36, n/ep=3, n/st=10, player_1/loss=1.142, player_2/loss=0.895, rew=181.33]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #277: test_reward: 186.000000 ± 60.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #278: 10001it [00:34, 289.59it/s, env_step=2780000, len=15, n/ep=0, n/st=10, player_1/loss=0.876, player_2/loss=0.666, rew=14.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #278: test_reward: 243.800000 ± 15.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #279: 10001it [00:34, 289.34it/s, env_step=2790000, len=15, n/ep=0, n/st=10, player_1/loss=0.856, player_2/loss=0.650, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #279: test_reward: 259.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #280: 10001it [00:34, 289.71it/s, env_step=2800000, len=30, n/ep=0, n/st=10, player_1/loss=0.966, player_2/loss=0.741, rew=129.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #280: test_reward: 178.400000 ± 58.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #281: 10001it [00:34, 289.33it/s, env_step=2810000, len=13, n/ep=1, n/st=10, player_1/loss=1.091, player_2/loss=0.863, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #281: test_reward: 137.400000 ± 1.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #282: 10001it [00:34, 289.75it/s, env_step=2820000, len=27, n/ep=0, n/st=10, player_1/loss=1.127, player_2/loss=0.777, rew=58.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #282: test_reward: 173.800000 ± 28.034978, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #283: 10001it [00:34, 289.23it/s, env_step=2830000, len=19, n/ep=1, n/st=10, player_1/loss=1.329, player_2/loss=1.499, rew=19.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #283: test_reward: 43.100000 ± 42.300000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #284: 10001it [00:34, 289.94it/s, env_step=2840000, len=37, n/ep=1, n/st=10, player_1/loss=1.138, player_2/loss=1.028, rew=121.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #284: test_reward: 216.900000 ± 34.486084, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #285: 10001it [00:34, 289.57it/s, env_step=2850000, len=7, n/ep=3, n/st=10, player_1/loss=1.230, player_2/loss=1.192, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #285: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #286: 10001it [00:34, 289.66it/s, env_step=2860000, len=7, n/ep=2, n/st=10, player_1/loss=0.990, player_2/loss=1.334, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #286: test_reward: 22.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #287: 10001it [00:34, 289.53it/s, env_step=2870000, len=17, n/ep=0, n/st=10, player_1/loss=1.278, player_2/loss=1.294, rew=16.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #287: test_reward: 12.700000 ± 2.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #288: 10001it [00:34, 289.00it/s, env_step=2880000, len=25, n/ep=1, n/st=10, player_1/loss=1.053, player_2/loss=0.883, rew=83.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #288: test_reward: 133.100000 ± 20.427677, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #289: 10001it [00:34, 288.98it/s, env_step=2890000, len=25, n/ep=0, n/st=10, player_1/loss=1.184, player_2/loss=1.051, rew=86.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #289: test_reward: 156.300000 ± 73.002808, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #290: 10001it [00:34, 289.39it/s, env_step=2900000, len=8, n/ep=1, n/st=10, player_1/loss=1.523, player_2/loss=1.813, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #290: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #291: 10001it [00:34, 289.44it/s, env_step=2910000, len=36, n/ep=1, n/st=10, player_1/loss=1.569, player_2/loss=1.826, rew=133.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #291: test_reward: 88.200000 ± 30.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #292: 10001it [00:34, 289.56it/s, env_step=2920000, len=8, n/ep=1, n/st=10, player_1/loss=1.461, player_2/loss=1.398, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #292: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #293: 10001it [00:34, 289.81it/s, env_step=2930000, len=33, n/ep=0, n/st=10, player_1/loss=1.428, player_2/loss=1.639, rew=94.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #293: test_reward: 73.600000 ± 24.992799, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #294: 10001it [00:34, 289.61it/s, env_step=2940000, len=18, n/ep=0, n/st=10, player_1/loss=1.681, player_2/loss=1.825, rew=21.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #294: test_reward: 20.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #295: 10001it [00:34, 289.41it/s, env_step=2950000, len=25, n/ep=0, n/st=10, player_1/loss=1.281, player_2/loss=0.918, rew=62.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #295: test_reward: 160.200000 ± 53.400000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #296: 10001it [00:34, 289.23it/s, env_step=2960000, len=13, n/ep=0, n/st=10, player_1/loss=1.562, player_2/loss=0.918, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #296: test_reward: 162.000000 ± 43.349740, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #297: 10001it [00:34, 289.45it/s, env_step=2970000, len=24, n/ep=2, n/st=10, player_1/loss=1.394, player_2/loss=0.938, rew=44.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #297: test_reward: 23.200000 ± 30.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #298: 10001it [00:34, 288.59it/s, env_step=2980000, len=30, n/ep=1, n/st=10, player_1/loss=1.355, player_2/loss=1.079, rew=109.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #298: test_reward: 138.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #299: 10001it [00:34, 289.04it/s, env_step=2990000, len=21, n/ep=0, n/st=10, player_1/loss=1.343, player_2/loss=0.994, rew=37.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #299: test_reward: 37.600000 ± 19.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #300: 10001it [00:34, 288.96it/s, env_step=3000000, len=16, n/ep=0, n/st=10, player_1/loss=1.287, player_2/loss=0.932, rew=11.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #300: test_reward: 192.900000 ± 50.270170, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #301: 10001it [00:34, 289.33it/s, env_step=3010000, len=15, n/ep=1, n/st=10, player_1/loss=1.179, player_2/loss=1.063, rew=12.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #301: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #302: 10001it [00:34, 288.41it/s, env_step=3020000, len=7, n/ep=1, n/st=10, player_1/loss=1.104, player_2/loss=1.095, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #302: test_reward: 3.100000 ± 3.300000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #303: 10001it [00:34, 289.36it/s, env_step=3030000, len=7, n/ep=2, n/st=10, player_1/loss=1.120, player_2/loss=1.270, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #303: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #304: 10001it [00:34, 289.31it/s, env_step=3040000, len=13, n/ep=0, n/st=10, player_1/loss=1.203, player_2/loss=1.365, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #304: test_reward: 175.700000 ± 27.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #305: 10001it [00:34, 289.25it/s, env_step=3050000, len=21, n/ep=1, n/st=10, player_1/loss=1.201, player_2/loss=1.188, rew=26.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #305: test_reward: 110.900000 ± 27.300000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #306: 10001it [00:34, 289.49it/s, env_step=3060000, len=35, n/ep=0, n/st=10, player_1/loss=1.098, player_2/loss=1.211, rew=127.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #306: test_reward: 10.200000 ± 24.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #307: 10001it [00:34, 289.09it/s, env_step=3070000, len=19, n/ep=0, n/st=10, player_1/loss=1.200, player_2/loss=0.992, rew=37.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #307: test_reward: 221.800000 ± 0.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #308: 10001it [00:34, 289.98it/s, env_step=3080000, len=7, n/ep=0, n/st=10, player_1/loss=1.033, player_2/loss=1.112, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #308: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #309: 10001it [00:34, 289.46it/s, env_step=3090000, len=19, n/ep=1, n/st=10, player_1/loss=1.043, player_2/loss=1.231, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #309: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #310: 10001it [00:34, 288.82it/s, env_step=3100000, len=35, n/ep=0, n/st=10, player_1/loss=1.069, player_2/loss=1.021, rew=139.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #310: test_reward: 180.000000 ± 47.337089, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #311: 10001it [00:34, 289.00it/s, env_step=3110000, len=7, n/ep=1, n/st=10, player_1/loss=0.987, player_2/loss=0.885, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #311: test_reward: 199.200000 ± 59.400000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #312: 10001it [00:34, 289.10it/s, env_step=3120000, len=39, n/ep=0, n/st=10, player_1/loss=0.900, player_2/loss=0.811, rew=179.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #312: test_reward: 186.000000 ± 39.509493, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #313: 10001it [00:34, 288.75it/s, env_step=3130000, len=7, n/ep=1, n/st=10, player_1/loss=0.964, player_2/loss=0.849, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #313: test_reward: 178.700000 ± 21.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #314: 10001it [00:34, 289.08it/s, env_step=3140000, len=23, n/ep=1, n/st=10, player_1/loss=1.274, player_2/loss=0.980, rew=31.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #314: test_reward: 169.600000 ± 36.756496, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #315: 10001it [00:34, 288.87it/s, env_step=3150000, len=22, n/ep=0, n/st=10, player_1/loss=1.144, player_2/loss=0.977, rew=49.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #315: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #316: 10001it [00:34, 288.95it/s, env_step=3160000, len=7, n/ep=1, n/st=10, player_1/loss=1.017, player_2/loss=0.884, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #316: test_reward: 156.900000 ± 72.833303, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #317: 10001it [00:34, 289.21it/s, env_step=3170000, len=7, n/ep=0, n/st=10, player_1/loss=1.052, player_2/loss=1.323, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #317: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #318: 10001it [00:34, 289.21it/s, env_step=3180000, len=7, n/ep=0, n/st=10, player_1/loss=1.056, player_2/loss=1.356, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #318: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #319: 10001it [00:34, 289.01it/s, env_step=3190000, len=7, n/ep=0, n/st=10, player_1/loss=1.025, player_2/loss=1.339, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #319: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #320: 10001it [00:34, 288.90it/s, env_step=3200000, len=23, n/ep=1, n/st=10, player_1/loss=1.065, player_2/loss=1.184, rew=51.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #320: test_reward: 229.600000 ± 70.200000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #321: 10001it [00:34, 289.64it/s, env_step=3210000, len=12, n/ep=2, n/st=10, player_1/loss=1.067, player_2/loss=1.300, rew=14.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #321: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #322: 10001it [00:34, 289.38it/s, env_step=3220000, len=27, n/ep=1, n/st=10, player_1/loss=1.103, player_2/loss=1.340, rew=90.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #322: test_reward: 168.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #323: 10001it [00:34, 289.09it/s, env_step=3230000, len=7, n/ep=0, n/st=10, player_1/loss=1.092, player_2/loss=1.098, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #323: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #324: 10001it [00:34, 288.47it/s, env_step=3240000, len=7, n/ep=2, n/st=10, player_1/loss=0.965, player_2/loss=1.264, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #324: test_reward: 10.800000 ± 26.400000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #325: 10001it [00:34, 289.03it/s, env_step=3250000, len=19, n/ep=1, n/st=10, player_1/loss=1.077, player_2/loss=1.316, rew=9.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #325: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #326: 10001it [00:34, 288.94it/s, env_step=3260000, len=15, n/ep=0, n/st=10, player_1/loss=1.067, player_2/loss=1.273, rew=7.50]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #326: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #327: 10001it [00:34, 289.29it/s, env_step=3270000, len=7, n/ep=1, n/st=10, player_1/loss=1.035, player_2/loss=1.422, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #327: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #328: 10001it [00:34, 288.77it/s, env_step=3280000, len=7, n/ep=2, n/st=10, player_1/loss=1.026, player_2/loss=1.316, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #328: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #329: 10001it [00:34, 289.01it/s, env_step=3290000, len=7, n/ep=0, n/st=10, player_1/loss=1.054, player_2/loss=1.412, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #329: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #330: 10001it [00:34, 288.98it/s, env_step=3300000, len=8, n/ep=1, n/st=10, player_1/loss=1.092, player_2/loss=1.312, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #330: test_reward: 153.000000 ± 54.345193, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #331: 10001it [00:34, 289.30it/s, env_step=3310000, len=18, n/ep=2, n/st=10, player_1/loss=1.110, player_2/loss=1.212, rew=26.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #331: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #332: 10001it [00:34, 288.78it/s, env_step=3320000, len=7, n/ep=1, n/st=10, player_1/loss=1.139, player_2/loss=1.359, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #332: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #333: 10001it [00:34, 289.09it/s, env_step=3330000, len=7, n/ep=1, n/st=10, player_1/loss=1.150, player_2/loss=1.285, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #333: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #334: 10001it [00:34, 289.18it/s, env_step=3340000, len=7, n/ep=3, n/st=10, player_1/loss=1.078, player_2/loss=1.259, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #334: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #335: 10001it [00:34, 288.73it/s, env_step=3350000, len=7, n/ep=0, n/st=10, player_1/loss=1.136, player_2/loss=1.356, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #335: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #336: 10001it [00:34, 289.29it/s, env_step=3360000, len=27, n/ep=0, n/st=10, player_1/loss=1.050, player_2/loss=1.303, rew=38.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #336: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #337: 10001it [00:34, 289.12it/s, env_step=3370000, len=7, n/ep=2, n/st=10, player_1/loss=0.978, player_2/loss=1.349, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #337: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #338: 10001it [00:34, 288.77it/s, env_step=3380000, len=35, n/ep=0, n/st=10, player_1/loss=1.023, player_2/loss=1.305, rew=194.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #338: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #339: 10001it [00:34, 289.04it/s, env_step=3390000, len=7, n/ep=3, n/st=10, player_1/loss=1.059, player_2/loss=1.355, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #339: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #340: 10001it [00:34, 289.37it/s, env_step=3400000, len=7, n/ep=0, n/st=10, player_1/loss=1.135, player_2/loss=1.282, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #340: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #341: 10001it [00:34, 289.12it/s, env_step=3410000, len=7, n/ep=1, n/st=10, player_1/loss=1.095, player_2/loss=1.272, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #341: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #342: 10001it [00:34, 289.07it/s, env_step=3420000, len=7, n/ep=1, n/st=10, player_1/loss=1.082, player_2/loss=1.333, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #342: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #343: 10001it [00:34, 288.86it/s, env_step=3430000, len=7, n/ep=0, n/st=10, player_1/loss=1.017, player_2/loss=1.397, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #343: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #344: 10001it [00:34, 289.12it/s, env_step=3440000, len=15, n/ep=0, n/st=10, player_1/loss=1.165, player_2/loss=1.376, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #344: test_reward: 212.400000 ± 34.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #345: 10001it [00:34, 288.89it/s, env_step=3450000, len=7, n/ep=1, n/st=10, player_1/loss=1.096, player_2/loss=1.362, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #345: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #346: 10001it [00:34, 289.16it/s, env_step=3460000, len=15, n/ep=0, n/st=10, player_1/loss=1.012, player_2/loss=1.318, rew=36.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #346: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #347: 10001it [00:34, 288.95it/s, env_step=3470000, len=7, n/ep=1, n/st=10, player_1/loss=1.046, player_2/loss=1.281, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #347: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #348: 10001it [00:34, 288.85it/s, env_step=3480000, len=7, n/ep=0, n/st=10, player_1/loss=1.014, player_2/loss=1.268, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #348: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #349: 10001it [00:34, 289.21it/s, env_step=3490000, len=7, n/ep=0, n/st=10, player_1/loss=0.997, player_2/loss=1.246, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #349: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #350: 10001it [00:34, 288.56it/s, env_step=3500000, len=7, n/ep=1, n/st=10, player_1/loss=0.955, player_2/loss=1.234, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #350: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #351: 10001it [00:34, 288.58it/s, env_step=3510000, len=7, n/ep=1, n/st=10, player_1/loss=0.946, player_2/loss=1.245, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #351: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #352: 10001it [00:34, 288.91it/s, env_step=3520000, len=7, n/ep=1, n/st=10, player_1/loss=1.209, player_2/loss=1.485, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #352: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #353: 10001it [00:34, 289.19it/s, env_step=3530000, len=7, n/ep=0, n/st=10, player_1/loss=0.984, player_2/loss=1.288, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #353: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #354: 10001it [00:34, 288.67it/s, env_step=3540000, len=7, n/ep=0, n/st=10, player_1/loss=1.140, player_2/loss=1.127, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #354: test_reward: 207.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #355: 10001it [00:34, 289.04it/s, env_step=3550000, len=31, n/ep=0, n/st=10, player_1/loss=1.075, player_2/loss=1.022, rew=117.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #355: test_reward: 89.600000 ± 10.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #356: 10001it [00:34, 288.82it/s, env_step=3560000, len=13, n/ep=0, n/st=10, player_1/loss=0.976, player_2/loss=0.923, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #356: test_reward: 212.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #357: 10001it [00:34, 288.04it/s, env_step=3570000, len=13, n/ep=1, n/st=10, player_1/loss=1.009, player_2/loss=0.778, rew=4.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #357: test_reward: 127.700000 ± 18.900000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #358: 10001it [00:34, 288.11it/s, env_step=3580000, len=15, n/ep=0, n/st=10, player_1/loss=1.061, player_2/loss=0.815, rew=13.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #358: test_reward: 71.200000 ± 5.400000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #359: 10001it [00:34, 288.73it/s, env_step=3590000, len=9, n/ep=4, n/st=10, player_1/loss=1.411, player_2/loss=1.516, rew=6.50]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #359: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #360: 10001it [00:34, 288.74it/s, env_step=3600000, len=19, n/ep=1, n/st=10, player_1/loss=1.066, player_2/loss=1.313, rew=33.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #360: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #361: 10001it [00:34, 289.13it/s, env_step=3610000, len=7, n/ep=0, n/st=10, player_1/loss=0.979, player_2/loss=1.315, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #361: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #362: 10001it [00:34, 288.77it/s, env_step=3620000, len=27, n/ep=0, n/st=10, player_1/loss=0.976, player_2/loss=1.254, rew=63.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #362: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #363: 10001it [00:34, 288.52it/s, env_step=3630000, len=7, n/ep=0, n/st=10, player_1/loss=1.044, player_2/loss=1.181, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #363: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #364: 10001it [00:34, 288.91it/s, env_step=3640000, len=9, n/ep=0, n/st=10, player_1/loss=0.926, player_2/loss=1.206, rew=4.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #364: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #365: 10001it [00:34, 288.55it/s, env_step=3650000, len=10, n/ep=3, n/st=10, player_1/loss=0.962, player_2/loss=1.171, rew=4.33]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #365: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #366: 10001it [00:34, 289.22it/s, env_step=3660000, len=7, n/ep=1, n/st=10, player_1/loss=0.877, player_2/loss=1.113, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #366: test_reward: 1.800000 ± 0.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #367: 10001it [00:34, 288.39it/s, env_step=3670000, len=7, n/ep=1, n/st=10, player_1/loss=0.936, player_2/loss=1.173, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #367: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #368: 10001it [00:35, 282.46it/s, env_step=3680000, len=7, n/ep=0, n/st=10, player_1/loss=1.142, player_2/loss=1.128, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #368: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #369: 10001it [00:35, 280.12it/s, env_step=3690000, len=8, n/ep=1, n/st=10, player_1/loss=1.315, player_2/loss=1.092, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #369: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #370: 10001it [00:35, 284.55it/s, env_step=3700000, len=9, n/ep=0, n/st=10, player_1/loss=1.286, player_2/loss=1.142, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #370: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #371: 10001it [00:34, 289.84it/s, env_step=3710000, len=28, n/ep=1, n/st=10, player_1/loss=1.132, player_2/loss=1.312, rew=58.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #371: test_reward: 68.200000 ± 0.600000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #372: 10001it [00:35, 285.43it/s, env_step=3720000, len=7, n/ep=0, n/st=10, player_1/loss=1.266, player_2/loss=1.326, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #372: test_reward: 58.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #373: 10001it [00:35, 283.18it/s, env_step=3730000, len=17, n/ep=1, n/st=10, player_1/loss=1.143, player_2/loss=1.174, rew=24.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #373: test_reward: 2.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #374: 10001it [00:34, 287.14it/s, env_step=3740000, len=17, n/ep=0, n/st=10, player_1/loss=1.040, player_2/loss=0.841, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #374: test_reward: 196.700000 ± 14.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #375: 10001it [00:34, 287.77it/s, env_step=3750000, len=23, n/ep=0, n/st=10, player_1/loss=0.988, player_2/loss=0.677, rew=66.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #375: test_reward: 176.400000 ± 50.221908, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #376: 10001it [00:34, 289.17it/s, env_step=3760000, len=39, n/ep=0, n/st=10, player_1/loss=0.961, player_2/loss=0.631, rew=254.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #376: test_reward: 213.300000 ± 65.100000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #377: 10001it [00:35, 283.59it/s, env_step=3770000, len=31, n/ep=1, n/st=10, player_1/loss=0.935, player_2/loss=0.626, rew=145.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #377: test_reward: 216.700000 ± 32.975900, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #378: 10001it [00:35, 284.42it/s, env_step=3780000, len=27, n/ep=1, n/st=10, player_1/loss=0.980, player_2/loss=0.710, rew=70.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #378: test_reward: 187.000000 ± 0.000000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #379: 10001it [00:32, 303.62it/s, env_step=3790000, len=25, n/ep=1, n/st=10, player_1/loss=1.275, player_2/loss=0.996, rew=65.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #379: test_reward: 63.400000 ± 1.800000, best_reward: 267.700000 ± 15.900000 in #171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #380: 10001it [00:33, 300.44it/s, env_step=3800000, len=25, n/ep=1, n/st=10, player_1/loss=1.164, player_2/loss=0.742, rew=76.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #380: test_reward: 280.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #381: 10001it [00:33, 296.48it/s, env_step=3810000, len=39, n/ep=1, n/st=10, player_1/loss=1.164, player_2/loss=0.716, rew=218.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #381: test_reward: 239.400000 ± 13.800000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #382: 10001it [00:34, 293.54it/s, env_step=3820000, len=11, n/ep=2, n/st=10, player_1/loss=1.090, player_2/loss=0.701, rew=2.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #382: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #383: 10001it [00:33, 302.34it/s, env_step=3830000, len=32, n/ep=0, n/st=10, player_1/loss=1.150, player_2/loss=0.802, rew=100.50]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #383: test_reward: 115.800000 ± 42.621122, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #384: 10001it [00:34, 286.96it/s, env_step=3840000, len=31, n/ep=0, n/st=10, player_1/loss=1.336, player_2/loss=1.219, rew=66.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #384: test_reward: 47.900000 ± 11.700000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #385: 10001it [00:34, 289.94it/s, env_step=3850000, len=18, n/ep=2, n/st=10, player_1/loss=1.654, player_2/loss=1.785, rew=34.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #385: test_reward: 132.600000 ± 31.200000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #386: 10001it [00:35, 281.64it/s, env_step=3860000, len=11, n/ep=0, n/st=10, player_1/loss=1.251, player_2/loss=1.327, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #386: test_reward: 175.400000 ± 37.694031, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #387: 10001it [00:34, 288.79it/s, env_step=3870000, len=19, n/ep=0, n/st=10, player_1/loss=1.243, player_2/loss=1.134, rew=27.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #387: test_reward: 29.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #388: 10001it [00:34, 288.93it/s, env_step=3880000, len=13, n/ep=3, n/st=10, player_1/loss=1.382, player_2/loss=1.344, rew=22.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #388: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #389: 10001it [00:34, 288.91it/s, env_step=3890000, len=17, n/ep=0, n/st=10, player_1/loss=1.234, player_2/loss=1.267, rew=22.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #389: test_reward: 92.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #390: 10001it [00:34, 287.90it/s, env_step=3900000, len=7, n/ep=2, n/st=10, player_1/loss=1.071, player_2/loss=1.252, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #390: test_reward: 10.700000 ± 26.100000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #391: 10001it [00:34, 287.17it/s, env_step=3910000, len=7, n/ep=0, n/st=10, player_1/loss=1.087, player_2/loss=1.180, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #391: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #392: 10001it [00:34, 287.37it/s, env_step=3920000, len=9, n/ep=3, n/st=10, player_1/loss=1.025, player_2/loss=1.171, rew=3.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #392: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #393: 10001it [00:35, 282.71it/s, env_step=3930000, len=7, n/ep=0, n/st=10, player_1/loss=1.377, player_2/loss=1.502, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #393: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #394: 10001it [00:34, 286.58it/s, env_step=3940000, len=42, n/ep=0, n/st=10, player_1/loss=1.770, player_2/loss=1.990, rew=151.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #394: test_reward: 68.800000 ± 12.600000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #395: 10001it [00:34, 287.45it/s, env_step=3950000, len=18, n/ep=1, n/st=10, player_1/loss=1.086, player_2/loss=1.029, rew=34.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #395: test_reward: 210.500000 ± 61.500000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #396: 10001it [00:34, 287.20it/s, env_step=3960000, len=7, n/ep=3, n/st=10, player_1/loss=1.181, player_2/loss=0.978, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #396: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #397: 10001it [00:34, 287.93it/s, env_step=3970000, len=19, n/ep=1, n/st=10, player_1/loss=1.066, player_2/loss=0.903, rew=6.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #397: test_reward: 175.000000 ± 46.008695, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #398: 10001it [00:34, 287.60it/s, env_step=3980000, len=7, n/ep=0, n/st=10, player_1/loss=1.117, player_2/loss=1.105, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #398: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #399: 10001it [00:34, 287.12it/s, env_step=3990000, len=7, n/ep=0, n/st=10, player_1/loss=1.006, player_2/loss=1.063, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #399: test_reward: 160.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #400: 10001it [00:34, 286.57it/s, env_step=4000000, len=12, n/ep=2, n/st=10, player_1/loss=1.032, player_2/loss=1.075, rew=8.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #400: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #401: 10001it [00:34, 287.48it/s, env_step=4010000, len=7, n/ep=1, n/st=10, player_1/loss=1.059, player_2/loss=1.255, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #401: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #402: 10001it [00:34, 286.92it/s, env_step=4020000, len=37, n/ep=0, n/st=10, player_1/loss=1.051, player_2/loss=1.235, rew=219.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #402: test_reward: 203.800000 ± 67.269309, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #403: 10001it [00:34, 287.86it/s, env_step=4030000, len=7, n/ep=0, n/st=10, player_1/loss=1.058, player_2/loss=1.345, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #403: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #404: 10001it [00:34, 286.60it/s, env_step=4040000, len=7, n/ep=1, n/st=10, player_1/loss=1.033, player_2/loss=1.268, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #404: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #405: 10001it [00:34, 287.23it/s, env_step=4050000, len=7, n/ep=1, n/st=10, player_1/loss=1.014, player_2/loss=1.264, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #405: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #406: 10001it [00:34, 287.29it/s, env_step=4060000, len=22, n/ep=0, n/st=10, player_1/loss=1.022, player_2/loss=1.155, rew=49.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #406: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #407: 10001it [00:34, 287.20it/s, env_step=4070000, len=39, n/ep=0, n/st=10, player_1/loss=0.988, player_2/loss=0.895, rew=178.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #407: test_reward: 172.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #408: 10001it [00:34, 287.31it/s, env_step=4080000, len=14, n/ep=0, n/st=10, player_1/loss=0.977, player_2/loss=1.062, rew=13.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #408: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #409: 10001it [00:34, 287.64it/s, env_step=4090000, len=29, n/ep=0, n/st=10, player_1/loss=0.953, player_2/loss=1.152, rew=65.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #409: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #410: 10001it [00:34, 286.80it/s, env_step=4100000, len=7, n/ep=2, n/st=10, player_1/loss=1.032, player_2/loss=1.105, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #410: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #411: 10001it [00:34, 287.24it/s, env_step=4110000, len=7, n/ep=2, n/st=10, player_1/loss=1.062, player_2/loss=1.203, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #411: test_reward: 1.800000 ± 0.600000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #412: 10001it [00:34, 287.56it/s, env_step=4120000, len=11, n/ep=3, n/st=10, player_1/loss=1.054, player_2/loss=1.269, rew=11.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #412: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #413: 10001it [00:34, 286.98it/s, env_step=4130000, len=7, n/ep=1, n/st=10, player_1/loss=1.122, player_2/loss=1.327, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #413: test_reward: 6.700000 ± 14.100000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #414: 10001it [00:34, 287.24it/s, env_step=4140000, len=20, n/ep=2, n/st=10, player_1/loss=1.063, player_2/loss=1.345, rew=83.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #414: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #415: 10001it [00:34, 287.32it/s, env_step=4150000, len=7, n/ep=0, n/st=10, player_1/loss=1.051, player_2/loss=1.239, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #415: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #416: 10001it [00:34, 287.37it/s, env_step=4160000, len=40, n/ep=1, n/st=10, player_1/loss=1.274, player_2/loss=1.461, rew=188.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #416: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #417: 10001it [00:34, 287.21it/s, env_step=4170000, len=10, n/ep=0, n/st=10, player_1/loss=1.437, player_2/loss=1.671, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #417: test_reward: 131.000000 ± 42.532341, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #418: 10001it [00:34, 287.58it/s, env_step=4180000, len=37, n/ep=0, n/st=10, player_1/loss=1.417, player_2/loss=1.687, rew=173.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #418: test_reward: 113.000000 ± 24.653600, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #419: 10001it [00:34, 286.70it/s, env_step=4190000, len=23, n/ep=2, n/st=10, player_1/loss=1.276, player_2/loss=1.482, rew=46.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #419: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #420: 10001it [00:34, 287.67it/s, env_step=4200000, len=7, n/ep=2, n/st=10, player_1/loss=1.034, player_2/loss=1.397, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #420: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #421: 10001it [00:34, 287.10it/s, env_step=4210000, len=7, n/ep=2, n/st=10, player_1/loss=1.113, player_2/loss=1.325, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #421: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #422: 10001it [00:34, 287.35it/s, env_step=4220000, len=7, n/ep=3, n/st=10, player_1/loss=1.087, player_2/loss=1.174, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #422: test_reward: 6.100000 ± 12.300000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #423: 10001it [00:34, 287.06it/s, env_step=4230000, len=23, n/ep=0, n/st=10, player_1/loss=1.150, player_2/loss=1.044, rew=44.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #423: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #424: 10001it [00:34, 287.07it/s, env_step=4240000, len=39, n/ep=1, n/st=10, player_1/loss=1.135, player_2/loss=0.895, rew=267.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #424: test_reward: 232.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #425: 10001it [00:34, 287.07it/s, env_step=4250000, len=27, n/ep=1, n/st=10, player_1/loss=1.002, player_2/loss=0.944, rew=49.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #425: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #426: 10001it [00:34, 287.69it/s, env_step=4260000, len=39, n/ep=0, n/st=10, player_1/loss=1.231, player_2/loss=1.303, rew=200.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #426: test_reward: 161.200000 ± 18.685824, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #427: 10001it [00:34, 286.66it/s, env_step=4270000, len=25, n/ep=1, n/st=10, player_1/loss=1.048, player_2/loss=1.260, rew=64.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #427: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #428: 10001it [00:34, 287.68it/s, env_step=4280000, len=17, n/ep=0, n/st=10, player_1/loss=0.947, player_2/loss=1.202, rew=78.67]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #428: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #429: 10001it [00:34, 286.90it/s, env_step=4290000, len=7, n/ep=1, n/st=10, player_1/loss=0.933, player_2/loss=1.234, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #429: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #430: 10001it [00:34, 287.28it/s, env_step=4300000, len=7, n/ep=1, n/st=10, player_1/loss=0.987, player_2/loss=1.261, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #430: test_reward: 21.000000 ± 57.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #431: 10001it [00:34, 287.05it/s, env_step=4310000, len=19, n/ep=0, n/st=10, player_1/loss=1.023, player_2/loss=1.388, rew=25.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #431: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #432: 10001it [00:34, 287.07it/s, env_step=4320000, len=7, n/ep=2, n/st=10, player_1/loss=1.101, player_2/loss=1.342, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #432: test_reward: 15.400000 ± 28.397887, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #433: 10001it [00:34, 287.67it/s, env_step=4330000, len=7, n/ep=1, n/st=10, player_1/loss=1.145, player_2/loss=1.410, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #433: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #434: 10001it [00:34, 287.48it/s, env_step=4340000, len=7, n/ep=1, n/st=10, player_1/loss=1.058, player_2/loss=1.338, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #434: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #435: 10001it [00:34, 287.34it/s, env_step=4350000, len=7, n/ep=1, n/st=10, player_1/loss=1.113, player_2/loss=1.287, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #435: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #436: 10001it [00:34, 287.09it/s, env_step=4360000, len=7, n/ep=1, n/st=10, player_1/loss=1.069, player_2/loss=1.262, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #436: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #437: 10001it [00:34, 287.47it/s, env_step=4370000, len=7, n/ep=1, n/st=10, player_1/loss=1.031, player_2/loss=1.258, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #437: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #438: 10001it [00:34, 287.19it/s, env_step=4380000, len=7, n/ep=1, n/st=10, player_1/loss=1.026, player_2/loss=1.187, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #438: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #439: 10001it [00:34, 287.30it/s, env_step=4390000, len=7, n/ep=1, n/st=10, player_1/loss=1.012, player_2/loss=1.215, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #439: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #440: 10001it [00:34, 287.25it/s, env_step=4400000, len=7, n/ep=1, n/st=10, player_1/loss=0.984, player_2/loss=1.145, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #440: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #441: 10001it [00:34, 287.03it/s, env_step=4410000, len=7, n/ep=0, n/st=10, player_1/loss=1.058, player_2/loss=1.168, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #441: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #442: 10001it [00:34, 287.47it/s, env_step=4420000, len=23, n/ep=0, n/st=10, player_1/loss=1.123, player_2/loss=1.229, rew=40.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #442: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #443: 10001it [00:34, 287.13it/s, env_step=4430000, len=7, n/ep=1, n/st=10, player_1/loss=1.106, player_2/loss=1.212, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #443: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #444: 10001it [00:34, 287.01it/s, env_step=4440000, len=7, n/ep=1, n/st=10, player_1/loss=1.161, player_2/loss=1.171, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #444: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #445: 10001it [00:34, 286.03it/s, env_step=4450000, len=19, n/ep=2, n/st=10, player_1/loss=1.158, player_2/loss=1.180, rew=52.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #445: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #446: 10001it [00:34, 286.93it/s, env_step=4460000, len=7, n/ep=1, n/st=10, player_1/loss=1.093, player_2/loss=1.174, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #446: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #447: 10001it [00:34, 287.32it/s, env_step=4470000, len=7, n/ep=2, n/st=10, player_1/loss=1.084, player_2/loss=1.207, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #447: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #448: 10001it [00:34, 287.21it/s, env_step=4480000, len=18, n/ep=0, n/st=10, player_1/loss=1.077, player_2/loss=1.199, rew=35.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #448: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #449: 10001it [00:34, 287.43it/s, env_step=4490000, len=7, n/ep=1, n/st=10, player_1/loss=1.081, player_2/loss=1.185, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #449: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #450: 10001it [00:34, 287.13it/s, env_step=4500000, len=7, n/ep=0, n/st=10, player_1/loss=1.081, player_2/loss=1.269, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #450: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #451: 10001it [00:34, 287.62it/s, env_step=4510000, len=7, n/ep=1, n/st=10, player_1/loss=1.009, player_2/loss=1.273, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #451: test_reward: 8.000000 ± 12.132601, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #452: 10001it [00:34, 287.09it/s, env_step=4520000, len=15, n/ep=0, n/st=10, player_1/loss=1.134, player_2/loss=1.316, rew=18.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #452: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #453: 10001it [00:34, 286.67it/s, env_step=4530000, len=7, n/ep=0, n/st=10, player_1/loss=1.189, player_2/loss=1.345, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #453: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #454: 10001it [00:34, 287.26it/s, env_step=4540000, len=13, n/ep=0, n/st=10, player_1/loss=1.042, player_2/loss=1.268, rew=14.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #454: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #455: 10001it [00:34, 286.66it/s, env_step=4550000, len=7, n/ep=1, n/st=10, player_1/loss=1.105, player_2/loss=1.455, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #455: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #456: 10001it [00:34, 287.14it/s, env_step=4560000, len=7, n/ep=1, n/st=10, player_1/loss=1.071, player_2/loss=1.231, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #456: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #457: 10001it [00:34, 286.91it/s, env_step=4570000, len=7, n/ep=0, n/st=10, player_1/loss=1.187, player_2/loss=1.276, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #457: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #458: 10001it [00:34, 287.08it/s, env_step=4580000, len=7, n/ep=2, n/st=10, player_1/loss=1.092, player_2/loss=1.261, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #458: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #459: 10001it [00:34, 287.19it/s, env_step=4590000, len=7, n/ep=2, n/st=10, player_1/loss=1.134, player_2/loss=1.452, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #459: test_reward: 10.900000 ± 26.700000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #460: 10001it [00:34, 287.42it/s, env_step=4600000, len=7, n/ep=0, n/st=10, player_1/loss=1.096, player_2/loss=1.237, rew=0.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #460: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #461: 10001it [00:34, 287.01it/s, env_step=4610000, len=7, n/ep=1, n/st=10, player_1/loss=1.040, player_2/loss=1.316, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #461: test_reward: 26.300000 ± 49.819775, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #462: 10001it [00:34, 286.21it/s, env_step=4620000, len=7, n/ep=1, n/st=10, player_1/loss=1.096, player_2/loss=1.371, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #462: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #463: 10001it [00:34, 287.11it/s, env_step=4630000, len=7, n/ep=1, n/st=10, player_1/loss=1.212, player_2/loss=1.253, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #463: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #464: 10001it [00:34, 287.52it/s, env_step=4640000, len=16, n/ep=3, n/st=10, player_1/loss=1.175, player_2/loss=1.359, rew=32.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #464: test_reward: 2.600000 ± 1.800000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #465: 10001it [00:34, 287.18it/s, env_step=4650000, len=42, n/ep=1, n/st=10, player_1/loss=1.243, player_2/loss=1.352, rew=205.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #465: test_reward: 21.400000 ± 1.800000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #466: 10001it [00:34, 287.38it/s, env_step=4660000, len=7, n/ep=0, n/st=10, player_1/loss=1.161, player_2/loss=1.230, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #466: test_reward: 1.800000 ± 0.600000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #467: 10001it [00:34, 287.31it/s, env_step=4670000, len=7, n/ep=0, n/st=10, player_1/loss=1.178, player_2/loss=1.301, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #467: test_reward: 10.400000 ± 25.200000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #468: 10001it [00:34, 287.13it/s, env_step=4680000, len=7, n/ep=3, n/st=10, player_1/loss=1.150, player_2/loss=1.291, rew=0.67]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #468: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #469: 10001it [00:34, 287.21it/s, env_step=4690000, len=17, n/ep=0, n/st=10, player_1/loss=1.184, player_2/loss=1.302, rew=22.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #469: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #470: 10001it [00:34, 286.95it/s, env_step=4700000, len=7, n/ep=2, n/st=10, player_1/loss=1.061, player_2/loss=1.302, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #470: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #471: 10001it [00:34, 286.70it/s, env_step=4710000, len=7, n/ep=2, n/st=10, player_1/loss=1.015, player_2/loss=1.294, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #471: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #472: 10001it [00:35, 281.75it/s, env_step=4720000, len=7, n/ep=2, n/st=10, player_1/loss=1.029, player_2/loss=1.371, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #472: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #473: 10001it [00:34, 288.03it/s, env_step=4730000, len=17, n/ep=1, n/st=10, player_1/loss=1.001, player_2/loss=1.268, rew=28.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #473: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #474: 10001it [00:34, 288.02it/s, env_step=4740000, len=7, n/ep=0, n/st=10, player_1/loss=1.105, player_2/loss=1.360, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #474: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #475: 10001it [00:34, 286.30it/s, env_step=4750000, len=7, n/ep=2, n/st=10, player_1/loss=1.019, player_2/loss=1.255, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #475: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #476: 10001it [00:34, 286.37it/s, env_step=4760000, len=7, n/ep=1, n/st=10, player_1/loss=0.949, player_2/loss=1.214, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #476: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #477: 10001it [00:34, 286.40it/s, env_step=4770000, len=13, n/ep=0, n/st=10, player_1/loss=1.070, player_2/loss=1.287, rew=11.00]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #477: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #478: 10001it [00:34, 286.35it/s, env_step=4780000, len=14, n/ep=2, n/st=10, player_1/loss=1.005, player_2/loss=1.310, rew=9.50]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #478: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #479: 10001it [00:35, 282.61it/s, env_step=4790000, len=7, n/ep=1, n/st=10, player_1/loss=1.041, player_2/loss=1.279, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #479: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #480: 10001it [00:35, 284.44it/s, env_step=4800000, len=7, n/ep=1, n/st=10, player_1/loss=1.019, player_2/loss=1.185, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #480: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #481: 10001it [00:34, 286.13it/s, env_step=4810000, len=7, n/ep=2, n/st=10, player_1/loss=1.070, player_2/loss=1.125, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #481: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #482: 10001it [00:34, 285.93it/s, env_step=4820000, len=7, n/ep=0, n/st=10, player_1/loss=1.093, player_2/loss=1.349, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #482: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #483: 10001it [00:34, 286.29it/s, env_step=4830000, len=19, n/ep=1, n/st=10, player_1/loss=1.180, player_2/loss=1.523, rew=0.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #483: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #484: 10001it [00:34, 286.11it/s, env_step=4840000, len=13, n/ep=0, n/st=10, player_1/loss=1.384, player_2/loss=1.525, rew=15.33]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #484: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #485: 10001it [00:34, 286.27it/s, env_step=4850000, len=7, n/ep=0, n/st=10, player_1/loss=1.334, player_2/loss=1.369, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #485: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #486: 10001it [00:34, 286.42it/s, env_step=4860000, len=37, n/ep=0, n/st=10, player_1/loss=1.385, player_2/loss=1.393, rew=185.00]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #486: test_reward: 14.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #487: 10001it [00:34, 286.09it/s, env_step=4870000, len=7, n/ep=0, n/st=10, player_1/loss=1.466, player_2/loss=1.696, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #487: test_reward: 33.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #488: 10001it [00:35, 285.65it/s, env_step=4880000, len=7, n/ep=1, n/st=10, player_1/loss=1.149, player_2/loss=1.321, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #488: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #489: 10001it [00:34, 286.45it/s, env_step=4890000, len=7, n/ep=1, n/st=10, player_1/loss=1.041, player_2/loss=1.208, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #489: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #490: 10001it [00:36, 277.36it/s, env_step=4900000, len=7, n/ep=0, n/st=10, player_1/loss=1.056, player_2/loss=1.136, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #490: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #491: 10001it [00:35, 284.81it/s, env_step=4910000, len=7, n/ep=2, n/st=10, player_1/loss=1.097, player_2/loss=1.172, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #491: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #492: 10001it [00:34, 286.37it/s, env_step=4920000, len=30, n/ep=2, n/st=10, player_1/loss=1.076, player_2/loss=1.178, rew=65.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #492: test_reward: 117.900000 ± 25.668853, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #493: 10001it [00:34, 286.41it/s, env_step=4930000, len=15, n/ep=2, n/st=10, player_1/loss=1.180, player_2/loss=1.152, rew=32.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #493: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #494: 10001it [00:34, 286.48it/s, env_step=4940000, len=13, n/ep=1, n/st=10, player_1/loss=1.215, player_2/loss=1.215, rew=5.00]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #494: test_reward: 22.900000 ± 63.369472, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #495: 10001it [00:34, 286.05it/s, env_step=4950000, len=8, n/ep=2, n/st=10, player_1/loss=1.030, player_2/loss=1.193, rew=1.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #495: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #496: 10001it [00:35, 285.59it/s, env_step=4960000, len=19, n/ep=2, n/st=10, player_1/loss=1.108, player_2/loss=1.248, rew=73.50]                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #496: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #497: 10001it [00:34, 286.29it/s, env_step=4970000, len=7, n/ep=0, n/st=10, player_1/loss=1.093, player_2/loss=1.154, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #497: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #498: 10001it [00:34, 286.18it/s, env_step=4980000, len=7, n/ep=2, n/st=10, player_1/loss=1.068, player_2/loss=1.133, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #498: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #499: 10001it [00:35, 285.50it/s, env_step=4990000, len=7, n/ep=0, n/st=10, player_1/loss=1.078, player_2/loss=1.169, rew=2.00]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #499: test_reward: 2.000000 ± 0.000000, best_reward: 280.000000 ± 0.000000 in #380\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: TRAINING AGENTS\n",
    "####################################################\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure the agents\n",
    "agent1 = rainbow_policy(state_shape= state_shape,\n",
    "                        action_shape= action_shape,\n",
    "                        learning_rate=  0.0001, # Increased from 0000625\n",
    "                        gamma= 0.8, # Decreased from 0.9\n",
    "                        n_step= 3, # Number of steps to look ahead\n",
    "                        num_atoms= 51,\n",
    "                        is_noisy= True,\n",
    "                        noisy_std= 0.1,\n",
    "                        is_dueling= True)\n",
    "\n",
    "\n",
    "agent2 = rainbow_policy(state_shape= state_shape,\n",
    "                        action_shape= action_shape,\n",
    "                        learning_rate=  0.0001, # Increased from 0000625\n",
    "                        gamma= 0.8, # Decreased from 0.9\n",
    "                        n_step= 3, # Number of steps to look ahead\n",
    "                        num_atoms= 51,\n",
    "                        is_noisy= True,\n",
    "                        noisy_std= 0.1,\n",
    "                        is_dueling= True)\n",
    "\n",
    "# Train the agent\n",
    "off_policy_traininer_results, final_agent_player1, final_agent_player2 = train_agent(filename= \"rainbow_vs_rainbow_blocking_reward_complex_cnn\",\n",
    "                                                                                     epochs= 500, # Default 50\n",
    "                                                                                     agent_player1= agent1,\n",
    "                                                                                     agent_player2= agent2,\n",
    "                                                                                     training_env_num= 10,\n",
    "                                                                                     testing_env_num= 10,\n",
    "                                                                                     buffer_size= 10000, # Default 100000\n",
    "                                                                                     batch_size= 64, # Default 32\n",
    "                                                                                     step_per_epoch= 10000, # Default 100000\n",
    "                                                                                     step_per_collect= 10,\n",
    "                                                                                     update_per_step= 0.1,\n",
    "                                                                                     testing_eps= 0.005,\n",
    "                                                                                     training_eps_init= 1,\n",
    "                                                                                     training_eps_final= 0.2) # Default 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8f3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  42.0\n",
      "Final mean reward agent 1: 81.0, std: 0.0\n",
      "Final mean reward agent 2: 199.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE BEST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Get the environment settings\n",
    "env = get_env()\n",
    "observation_space = env.observation_space['observation'] if isinstance(env.observation_space, gym.spaces.Dict) else env.observation_space\n",
    "state_shape = observation_space.shape or observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "# Configure the best agent\n",
    "best_agent1 = rainbow_policy(state_shape= state_shape,\n",
    "                             action_shape= action_shape)\n",
    "best_agent1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_fewer_iterations/best_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "\n",
    "best_agent2 = rainbow_policy(state_shape= state_shape,\n",
    "                             action_shape= action_shape)\n",
    "best_agent2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_fewer_iterations/best_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= best_agent1,\n",
    "      agent_player2= best_agent2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c704acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average steps of game:  7.0\n",
      "Final mean reward agent 1: 5.0, std: 0.0\n",
      "Final mean reward agent 2: -3.0, std: 0.0\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# EXPERIMENT: VIEWING THE LAST LEARNED POLICY\n",
    "####################################################\n",
    "\n",
    "# Configure the final agent\n",
    "final_agent_player1 = rainbow_policy(state_shape= state_shape,\n",
    "                                     action_shape= action_shape)\n",
    "final_agent_player1.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_fewer_iterations/final_policy_agent1.pth\"))\n",
    "best_agent1.set_eps(0)\n",
    "\n",
    "final_agent_player2 = rainbow_policy(state_shape= state_shape,\n",
    "                                     action_shape= action_shape)\n",
    "final_agent_player2.load_state_dict(torch.load(\"./saved_variables/paper_notebooks/9/rainbow_vs_rainbow_blocking_reward_fewer_iterations/final_policy_agent2.pth\"))\n",
    "best_agent2.set_eps(0)\n",
    "\n",
    "# Watch the best agent at work\n",
    "watch(numer_of_games= 3,\n",
    "      render_speed= 0.3,\n",
    "      agent_player1= final_agent_player1,\n",
    "      agent_player2= final_agent_player2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84478519",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Discussion\n",
    "\n",
    "1. When a reward for making moves is given, the agents learn to play together rather then against each other. Just as was the case for DQN. This can be seen by looking at the gameplay of the best reward agents where a tie is reached.\n",
    "> Best reward: 594.700000 ± 344.331541 in epoch 64\n",
    "\n",
    "2. Afterwards we did an experiment with the \"default\" parameters, which does ten times as many iterations per epoch. The found results for the model using a reward for each move is a perfect synced play between agents of getting ties. Thus, this would have been identical as just doing more epochs.\n",
    "> Best reward: 932.000000 ± 0.000000 in epoch 37\n",
    "\n",
    "3. Since the agent optimizes to the rewards, it is more logical to give it a reward when blocking a winning move rather then just for any move made.\n",
    "This will incentive defensive behaviour which is what we want indeed. \n",
    "Since testing only happens on epochs and thus saving the model only happens after an epoch, we beleive it might be better to do shorter epochs but more epochs. For the default iteration and epoch count we got:\n",
    "> Best reward: 233.000000 ± 0.000000 in epoch 25\n",
    "\n",
    "4. After this we used rewards for blocking moves but using 10 times as many epochs for 10 times fewer iterations per epoch. The batch size was also increased to 64 and the learning rate was increased to 0,0001. The gamma was decreased to 0.8. All of this was done to combat the harder network to train and to have more checkpoints for testing for the best model. The reward was also changed so a blocking move gets 1, a win gets 5 (instead of 25) and a draw gets 3(instead of 15). As a result, we got:\n",
    "> Best reward: 280.000000 ± 0.000000 in epoch 380\n",
    "\n",
    "5. From the previous experiments, the fourth was most promising as it had results that were human-like. However, it seems to diverge from a defending strategy to a combination play strategy which causes it to perform worse again. We think a league based testing strategy would be better, which will be tested in the next notebook. Just to test our feature extraction capabilities, we do the same experiment but with a more complex CNN, namely one that outputs 64 filters instead of 16. We also keep the final epsilon higher, from 0.05 to 0.2 in an attempt to reduce the overfitting that seems to happen after a while (when the epsilon has fully decayed). This had de following results:\n",
    "> Todo\n",
    "\n",
    "It is noted that comparing results is difficult since the reward strategy is different between the experiments.\n",
    "After manual inspection by playing against the bot and watching the bots play against each other, the most promosing setup was: X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9110be",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CLEAN VARIABLES\n",
    "####################################################\n",
    "\n",
    "del action_shape\n",
    "del agent1\n",
    "del agent2\n",
    "del best_agent1\n",
    "del best_agent2\n",
    "del env\n",
    "del final_agent_player1\n",
    "del final_agent_player2\n",
    "del observation_space\n",
    "del off_policy_traininer_results\n",
    "del state_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d3da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b88c88564fefe7444548986d165ad8d7f764d0079ffa923785a3f5a89d52c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
